{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beiPfeujKcD2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDkpSOxLKU9F"
   },
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy1G1v4REK8n"
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5nGHn7BLcHv"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.AdaptiveMaxPool2d(output_size=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout1d(0.3),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.Linear(in_features=32, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1FBNAkXUjo1"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device: str):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * dataloader.batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    wandb.log({\"train_loss\": train_loss / num_batches})\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = accuracy = 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            accuracy += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    accuracy /= size\n",
    "\n",
    "    wandb.log({\"test_loss\": test_loss, \"test_accuracy\": accuracy})\n",
    "\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100 * accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23458,
     "status": "ok",
     "timestamp": 1746198871758,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "c732t0KmVilF",
    "outputId": "dd68ee21-ac74-437a-b033-917aeff5d576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshadaevf\u001b[0m (\u001b[33mshadaevf-rtu-mirea\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "%wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 345528,
     "status": "ok",
     "timestamp": 1746186479316,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "72Xsgqt9Vjci",
    "outputId": "8c3ee64c-422b-4637-90d6-30cd815eb888"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250502_114215-2dwm3e2g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1/runs/2dwm3e2g' target=\"_blank\">experiment_2</a></strong> to <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1/runs/2dwm3e2g' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1/runs/2dwm3e2g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.487679  [   64/50000]\n",
      "loss: 2.317317  [  704/50000]\n",
      "loss: 2.140590  [ 1344/50000]\n",
      "loss: 2.192800  [ 1984/50000]\n",
      "loss: 2.262737  [ 2624/50000]\n",
      "loss: 2.254214  [ 3264/50000]\n",
      "loss: 1.992481  [ 3904/50000]\n",
      "loss: 2.001099  [ 4544/50000]\n",
      "loss: 1.999909  [ 5184/50000]\n",
      "loss: 2.014502  [ 5824/50000]\n",
      "loss: 2.339933  [ 6464/50000]\n",
      "loss: 2.061233  [ 7104/50000]\n",
      "loss: 2.118289  [ 7744/50000]\n",
      "loss: 1.914649  [ 8384/50000]\n",
      "loss: 2.080012  [ 9024/50000]\n",
      "loss: 1.905033  [ 9664/50000]\n",
      "loss: 1.936393  [10304/50000]\n",
      "loss: 1.978029  [10944/50000]\n",
      "loss: 2.137023  [11584/50000]\n",
      "loss: 2.092334  [12224/50000]\n",
      "loss: 1.947073  [12864/50000]\n",
      "loss: 1.956836  [13504/50000]\n",
      "loss: 1.925133  [14144/50000]\n",
      "loss: 2.002147  [14784/50000]\n",
      "loss: 2.026057  [15424/50000]\n",
      "loss: 2.028409  [16064/50000]\n",
      "loss: 1.893734  [16704/50000]\n",
      "loss: 1.922664  [17344/50000]\n",
      "loss: 1.835892  [17984/50000]\n",
      "loss: 1.983885  [18624/50000]\n",
      "loss: 1.826490  [19264/50000]\n",
      "loss: 1.967239  [19904/50000]\n",
      "loss: 1.979837  [20544/50000]\n",
      "loss: 2.101705  [21184/50000]\n",
      "loss: 2.033708  [21824/50000]\n",
      "loss: 2.021989  [22464/50000]\n",
      "loss: 1.943271  [23104/50000]\n",
      "loss: 2.001745  [23744/50000]\n",
      "loss: 1.953608  [24384/50000]\n",
      "loss: 1.921093  [25024/50000]\n",
      "loss: 1.888726  [25664/50000]\n",
      "loss: 1.908182  [26304/50000]\n",
      "loss: 1.928752  [26944/50000]\n",
      "loss: 1.848908  [27584/50000]\n",
      "loss: 2.042736  [28224/50000]\n",
      "loss: 1.883736  [28864/50000]\n",
      "loss: 2.084746  [29504/50000]\n",
      "loss: 1.773214  [30144/50000]\n",
      "loss: 2.025797  [30784/50000]\n",
      "loss: 1.956079  [31424/50000]\n",
      "loss: 1.915120  [32064/50000]\n",
      "loss: 1.875874  [32704/50000]\n",
      "loss: 1.888803  [33344/50000]\n",
      "loss: 1.972326  [33984/50000]\n",
      "loss: 1.930723  [34624/50000]\n",
      "loss: 1.994877  [35264/50000]\n",
      "loss: 1.847175  [35904/50000]\n",
      "loss: 1.934106  [36544/50000]\n",
      "loss: 1.801020  [37184/50000]\n",
      "loss: 1.994960  [37824/50000]\n",
      "loss: 1.750185  [38464/50000]\n",
      "loss: 1.770965  [39104/50000]\n",
      "loss: 1.876636  [39744/50000]\n",
      "loss: 1.911005  [40384/50000]\n",
      "loss: 1.960558  [41024/50000]\n",
      "loss: 1.935901  [41664/50000]\n",
      "loss: 1.867360  [42304/50000]\n",
      "loss: 2.028477  [42944/50000]\n",
      "loss: 1.809355  [43584/50000]\n",
      "loss: 1.692316  [44224/50000]\n",
      "loss: 2.063454  [44864/50000]\n",
      "loss: 1.943736  [45504/50000]\n",
      "loss: 1.752672  [46144/50000]\n",
      "loss: 2.056529  [46784/50000]\n",
      "loss: 1.950380  [47424/50000]\n",
      "loss: 1.918702  [48064/50000]\n",
      "loss: 1.791873  [48704/50000]\n",
      "loss: 1.805228  [49344/50000]\n",
      "loss: 1.884204  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.506669 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.809465  [   64/50000]\n",
      "loss: 1.906686  [  704/50000]\n",
      "loss: 1.718898  [ 1344/50000]\n",
      "loss: 1.893190  [ 1984/50000]\n",
      "loss: 1.820071  [ 2624/50000]\n",
      "loss: 1.859637  [ 3264/50000]\n",
      "loss: 1.761892  [ 3904/50000]\n",
      "loss: 1.859348  [ 4544/50000]\n",
      "loss: 1.761582  [ 5184/50000]\n",
      "loss: 1.817801  [ 5824/50000]\n",
      "loss: 1.996031  [ 6464/50000]\n",
      "loss: 1.846348  [ 7104/50000]\n",
      "loss: 1.827255  [ 7744/50000]\n",
      "loss: 1.938681  [ 8384/50000]\n",
      "loss: 1.660785  [ 9024/50000]\n",
      "loss: 1.724255  [ 9664/50000]\n",
      "loss: 1.850696  [10304/50000]\n",
      "loss: 1.828288  [10944/50000]\n",
      "loss: 1.757987  [11584/50000]\n",
      "loss: 1.768515  [12224/50000]\n",
      "loss: 1.856956  [12864/50000]\n",
      "loss: 1.749617  [13504/50000]\n",
      "loss: 1.775048  [14144/50000]\n",
      "loss: 1.763102  [14784/50000]\n",
      "loss: 2.048234  [15424/50000]\n",
      "loss: 2.087824  [16064/50000]\n",
      "loss: 1.734985  [16704/50000]\n",
      "loss: 1.851724  [17344/50000]\n",
      "loss: 1.870993  [17984/50000]\n",
      "loss: 1.950689  [18624/50000]\n",
      "loss: 1.729533  [19264/50000]\n",
      "loss: 1.891629  [19904/50000]\n",
      "loss: 1.741146  [20544/50000]\n",
      "loss: 1.689850  [21184/50000]\n",
      "loss: 1.827200  [21824/50000]\n",
      "loss: 1.882938  [22464/50000]\n",
      "loss: 1.955295  [23104/50000]\n",
      "loss: 1.769856  [23744/50000]\n",
      "loss: 1.587978  [24384/50000]\n",
      "loss: 1.752570  [25024/50000]\n",
      "loss: 1.655097  [25664/50000]\n",
      "loss: 1.849151  [26304/50000]\n",
      "loss: 1.698638  [26944/50000]\n",
      "loss: 1.710250  [27584/50000]\n",
      "loss: 1.813386  [28224/50000]\n",
      "loss: 1.881878  [28864/50000]\n",
      "loss: 1.736369  [29504/50000]\n",
      "loss: 1.903953  [30144/50000]\n",
      "loss: 1.696772  [30784/50000]\n",
      "loss: 1.790577  [31424/50000]\n",
      "loss: 1.761481  [32064/50000]\n",
      "loss: 1.756776  [32704/50000]\n",
      "loss: 1.853778  [33344/50000]\n",
      "loss: 1.563647  [33984/50000]\n",
      "loss: 1.676107  [34624/50000]\n",
      "loss: 1.819265  [35264/50000]\n",
      "loss: 1.693829  [35904/50000]\n",
      "loss: 1.660607  [36544/50000]\n",
      "loss: 1.634854  [37184/50000]\n",
      "loss: 1.754675  [37824/50000]\n",
      "loss: 1.605447  [38464/50000]\n",
      "loss: 1.648877  [39104/50000]\n",
      "loss: 1.697030  [39744/50000]\n",
      "loss: 1.813182  [40384/50000]\n",
      "loss: 1.724862  [41024/50000]\n",
      "loss: 2.081737  [41664/50000]\n",
      "loss: 1.807105  [42304/50000]\n",
      "loss: 1.795401  [42944/50000]\n",
      "loss: 1.849091  [43584/50000]\n",
      "loss: 1.667398  [44224/50000]\n",
      "loss: 1.807035  [44864/50000]\n",
      "loss: 1.722485  [45504/50000]\n",
      "loss: 1.792732  [46144/50000]\n",
      "loss: 1.650440  [46784/50000]\n",
      "loss: 1.819413  [47424/50000]\n",
      "loss: 1.659610  [48064/50000]\n",
      "loss: 1.708266  [48704/50000]\n",
      "loss: 1.544830  [49344/50000]\n",
      "loss: 1.906232  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 1.351684 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.765802  [   64/50000]\n",
      "loss: 1.679548  [  704/50000]\n",
      "loss: 1.785260  [ 1344/50000]\n",
      "loss: 1.874215  [ 1984/50000]\n",
      "loss: 1.810759  [ 2624/50000]\n",
      "loss: 1.821478  [ 3264/50000]\n",
      "loss: 1.682573  [ 3904/50000]\n",
      "loss: 1.763597  [ 4544/50000]\n",
      "loss: 1.763179  [ 5184/50000]\n",
      "loss: 1.885956  [ 5824/50000]\n",
      "loss: 1.762611  [ 6464/50000]\n",
      "loss: 1.626342  [ 7104/50000]\n",
      "loss: 1.627907  [ 7744/50000]\n",
      "loss: 1.725919  [ 8384/50000]\n",
      "loss: 1.790591  [ 9024/50000]\n",
      "loss: 1.555687  [ 9664/50000]\n",
      "loss: 1.662723  [10304/50000]\n",
      "loss: 1.963561  [10944/50000]\n",
      "loss: 1.778155  [11584/50000]\n",
      "loss: 1.843239  [12224/50000]\n",
      "loss: 1.823987  [12864/50000]\n",
      "loss: 1.818766  [13504/50000]\n",
      "loss: 1.741964  [14144/50000]\n",
      "loss: 1.741724  [14784/50000]\n",
      "loss: 1.875166  [15424/50000]\n",
      "loss: 1.809606  [16064/50000]\n",
      "loss: 1.871665  [16704/50000]\n",
      "loss: 1.725922  [17344/50000]\n",
      "loss: 1.772789  [17984/50000]\n",
      "loss: 1.779702  [18624/50000]\n",
      "loss: 1.716527  [19264/50000]\n",
      "loss: 1.734626  [19904/50000]\n",
      "loss: 1.650012  [20544/50000]\n",
      "loss: 1.703244  [21184/50000]\n",
      "loss: 1.631932  [21824/50000]\n",
      "loss: 1.967463  [22464/50000]\n",
      "loss: 1.782825  [23104/50000]\n",
      "loss: 1.477969  [23744/50000]\n",
      "loss: 1.682907  [24384/50000]\n",
      "loss: 1.825507  [25024/50000]\n",
      "loss: 1.419040  [25664/50000]\n",
      "loss: 1.798429  [26304/50000]\n",
      "loss: 1.444483  [26944/50000]\n",
      "loss: 1.745054  [27584/50000]\n",
      "loss: 1.449159  [28224/50000]\n",
      "loss: 1.656501  [28864/50000]\n",
      "loss: 1.895725  [29504/50000]\n",
      "loss: 1.390241  [30144/50000]\n",
      "loss: 1.880645  [30784/50000]\n",
      "loss: 1.868823  [31424/50000]\n",
      "loss: 1.772518  [32064/50000]\n",
      "loss: 1.823441  [32704/50000]\n",
      "loss: 1.557565  [33344/50000]\n",
      "loss: 1.823639  [33984/50000]\n",
      "loss: 1.763108  [34624/50000]\n",
      "loss: 1.492044  [35264/50000]\n",
      "loss: 1.796993  [35904/50000]\n",
      "loss: 1.711050  [36544/50000]\n",
      "loss: 1.444424  [37184/50000]\n",
      "loss: 1.681249  [37824/50000]\n",
      "loss: 1.606701  [38464/50000]\n",
      "loss: 1.624120  [39104/50000]\n",
      "loss: 1.767977  [39744/50000]\n",
      "loss: 1.522127  [40384/50000]\n",
      "loss: 1.655837  [41024/50000]\n",
      "loss: 1.716690  [41664/50000]\n",
      "loss: 1.717015  [42304/50000]\n",
      "loss: 1.611104  [42944/50000]\n",
      "loss: 1.413225  [43584/50000]\n",
      "loss: 1.943769  [44224/50000]\n",
      "loss: 1.722363  [44864/50000]\n",
      "loss: 1.798982  [45504/50000]\n",
      "loss: 1.701302  [46144/50000]\n",
      "loss: 1.648046  [46784/50000]\n",
      "loss: 1.683608  [47424/50000]\n",
      "loss: 1.778516  [48064/50000]\n",
      "loss: 1.586752  [48704/50000]\n",
      "loss: 1.599441  [49344/50000]\n",
      "loss: 1.732430  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.256522 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.548895  [   64/50000]\n",
      "loss: 1.620320  [  704/50000]\n",
      "loss: 1.486869  [ 1344/50000]\n",
      "loss: 1.784298  [ 1984/50000]\n",
      "loss: 1.785849  [ 2624/50000]\n",
      "loss: 1.638659  [ 3264/50000]\n",
      "loss: 1.766780  [ 3904/50000]\n",
      "loss: 1.647299  [ 4544/50000]\n",
      "loss: 1.772880  [ 5184/50000]\n",
      "loss: 1.447402  [ 5824/50000]\n",
      "loss: 1.636886  [ 6464/50000]\n",
      "loss: 1.772205  [ 7104/50000]\n",
      "loss: 1.498975  [ 7744/50000]\n",
      "loss: 1.826441  [ 8384/50000]\n",
      "loss: 1.600183  [ 9024/50000]\n",
      "loss: 1.680847  [ 9664/50000]\n",
      "loss: 1.649740  [10304/50000]\n",
      "loss: 1.498006  [10944/50000]\n",
      "loss: 1.635131  [11584/50000]\n",
      "loss: 1.488154  [12224/50000]\n",
      "loss: 1.632101  [12864/50000]\n",
      "loss: 1.590400  [13504/50000]\n",
      "loss: 1.573970  [14144/50000]\n",
      "loss: 1.644728  [14784/50000]\n",
      "loss: 1.728788  [15424/50000]\n",
      "loss: 1.690001  [16064/50000]\n",
      "loss: 1.516943  [16704/50000]\n",
      "loss: 1.781880  [17344/50000]\n",
      "loss: 1.619183  [17984/50000]\n",
      "loss: 1.983119  [18624/50000]\n",
      "loss: 1.698576  [19264/50000]\n",
      "loss: 1.742527  [19904/50000]\n",
      "loss: 1.995611  [20544/50000]\n",
      "loss: 1.581983  [21184/50000]\n",
      "loss: 1.757179  [21824/50000]\n",
      "loss: 1.449569  [22464/50000]\n",
      "loss: 1.624464  [23104/50000]\n",
      "loss: 1.810283  [23744/50000]\n",
      "loss: 1.688417  [24384/50000]\n",
      "loss: 2.031938  [25024/50000]\n",
      "loss: 1.669890  [25664/50000]\n",
      "loss: 1.549715  [26304/50000]\n",
      "loss: 1.803794  [26944/50000]\n",
      "loss: 1.858946  [27584/50000]\n",
      "loss: 1.731747  [28224/50000]\n",
      "loss: 1.534412  [28864/50000]\n",
      "loss: 1.870935  [29504/50000]\n",
      "loss: 1.595415  [30144/50000]\n",
      "loss: 1.675834  [30784/50000]\n",
      "loss: 1.547300  [31424/50000]\n",
      "loss: 1.651669  [32064/50000]\n",
      "loss: 1.477000  [32704/50000]\n",
      "loss: 1.825387  [33344/50000]\n",
      "loss: 1.479310  [33984/50000]\n",
      "loss: 1.586205  [34624/50000]\n",
      "loss: 1.484609  [35264/50000]\n",
      "loss: 1.815141  [35904/50000]\n",
      "loss: 1.673063  [36544/50000]\n",
      "loss: 1.662944  [37184/50000]\n",
      "loss: 1.730705  [37824/50000]\n",
      "loss: 1.785739  [38464/50000]\n",
      "loss: 1.592784  [39104/50000]\n",
      "loss: 1.561941  [39744/50000]\n",
      "loss: 1.705348  [40384/50000]\n",
      "loss: 1.532310  [41024/50000]\n",
      "loss: 1.694406  [41664/50000]\n",
      "loss: 1.728967  [42304/50000]\n",
      "loss: 1.552562  [42944/50000]\n",
      "loss: 1.631909  [43584/50000]\n",
      "loss: 1.874172  [44224/50000]\n",
      "loss: 1.880004  [44864/50000]\n",
      "loss: 1.684365  [45504/50000]\n",
      "loss: 1.644009  [46144/50000]\n",
      "loss: 1.706380  [46784/50000]\n",
      "loss: 1.806342  [47424/50000]\n",
      "loss: 1.717831  [48064/50000]\n",
      "loss: 1.585224  [48704/50000]\n",
      "loss: 1.644349  [49344/50000]\n",
      "loss: 1.608014  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.192327 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.691091  [   64/50000]\n",
      "loss: 1.705632  [  704/50000]\n",
      "loss: 1.522518  [ 1344/50000]\n",
      "loss: 1.468365  [ 1984/50000]\n",
      "loss: 1.579621  [ 2624/50000]\n",
      "loss: 1.732374  [ 3264/50000]\n",
      "loss: 1.638514  [ 3904/50000]\n",
      "loss: 1.590385  [ 4544/50000]\n",
      "loss: 1.661825  [ 5184/50000]\n",
      "loss: 1.615769  [ 5824/50000]\n",
      "loss: 1.629633  [ 6464/50000]\n",
      "loss: 1.559609  [ 7104/50000]\n",
      "loss: 1.563521  [ 7744/50000]\n",
      "loss: 1.750236  [ 8384/50000]\n",
      "loss: 1.572192  [ 9024/50000]\n",
      "loss: 1.680971  [ 9664/50000]\n",
      "loss: 1.731085  [10304/50000]\n",
      "loss: 1.576779  [10944/50000]\n",
      "loss: 1.590926  [11584/50000]\n",
      "loss: 1.512194  [12224/50000]\n",
      "loss: 1.785431  [12864/50000]\n",
      "loss: 1.495160  [13504/50000]\n",
      "loss: 1.725998  [14144/50000]\n",
      "loss: 1.602602  [14784/50000]\n",
      "loss: 1.837784  [15424/50000]\n",
      "loss: 1.452893  [16064/50000]\n",
      "loss: 1.654806  [16704/50000]\n",
      "loss: 1.765788  [17344/50000]\n",
      "loss: 1.693997  [17984/50000]\n",
      "loss: 1.654310  [18624/50000]\n",
      "loss: 1.769526  [19264/50000]\n",
      "loss: 1.579867  [19904/50000]\n",
      "loss: 1.635672  [20544/50000]\n",
      "loss: 1.548474  [21184/50000]\n",
      "loss: 1.562658  [21824/50000]\n",
      "loss: 1.542378  [22464/50000]\n",
      "loss: 1.550708  [23104/50000]\n",
      "loss: 1.479969  [23744/50000]\n",
      "loss: 1.754879  [24384/50000]\n",
      "loss: 1.479948  [25024/50000]\n",
      "loss: 1.625458  [25664/50000]\n",
      "loss: 1.556110  [26304/50000]\n",
      "loss: 1.521467  [26944/50000]\n",
      "loss: 1.497687  [27584/50000]\n",
      "loss: 1.467799  [28224/50000]\n",
      "loss: 1.488456  [28864/50000]\n",
      "loss: 1.618004  [29504/50000]\n",
      "loss: 1.343456  [30144/50000]\n",
      "loss: 1.512710  [30784/50000]\n",
      "loss: 1.412103  [31424/50000]\n",
      "loss: 1.746383  [32064/50000]\n",
      "loss: 1.622686  [32704/50000]\n",
      "loss: 1.559447  [33344/50000]\n",
      "loss: 1.505202  [33984/50000]\n",
      "loss: 1.588166  [34624/50000]\n",
      "loss: 1.625264  [35264/50000]\n",
      "loss: 1.718700  [35904/50000]\n",
      "loss: 1.439365  [36544/50000]\n",
      "loss: 1.511493  [37184/50000]\n",
      "loss: 1.477834  [37824/50000]\n",
      "loss: 1.679140  [38464/50000]\n",
      "loss: 1.680091  [39104/50000]\n",
      "loss: 1.687614  [39744/50000]\n",
      "loss: 1.397719  [40384/50000]\n",
      "loss: 1.300442  [41024/50000]\n",
      "loss: 1.678778  [41664/50000]\n",
      "loss: 1.563028  [42304/50000]\n",
      "loss: 1.735096  [42944/50000]\n",
      "loss: 1.552642  [43584/50000]\n",
      "loss: 1.747708  [44224/50000]\n",
      "loss: 1.514147  [44864/50000]\n",
      "loss: 1.457119  [45504/50000]\n",
      "loss: 1.618652  [46144/50000]\n",
      "loss: 1.690891  [46784/50000]\n",
      "loss: 1.782812  [47424/50000]\n",
      "loss: 1.566267  [48064/50000]\n",
      "loss: 1.524213  [48704/50000]\n",
      "loss: 1.616799  [49344/50000]\n",
      "loss: 1.499121  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.107723 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.432345  [   64/50000]\n",
      "loss: 1.836606  [  704/50000]\n",
      "loss: 1.688123  [ 1344/50000]\n",
      "loss: 1.554750  [ 1984/50000]\n",
      "loss: 1.520953  [ 2624/50000]\n",
      "loss: 1.713474  [ 3264/50000]\n",
      "loss: 1.531384  [ 3904/50000]\n",
      "loss: 1.770634  [ 4544/50000]\n",
      "loss: 1.694088  [ 5184/50000]\n",
      "loss: 1.443151  [ 5824/50000]\n",
      "loss: 1.748026  [ 6464/50000]\n",
      "loss: 1.472888  [ 7104/50000]\n",
      "loss: 1.485081  [ 7744/50000]\n",
      "loss: 1.679901  [ 8384/50000]\n",
      "loss: 1.475026  [ 9024/50000]\n",
      "loss: 1.515248  [ 9664/50000]\n",
      "loss: 1.537373  [10304/50000]\n",
      "loss: 1.646950  [10944/50000]\n",
      "loss: 1.562375  [11584/50000]\n",
      "loss: 1.508331  [12224/50000]\n",
      "loss: 1.539726  [12864/50000]\n",
      "loss: 1.616853  [13504/50000]\n",
      "loss: 1.290040  [14144/50000]\n",
      "loss: 1.524131  [14784/50000]\n",
      "loss: 1.444986  [15424/50000]\n",
      "loss: 1.659021  [16064/50000]\n",
      "loss: 1.717382  [16704/50000]\n",
      "loss: 1.512043  [17344/50000]\n",
      "loss: 1.635220  [17984/50000]\n",
      "loss: 1.615793  [18624/50000]\n",
      "loss: 1.423241  [19264/50000]\n",
      "loss: 1.561125  [19904/50000]\n",
      "loss: 1.425887  [20544/50000]\n",
      "loss: 1.587354  [21184/50000]\n",
      "loss: 1.737844  [21824/50000]\n",
      "loss: 1.481450  [22464/50000]\n",
      "loss: 1.426690  [23104/50000]\n",
      "loss: 1.683626  [23744/50000]\n",
      "loss: 1.563145  [24384/50000]\n",
      "loss: 1.548737  [25024/50000]\n",
      "loss: 1.769429  [25664/50000]\n",
      "loss: 1.617073  [26304/50000]\n",
      "loss: 1.604758  [26944/50000]\n",
      "loss: 1.404144  [27584/50000]\n",
      "loss: 1.365010  [28224/50000]\n",
      "loss: 1.576596  [28864/50000]\n",
      "loss: 1.607288  [29504/50000]\n",
      "loss: 1.786332  [30144/50000]\n",
      "loss: 1.572161  [30784/50000]\n",
      "loss: 1.286571  [31424/50000]\n",
      "loss: 1.572447  [32064/50000]\n",
      "loss: 1.688942  [32704/50000]\n",
      "loss: 1.871131  [33344/50000]\n",
      "loss: 1.798071  [33984/50000]\n",
      "loss: 1.779822  [34624/50000]\n",
      "loss: 1.672262  [35264/50000]\n",
      "loss: 1.472320  [35904/50000]\n",
      "loss: 1.506189  [36544/50000]\n",
      "loss: 1.562372  [37184/50000]\n",
      "loss: 1.533745  [37824/50000]\n",
      "loss: 1.569481  [38464/50000]\n",
      "loss: 1.627251  [39104/50000]\n",
      "loss: 1.317719  [39744/50000]\n",
      "loss: 1.383182  [40384/50000]\n",
      "loss: 1.515856  [41024/50000]\n",
      "loss: 1.496298  [41664/50000]\n",
      "loss: 1.427128  [42304/50000]\n",
      "loss: 1.506190  [42944/50000]\n",
      "loss: 1.746225  [43584/50000]\n",
      "loss: 1.546725  [44224/50000]\n",
      "loss: 1.559225  [44864/50000]\n",
      "loss: 1.525378  [45504/50000]\n",
      "loss: 1.348759  [46144/50000]\n",
      "loss: 1.462631  [46784/50000]\n",
      "loss: 1.777893  [47424/50000]\n",
      "loss: 1.324357  [48064/50000]\n",
      "loss: 1.483850  [48704/50000]\n",
      "loss: 1.347120  [49344/50000]\n",
      "loss: 1.569284  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 1.076267 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.286144  [   64/50000]\n",
      "loss: 1.770290  [  704/50000]\n",
      "loss: 1.512259  [ 1344/50000]\n",
      "loss: 1.372772  [ 1984/50000]\n",
      "loss: 1.481165  [ 2624/50000]\n",
      "loss: 1.622201  [ 3264/50000]\n",
      "loss: 1.544025  [ 3904/50000]\n",
      "loss: 1.444976  [ 4544/50000]\n",
      "loss: 1.479363  [ 5184/50000]\n",
      "loss: 1.407080  [ 5824/50000]\n",
      "loss: 1.920774  [ 6464/50000]\n",
      "loss: 1.494492  [ 7104/50000]\n",
      "loss: 1.345502  [ 7744/50000]\n",
      "loss: 1.255056  [ 8384/50000]\n",
      "loss: 1.636801  [ 9024/50000]\n",
      "loss: 1.679436  [ 9664/50000]\n",
      "loss: 1.375612  [10304/50000]\n",
      "loss: 1.402999  [10944/50000]\n",
      "loss: 1.416107  [11584/50000]\n",
      "loss: 1.593959  [12224/50000]\n",
      "loss: 1.657722  [12864/50000]\n",
      "loss: 1.848726  [13504/50000]\n",
      "loss: 1.538813  [14144/50000]\n",
      "loss: 1.476000  [14784/50000]\n",
      "loss: 1.406020  [15424/50000]\n",
      "loss: 1.429469  [16064/50000]\n",
      "loss: 1.557665  [16704/50000]\n",
      "loss: 1.513472  [17344/50000]\n",
      "loss: 1.417958  [17984/50000]\n",
      "loss: 1.460448  [18624/50000]\n",
      "loss: 1.578744  [19264/50000]\n",
      "loss: 1.594849  [19904/50000]\n",
      "loss: 1.739838  [20544/50000]\n",
      "loss: 1.466888  [21184/50000]\n",
      "loss: 1.524928  [21824/50000]\n",
      "loss: 1.562708  [22464/50000]\n",
      "loss: 1.633916  [23104/50000]\n",
      "loss: 1.548000  [23744/50000]\n",
      "loss: 1.718539  [24384/50000]\n",
      "loss: 1.450182  [25024/50000]\n",
      "loss: 1.525360  [25664/50000]\n",
      "loss: 1.472170  [26304/50000]\n",
      "loss: 1.646543  [26944/50000]\n",
      "loss: 1.543576  [27584/50000]\n",
      "loss: 1.494544  [28224/50000]\n",
      "loss: 1.217791  [28864/50000]\n",
      "loss: 1.476391  [29504/50000]\n",
      "loss: 1.540871  [30144/50000]\n",
      "loss: 1.501337  [30784/50000]\n",
      "loss: 1.665119  [31424/50000]\n",
      "loss: 1.794439  [32064/50000]\n",
      "loss: 1.279330  [32704/50000]\n",
      "loss: 1.315576  [33344/50000]\n",
      "loss: 1.458326  [33984/50000]\n",
      "loss: 1.636873  [34624/50000]\n",
      "loss: 1.701308  [35264/50000]\n",
      "loss: 1.452755  [35904/50000]\n",
      "loss: 1.472255  [36544/50000]\n",
      "loss: 1.554833  [37184/50000]\n",
      "loss: 1.640389  [37824/50000]\n",
      "loss: 1.539067  [38464/50000]\n",
      "loss: 1.610907  [39104/50000]\n",
      "loss: 1.390999  [39744/50000]\n",
      "loss: 1.519624  [40384/50000]\n",
      "loss: 1.798820  [41024/50000]\n",
      "loss: 1.752667  [41664/50000]\n",
      "loss: 1.397096  [42304/50000]\n",
      "loss: 1.660567  [42944/50000]\n",
      "loss: 1.462488  [43584/50000]\n",
      "loss: 1.371273  [44224/50000]\n",
      "loss: 1.720087  [44864/50000]\n",
      "loss: 1.834183  [45504/50000]\n",
      "loss: 1.561981  [46144/50000]\n",
      "loss: 1.652685  [46784/50000]\n",
      "loss: 1.287843  [47424/50000]\n",
      "loss: 1.500424  [48064/50000]\n",
      "loss: 1.445538  [48704/50000]\n",
      "loss: 1.686169  [49344/50000]\n",
      "loss: 1.679741  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.050723 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.477681  [   64/50000]\n",
      "loss: 1.423996  [  704/50000]\n",
      "loss: 1.393860  [ 1344/50000]\n",
      "loss: 1.469563  [ 1984/50000]\n",
      "loss: 1.425691  [ 2624/50000]\n",
      "loss: 1.437757  [ 3264/50000]\n",
      "loss: 1.655262  [ 3904/50000]\n",
      "loss: 1.497666  [ 4544/50000]\n",
      "loss: 1.569821  [ 5184/50000]\n",
      "loss: 1.196330  [ 5824/50000]\n",
      "loss: 1.574180  [ 6464/50000]\n",
      "loss: 1.515906  [ 7104/50000]\n",
      "loss: 1.517100  [ 7744/50000]\n",
      "loss: 1.413391  [ 8384/50000]\n",
      "loss: 1.513559  [ 9024/50000]\n",
      "loss: 1.735075  [ 9664/50000]\n",
      "loss: 1.653174  [10304/50000]\n",
      "loss: 1.700140  [10944/50000]\n",
      "loss: 1.291977  [11584/50000]\n",
      "loss: 1.439340  [12224/50000]\n",
      "loss: 1.533384  [12864/50000]\n",
      "loss: 1.351648  [13504/50000]\n",
      "loss: 1.480078  [14144/50000]\n",
      "loss: 1.558017  [14784/50000]\n",
      "loss: 1.632497  [15424/50000]\n",
      "loss: 1.331504  [16064/50000]\n",
      "loss: 1.438379  [16704/50000]\n",
      "loss: 1.677803  [17344/50000]\n",
      "loss: 1.595780  [17984/50000]\n",
      "loss: 1.661790  [18624/50000]\n",
      "loss: 1.488834  [19264/50000]\n",
      "loss: 1.422497  [19904/50000]\n",
      "loss: 1.674100  [20544/50000]\n",
      "loss: 1.463137  [21184/50000]\n",
      "loss: 1.475786  [21824/50000]\n",
      "loss: 1.563601  [22464/50000]\n",
      "loss: 1.475087  [23104/50000]\n",
      "loss: 1.634028  [23744/50000]\n",
      "loss: 1.329452  [24384/50000]\n",
      "loss: 1.490842  [25024/50000]\n",
      "loss: 1.390456  [25664/50000]\n",
      "loss: 1.537415  [26304/50000]\n",
      "loss: 1.527212  [26944/50000]\n",
      "loss: 1.440645  [27584/50000]\n",
      "loss: 1.365467  [28224/50000]\n",
      "loss: 1.574946  [28864/50000]\n",
      "loss: 1.458746  [29504/50000]\n",
      "loss: 1.569949  [30144/50000]\n",
      "loss: 1.600684  [30784/50000]\n",
      "loss: 1.534662  [31424/50000]\n",
      "loss: 1.533606  [32064/50000]\n",
      "loss: 1.537706  [32704/50000]\n",
      "loss: 1.687811  [33344/50000]\n",
      "loss: 1.298158  [33984/50000]\n",
      "loss: 1.515122  [34624/50000]\n",
      "loss: 1.518791  [35264/50000]\n",
      "loss: 1.666770  [35904/50000]\n",
      "loss: 1.691108  [36544/50000]\n",
      "loss: 1.626013  [37184/50000]\n",
      "loss: 1.722179  [37824/50000]\n",
      "loss: 1.594142  [38464/50000]\n",
      "loss: 1.611482  [39104/50000]\n",
      "loss: 1.378553  [39744/50000]\n",
      "loss: 1.538059  [40384/50000]\n",
      "loss: 1.682223  [41024/50000]\n",
      "loss: 1.583694  [41664/50000]\n",
      "loss: 1.453591  [42304/50000]\n",
      "loss: 1.273504  [42944/50000]\n",
      "loss: 1.599872  [43584/50000]\n",
      "loss: 1.676576  [44224/50000]\n",
      "loss: 1.609815  [44864/50000]\n",
      "loss: 1.402109  [45504/50000]\n",
      "loss: 1.614627  [46144/50000]\n",
      "loss: 1.586765  [46784/50000]\n",
      "loss: 1.458964  [47424/50000]\n",
      "loss: 1.766892  [48064/50000]\n",
      "loss: 1.542438  [48704/50000]\n",
      "loss: 1.413760  [49344/50000]\n",
      "loss: 1.413108  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.992397 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.355407  [   64/50000]\n",
      "loss: 1.553680  [  704/50000]\n",
      "loss: 1.353704  [ 1344/50000]\n",
      "loss: 1.298221  [ 1984/50000]\n",
      "loss: 1.638978  [ 2624/50000]\n",
      "loss: 1.480093  [ 3264/50000]\n",
      "loss: 1.370185  [ 3904/50000]\n",
      "loss: 1.390088  [ 4544/50000]\n",
      "loss: 1.706479  [ 5184/50000]\n",
      "loss: 1.335711  [ 5824/50000]\n",
      "loss: 1.326841  [ 6464/50000]\n",
      "loss: 1.580628  [ 7104/50000]\n",
      "loss: 1.802238  [ 7744/50000]\n",
      "loss: 1.424368  [ 8384/50000]\n",
      "loss: 1.483687  [ 9024/50000]\n",
      "loss: 1.440042  [ 9664/50000]\n",
      "loss: 1.317232  [10304/50000]\n",
      "loss: 1.685506  [10944/50000]\n",
      "loss: 1.525961  [11584/50000]\n",
      "loss: 1.473845  [12224/50000]\n",
      "loss: 1.586708  [12864/50000]\n",
      "loss: 1.764241  [13504/50000]\n",
      "loss: 1.464749  [14144/50000]\n",
      "loss: 1.448022  [14784/50000]\n",
      "loss: 1.366939  [15424/50000]\n",
      "loss: 1.474000  [16064/50000]\n",
      "loss: 1.535849  [16704/50000]\n",
      "loss: 1.577146  [17344/50000]\n",
      "loss: 1.155890  [17984/50000]\n",
      "loss: 1.597197  [18624/50000]\n",
      "loss: 1.381173  [19264/50000]\n",
      "loss: 1.688582  [19904/50000]\n",
      "loss: 1.474010  [20544/50000]\n",
      "loss: 1.497443  [21184/50000]\n",
      "loss: 1.222734  [21824/50000]\n",
      "loss: 1.420899  [22464/50000]\n",
      "loss: 1.491165  [23104/50000]\n",
      "loss: 1.754172  [23744/50000]\n",
      "loss: 1.533347  [24384/50000]\n",
      "loss: 1.358851  [25024/50000]\n",
      "loss: 1.499893  [25664/50000]\n",
      "loss: 1.468797  [26304/50000]\n",
      "loss: 1.352427  [26944/50000]\n",
      "loss: 1.318935  [27584/50000]\n",
      "loss: 1.756241  [28224/50000]\n",
      "loss: 1.516712  [28864/50000]\n",
      "loss: 1.712182  [29504/50000]\n",
      "loss: 1.656687  [30144/50000]\n",
      "loss: 1.730012  [30784/50000]\n",
      "loss: 1.433207  [31424/50000]\n",
      "loss: 1.703748  [32064/50000]\n",
      "loss: 1.641934  [32704/50000]\n",
      "loss: 1.467850  [33344/50000]\n",
      "loss: 1.584294  [33984/50000]\n",
      "loss: 1.542922  [34624/50000]\n",
      "loss: 1.379232  [35264/50000]\n",
      "loss: 1.333259  [35904/50000]\n",
      "loss: 1.424498  [36544/50000]\n",
      "loss: 1.453281  [37184/50000]\n",
      "loss: 1.450402  [37824/50000]\n",
      "loss: 1.331542  [38464/50000]\n",
      "loss: 1.437127  [39104/50000]\n",
      "loss: 1.493300  [39744/50000]\n",
      "loss: 1.391685  [40384/50000]\n",
      "loss: 1.432120  [41024/50000]\n",
      "loss: 1.577615  [41664/50000]\n",
      "loss: 1.208171  [42304/50000]\n",
      "loss: 1.698685  [42944/50000]\n",
      "loss: 1.449056  [43584/50000]\n",
      "loss: 1.266718  [44224/50000]\n",
      "loss: 1.335368  [44864/50000]\n",
      "loss: 1.359733  [45504/50000]\n",
      "loss: 1.349050  [46144/50000]\n",
      "loss: 1.496886  [46784/50000]\n",
      "loss: 1.476367  [47424/50000]\n",
      "loss: 1.635427  [48064/50000]\n",
      "loss: 1.585289  [48704/50000]\n",
      "loss: 1.471938  [49344/50000]\n",
      "loss: 1.496798  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.952426 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.421203  [   64/50000]\n",
      "loss: 1.327727  [  704/50000]\n",
      "loss: 1.509292  [ 1344/50000]\n",
      "loss: 1.493794  [ 1984/50000]\n",
      "loss: 1.364971  [ 2624/50000]\n",
      "loss: 1.448351  [ 3264/50000]\n",
      "loss: 1.254929  [ 3904/50000]\n",
      "loss: 1.596218  [ 4544/50000]\n",
      "loss: 1.534381  [ 5184/50000]\n",
      "loss: 1.523624  [ 5824/50000]\n",
      "loss: 1.614584  [ 6464/50000]\n",
      "loss: 1.795980  [ 7104/50000]\n",
      "loss: 1.456876  [ 7744/50000]\n",
      "loss: 1.400365  [ 8384/50000]\n",
      "loss: 1.620156  [ 9024/50000]\n",
      "loss: 1.620560  [ 9664/50000]\n",
      "loss: 1.421252  [10304/50000]\n",
      "loss: 1.573093  [10944/50000]\n",
      "loss: 1.416791  [11584/50000]\n",
      "loss: 1.370598  [12224/50000]\n",
      "loss: 1.369466  [12864/50000]\n",
      "loss: 1.481899  [13504/50000]\n",
      "loss: 1.504920  [14144/50000]\n",
      "loss: 1.372288  [14784/50000]\n",
      "loss: 1.592520  [15424/50000]\n",
      "loss: 1.547985  [16064/50000]\n",
      "loss: 1.539718  [16704/50000]\n",
      "loss: 1.283245  [17344/50000]\n",
      "loss: 1.524539  [17984/50000]\n",
      "loss: 1.414543  [18624/50000]\n",
      "loss: 1.529830  [19264/50000]\n",
      "loss: 1.284298  [19904/50000]\n",
      "loss: 1.483284  [20544/50000]\n",
      "loss: 1.448593  [21184/50000]\n",
      "loss: 1.332952  [21824/50000]\n",
      "loss: 1.295497  [22464/50000]\n",
      "loss: 1.503720  [23104/50000]\n",
      "loss: 1.438085  [23744/50000]\n",
      "loss: 1.507993  [24384/50000]\n",
      "loss: 1.224979  [25024/50000]\n",
      "loss: 1.553294  [25664/50000]\n",
      "loss: 1.408568  [26304/50000]\n",
      "loss: 1.569010  [26944/50000]\n",
      "loss: 1.632487  [27584/50000]\n",
      "loss: 1.556477  [28224/50000]\n",
      "loss: 1.526321  [28864/50000]\n",
      "loss: 1.753179  [29504/50000]\n",
      "loss: 1.471345  [30144/50000]\n",
      "loss: 1.802035  [30784/50000]\n",
      "loss: 1.441115  [31424/50000]\n",
      "loss: 1.361278  [32064/50000]\n",
      "loss: 1.424225  [32704/50000]\n",
      "loss: 1.527699  [33344/50000]\n",
      "loss: 1.297869  [33984/50000]\n",
      "loss: 1.576573  [34624/50000]\n",
      "loss: 1.380889  [35264/50000]\n",
      "loss: 1.621684  [35904/50000]\n",
      "loss: 1.674031  [36544/50000]\n",
      "loss: 1.579305  [37184/50000]\n",
      "loss: 1.403423  [37824/50000]\n",
      "loss: 1.372545  [38464/50000]\n",
      "loss: 1.893101  [39104/50000]\n",
      "loss: 1.700464  [39744/50000]\n",
      "loss: 1.446680  [40384/50000]\n",
      "loss: 1.467783  [41024/50000]\n",
      "loss: 1.368323  [41664/50000]\n",
      "loss: 1.376602  [42304/50000]\n",
      "loss: 1.320088  [42944/50000]\n",
      "loss: 1.584840  [43584/50000]\n",
      "loss: 1.266649  [44224/50000]\n",
      "loss: 1.528139  [44864/50000]\n",
      "loss: 1.823255  [45504/50000]\n",
      "loss: 1.562150  [46144/50000]\n",
      "loss: 1.437179  [46784/50000]\n",
      "loss: 1.524707  [47424/50000]\n",
      "loss: 1.542827  [48064/50000]\n",
      "loss: 1.475315  [48704/50000]\n",
      "loss: 1.451405  [49344/50000]\n",
      "loss: 1.495621  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.975440 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.593590  [   64/50000]\n",
      "loss: 1.479244  [  704/50000]\n",
      "loss: 1.434643  [ 1344/50000]\n",
      "loss: 1.496216  [ 1984/50000]\n",
      "loss: 1.125268  [ 2624/50000]\n",
      "loss: 1.155734  [ 3264/50000]\n",
      "loss: 1.398785  [ 3904/50000]\n",
      "loss: 1.688054  [ 4544/50000]\n",
      "loss: 1.389438  [ 5184/50000]\n",
      "loss: 1.569559  [ 5824/50000]\n",
      "loss: 1.319956  [ 6464/50000]\n",
      "loss: 1.685297  [ 7104/50000]\n",
      "loss: 1.426865  [ 7744/50000]\n",
      "loss: 1.499786  [ 8384/50000]\n",
      "loss: 1.432121  [ 9024/50000]\n",
      "loss: 1.561348  [ 9664/50000]\n",
      "loss: 1.285679  [10304/50000]\n",
      "loss: 1.360591  [10944/50000]\n",
      "loss: 1.400085  [11584/50000]\n",
      "loss: 1.358760  [12224/50000]\n",
      "loss: 1.583377  [12864/50000]\n",
      "loss: 1.471163  [13504/50000]\n",
      "loss: 1.331971  [14144/50000]\n",
      "loss: 1.165743  [14784/50000]\n",
      "loss: 1.705527  [15424/50000]\n",
      "loss: 1.495763  [16064/50000]\n",
      "loss: 1.726158  [16704/50000]\n",
      "loss: 1.592495  [17344/50000]\n",
      "loss: 1.600897  [17984/50000]\n",
      "loss: 1.518121  [18624/50000]\n",
      "loss: 1.408451  [19264/50000]\n",
      "loss: 1.354222  [19904/50000]\n",
      "loss: 1.430576  [20544/50000]\n",
      "loss: 1.308805  [21184/50000]\n",
      "loss: 1.502065  [21824/50000]\n",
      "loss: 1.473426  [22464/50000]\n",
      "loss: 1.349201  [23104/50000]\n",
      "loss: 1.453038  [23744/50000]\n",
      "loss: 1.228468  [24384/50000]\n",
      "loss: 1.490148  [25024/50000]\n",
      "loss: 1.400237  [25664/50000]\n",
      "loss: 1.480455  [26304/50000]\n",
      "loss: 1.557582  [26944/50000]\n",
      "loss: 1.322980  [27584/50000]\n",
      "loss: 1.594811  [28224/50000]\n",
      "loss: 1.579257  [28864/50000]\n",
      "loss: 1.487225  [29504/50000]\n",
      "loss: 1.532242  [30144/50000]\n",
      "loss: 1.458949  [30784/50000]\n",
      "loss: 1.317936  [31424/50000]\n",
      "loss: 1.736585  [32064/50000]\n",
      "loss: 1.496181  [32704/50000]\n",
      "loss: 1.611243  [33344/50000]\n",
      "loss: 1.387338  [33984/50000]\n",
      "loss: 1.337870  [34624/50000]\n",
      "loss: 1.588914  [35264/50000]\n",
      "loss: 1.487715  [35904/50000]\n",
      "loss: 1.210042  [36544/50000]\n",
      "loss: 1.421475  [37184/50000]\n",
      "loss: 1.252209  [37824/50000]\n",
      "loss: 1.555923  [38464/50000]\n",
      "loss: 1.657001  [39104/50000]\n",
      "loss: 1.260210  [39744/50000]\n",
      "loss: 1.449783  [40384/50000]\n",
      "loss: 1.719480  [41024/50000]\n",
      "loss: 1.530635  [41664/50000]\n",
      "loss: 1.536389  [42304/50000]\n",
      "loss: 1.485928  [42944/50000]\n",
      "loss: 1.135578  [43584/50000]\n",
      "loss: 1.341612  [44224/50000]\n",
      "loss: 1.509725  [44864/50000]\n",
      "loss: 1.386458  [45504/50000]\n",
      "loss: 1.444233  [46144/50000]\n",
      "loss: 1.458583  [46784/50000]\n",
      "loss: 1.516734  [47424/50000]\n",
      "loss: 1.686106  [48064/50000]\n",
      "loss: 1.510082  [48704/50000]\n",
      "loss: 1.385121  [49344/50000]\n",
      "loss: 1.520470  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.919445 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.309200  [   64/50000]\n",
      "loss: 1.336622  [  704/50000]\n",
      "loss: 1.695596  [ 1344/50000]\n",
      "loss: 1.295380  [ 1984/50000]\n",
      "loss: 1.501842  [ 2624/50000]\n",
      "loss: 1.175575  [ 3264/50000]\n",
      "loss: 1.471781  [ 3904/50000]\n",
      "loss: 1.428946  [ 4544/50000]\n",
      "loss: 1.376959  [ 5184/50000]\n",
      "loss: 1.643912  [ 5824/50000]\n",
      "loss: 1.417153  [ 6464/50000]\n",
      "loss: 1.617805  [ 7104/50000]\n",
      "loss: 1.537442  [ 7744/50000]\n",
      "loss: 1.248356  [ 8384/50000]\n",
      "loss: 1.482246  [ 9024/50000]\n",
      "loss: 1.314963  [ 9664/50000]\n",
      "loss: 1.511955  [10304/50000]\n",
      "loss: 1.192135  [10944/50000]\n",
      "loss: 1.504670  [11584/50000]\n",
      "loss: 1.705059  [12224/50000]\n",
      "loss: 1.393107  [12864/50000]\n",
      "loss: 1.418848  [13504/50000]\n",
      "loss: 1.377556  [14144/50000]\n",
      "loss: 1.238710  [14784/50000]\n",
      "loss: 1.374267  [15424/50000]\n",
      "loss: 1.301206  [16064/50000]\n",
      "loss: 1.562894  [16704/50000]\n",
      "loss: 1.434235  [17344/50000]\n",
      "loss: 1.390648  [17984/50000]\n",
      "loss: 1.597928  [18624/50000]\n",
      "loss: 1.536207  [19264/50000]\n",
      "loss: 1.393497  [19904/50000]\n",
      "loss: 1.394544  [20544/50000]\n",
      "loss: 1.430135  [21184/50000]\n",
      "loss: 1.615744  [21824/50000]\n",
      "loss: 1.418456  [22464/50000]\n",
      "loss: 1.477944  [23104/50000]\n",
      "loss: 1.315417  [23744/50000]\n",
      "loss: 1.298674  [24384/50000]\n",
      "loss: 1.394495  [25024/50000]\n",
      "loss: 1.256369  [25664/50000]\n",
      "loss: 1.700409  [26304/50000]\n",
      "loss: 1.505108  [26944/50000]\n",
      "loss: 1.443642  [27584/50000]\n",
      "loss: 1.584338  [28224/50000]\n",
      "loss: 1.307291  [28864/50000]\n",
      "loss: 1.490340  [29504/50000]\n",
      "loss: 1.472312  [30144/50000]\n",
      "loss: 1.837668  [30784/50000]\n",
      "loss: 1.345068  [31424/50000]\n",
      "loss: 1.676596  [32064/50000]\n",
      "loss: 1.094137  [32704/50000]\n",
      "loss: 1.359593  [33344/50000]\n",
      "loss: 1.609024  [33984/50000]\n",
      "loss: 1.365297  [34624/50000]\n",
      "loss: 1.402932  [35264/50000]\n",
      "loss: 1.473326  [35904/50000]\n",
      "loss: 1.472143  [36544/50000]\n",
      "loss: 1.741500  [37184/50000]\n",
      "loss: 1.491877  [37824/50000]\n",
      "loss: 1.562814  [38464/50000]\n",
      "loss: 1.606119  [39104/50000]\n",
      "loss: 1.476955  [39744/50000]\n",
      "loss: 1.517127  [40384/50000]\n",
      "loss: 1.340525  [41024/50000]\n",
      "loss: 1.338686  [41664/50000]\n",
      "loss: 1.415991  [42304/50000]\n",
      "loss: 1.524714  [42944/50000]\n",
      "loss: 1.635081  [43584/50000]\n",
      "loss: 1.417406  [44224/50000]\n",
      "loss: 1.535015  [44864/50000]\n",
      "loss: 1.526206  [45504/50000]\n",
      "loss: 1.377977  [46144/50000]\n",
      "loss: 1.403560  [46784/50000]\n",
      "loss: 1.567337  [47424/50000]\n",
      "loss: 1.347694  [48064/50000]\n",
      "loss: 1.409923  [48704/50000]\n",
      "loss: 1.435826  [49344/50000]\n",
      "loss: 1.424006  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.885975 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.560403  [   64/50000]\n",
      "loss: 1.621184  [  704/50000]\n",
      "loss: 1.431755  [ 1344/50000]\n",
      "loss: 1.711651  [ 1984/50000]\n",
      "loss: 1.430253  [ 2624/50000]\n",
      "loss: 1.379471  [ 3264/50000]\n",
      "loss: 1.770436  [ 3904/50000]\n",
      "loss: 1.433620  [ 4544/50000]\n",
      "loss: 1.532211  [ 5184/50000]\n",
      "loss: 1.341807  [ 5824/50000]\n",
      "loss: 1.308324  [ 6464/50000]\n",
      "loss: 1.545191  [ 7104/50000]\n",
      "loss: 1.520208  [ 7744/50000]\n",
      "loss: 1.433326  [ 8384/50000]\n",
      "loss: 1.461644  [ 9024/50000]\n",
      "loss: 1.348261  [ 9664/50000]\n",
      "loss: 1.311827  [10304/50000]\n",
      "loss: 1.299008  [10944/50000]\n",
      "loss: 1.327790  [11584/50000]\n",
      "loss: 1.510591  [12224/50000]\n",
      "loss: 1.470879  [12864/50000]\n",
      "loss: 1.569431  [13504/50000]\n",
      "loss: 1.493297  [14144/50000]\n",
      "loss: 1.279127  [14784/50000]\n",
      "loss: 1.335834  [15424/50000]\n",
      "loss: 1.477221  [16064/50000]\n",
      "loss: 1.350959  [16704/50000]\n",
      "loss: 1.527869  [17344/50000]\n",
      "loss: 1.207223  [17984/50000]\n",
      "loss: 1.386380  [18624/50000]\n",
      "loss: 1.293291  [19264/50000]\n",
      "loss: 1.543849  [19904/50000]\n",
      "loss: 1.418264  [20544/50000]\n",
      "loss: 1.468979  [21184/50000]\n",
      "loss: 1.270842  [21824/50000]\n",
      "loss: 1.559963  [22464/50000]\n",
      "loss: 1.309841  [23104/50000]\n",
      "loss: 1.357799  [23744/50000]\n",
      "loss: 1.229840  [24384/50000]\n",
      "loss: 1.277678  [25024/50000]\n",
      "loss: 1.278361  [25664/50000]\n",
      "loss: 1.509559  [26304/50000]\n",
      "loss: 1.538538  [26944/50000]\n",
      "loss: 1.532647  [27584/50000]\n",
      "loss: 1.605598  [28224/50000]\n",
      "loss: 1.538801  [28864/50000]\n",
      "loss: 1.365759  [29504/50000]\n",
      "loss: 1.475833  [30144/50000]\n",
      "loss: 1.376684  [30784/50000]\n",
      "loss: 1.343806  [31424/50000]\n",
      "loss: 1.278369  [32064/50000]\n",
      "loss: 1.359366  [32704/50000]\n",
      "loss: 1.588942  [33344/50000]\n",
      "loss: 1.623258  [33984/50000]\n",
      "loss: 1.421590  [34624/50000]\n",
      "loss: 1.583876  [35264/50000]\n",
      "loss: 1.377848  [35904/50000]\n",
      "loss: 1.496755  [36544/50000]\n",
      "loss: 1.348258  [37184/50000]\n",
      "loss: 1.482924  [37824/50000]\n",
      "loss: 1.425363  [38464/50000]\n",
      "loss: 1.581537  [39104/50000]\n",
      "loss: 1.352617  [39744/50000]\n",
      "loss: 1.528592  [40384/50000]\n",
      "loss: 1.345946  [41024/50000]\n",
      "loss: 1.344846  [41664/50000]\n",
      "loss: 1.316607  [42304/50000]\n",
      "loss: 1.492362  [42944/50000]\n",
      "loss: 1.743604  [43584/50000]\n",
      "loss: 1.522047  [44224/50000]\n",
      "loss: 1.485625  [44864/50000]\n",
      "loss: 1.420403  [45504/50000]\n",
      "loss: 1.560570  [46144/50000]\n",
      "loss: 1.304370  [46784/50000]\n",
      "loss: 1.594325  [47424/50000]\n",
      "loss: 1.566380  [48064/50000]\n",
      "loss: 1.414765  [48704/50000]\n",
      "loss: 1.279551  [49344/50000]\n",
      "loss: 1.449818  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.878560 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.669739  [   64/50000]\n",
      "loss: 1.435632  [  704/50000]\n",
      "loss: 1.388502  [ 1344/50000]\n",
      "loss: 1.315586  [ 1984/50000]\n",
      "loss: 1.460002  [ 2624/50000]\n",
      "loss: 1.373209  [ 3264/50000]\n",
      "loss: 1.210154  [ 3904/50000]\n",
      "loss: 1.334222  [ 4544/50000]\n",
      "loss: 1.463087  [ 5184/50000]\n",
      "loss: 1.338863  [ 5824/50000]\n",
      "loss: 1.396286  [ 6464/50000]\n",
      "loss: 1.138894  [ 7104/50000]\n",
      "loss: 1.240254  [ 7744/50000]\n",
      "loss: 1.515631  [ 8384/50000]\n",
      "loss: 1.719949  [ 9024/50000]\n",
      "loss: 1.412975  [ 9664/50000]\n",
      "loss: 1.354963  [10304/50000]\n",
      "loss: 1.200186  [10944/50000]\n",
      "loss: 1.469890  [11584/50000]\n",
      "loss: 1.367285  [12224/50000]\n",
      "loss: 1.352062  [12864/50000]\n",
      "loss: 1.366842  [13504/50000]\n",
      "loss: 1.253762  [14144/50000]\n",
      "loss: 1.356717  [14784/50000]\n",
      "loss: 1.434080  [15424/50000]\n",
      "loss: 1.661512  [16064/50000]\n",
      "loss: 1.349264  [16704/50000]\n",
      "loss: 1.292896  [17344/50000]\n",
      "loss: 1.286515  [17984/50000]\n",
      "loss: 1.283412  [18624/50000]\n",
      "loss: 1.069816  [19264/50000]\n",
      "loss: 1.428611  [19904/50000]\n",
      "loss: 1.337536  [20544/50000]\n",
      "loss: 1.694785  [21184/50000]\n",
      "loss: 1.368843  [21824/50000]\n",
      "loss: 1.033576  [22464/50000]\n",
      "loss: 1.321365  [23104/50000]\n",
      "loss: 1.454839  [23744/50000]\n",
      "loss: 1.548574  [24384/50000]\n",
      "loss: 1.228211  [25024/50000]\n",
      "loss: 1.379187  [25664/50000]\n",
      "loss: 1.380757  [26304/50000]\n",
      "loss: 1.499089  [26944/50000]\n",
      "loss: 1.491841  [27584/50000]\n",
      "loss: 1.617005  [28224/50000]\n",
      "loss: 1.280023  [28864/50000]\n",
      "loss: 1.430361  [29504/50000]\n",
      "loss: 1.407412  [30144/50000]\n",
      "loss: 1.485145  [30784/50000]\n",
      "loss: 1.897688  [31424/50000]\n",
      "loss: 1.579425  [32064/50000]\n",
      "loss: 1.433121  [32704/50000]\n",
      "loss: 1.643248  [33344/50000]\n",
      "loss: 1.343466  [33984/50000]\n",
      "loss: 1.458718  [34624/50000]\n",
      "loss: 1.362337  [35264/50000]\n",
      "loss: 1.476653  [35904/50000]\n",
      "loss: 1.232533  [36544/50000]\n",
      "loss: 1.369117  [37184/50000]\n",
      "loss: 1.360433  [37824/50000]\n",
      "loss: 1.376969  [38464/50000]\n",
      "loss: 1.566156  [39104/50000]\n",
      "loss: 1.251775  [39744/50000]\n",
      "loss: 1.691978  [40384/50000]\n",
      "loss: 1.601042  [41024/50000]\n",
      "loss: 1.360143  [41664/50000]\n",
      "loss: 1.206522  [42304/50000]\n",
      "loss: 1.317509  [42944/50000]\n",
      "loss: 1.349233  [43584/50000]\n",
      "loss: 1.319743  [44224/50000]\n",
      "loss: 1.519023  [44864/50000]\n",
      "loss: 1.655220  [45504/50000]\n",
      "loss: 1.559505  [46144/50000]\n",
      "loss: 1.343103  [46784/50000]\n",
      "loss: 1.468199  [47424/50000]\n",
      "loss: 1.731448  [48064/50000]\n",
      "loss: 1.653858  [48704/50000]\n",
      "loss: 1.310503  [49344/50000]\n",
      "loss: 1.218723  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.870532 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.533051  [   64/50000]\n",
      "loss: 1.406224  [  704/50000]\n",
      "loss: 1.529278  [ 1344/50000]\n",
      "loss: 1.336685  [ 1984/50000]\n",
      "loss: 1.364140  [ 2624/50000]\n",
      "loss: 1.421306  [ 3264/50000]\n",
      "loss: 1.273313  [ 3904/50000]\n",
      "loss: 1.687719  [ 4544/50000]\n",
      "loss: 1.160142  [ 5184/50000]\n",
      "loss: 1.419490  [ 5824/50000]\n",
      "loss: 1.199312  [ 6464/50000]\n",
      "loss: 1.557900  [ 7104/50000]\n",
      "loss: 1.382329  [ 7744/50000]\n",
      "loss: 1.528386  [ 8384/50000]\n",
      "loss: 1.577094  [ 9024/50000]\n",
      "loss: 1.543166  [ 9664/50000]\n",
      "loss: 1.332158  [10304/50000]\n",
      "loss: 1.322631  [10944/50000]\n",
      "loss: 1.454132  [11584/50000]\n",
      "loss: 1.326380  [12224/50000]\n",
      "loss: 1.565547  [12864/50000]\n",
      "loss: 1.529731  [13504/50000]\n",
      "loss: 1.491494  [14144/50000]\n",
      "loss: 1.338476  [14784/50000]\n",
      "loss: 1.452472  [15424/50000]\n",
      "loss: 1.455027  [16064/50000]\n",
      "loss: 1.377820  [16704/50000]\n",
      "loss: 1.726107  [17344/50000]\n",
      "loss: 1.462884  [17984/50000]\n",
      "loss: 1.445381  [18624/50000]\n",
      "loss: 1.251218  [19264/50000]\n",
      "loss: 1.286527  [19904/50000]\n",
      "loss: 1.409713  [20544/50000]\n",
      "loss: 1.506954  [21184/50000]\n",
      "loss: 1.539289  [21824/50000]\n",
      "loss: 1.406095  [22464/50000]\n",
      "loss: 1.395823  [23104/50000]\n",
      "loss: 1.557477  [23744/50000]\n",
      "loss: 1.497158  [24384/50000]\n",
      "loss: 1.318730  [25024/50000]\n",
      "loss: 1.348161  [25664/50000]\n",
      "loss: 1.586684  [26304/50000]\n",
      "loss: 1.171947  [26944/50000]\n",
      "loss: 1.643046  [27584/50000]\n",
      "loss: 1.423459  [28224/50000]\n",
      "loss: 1.168612  [28864/50000]\n",
      "loss: 1.218077  [29504/50000]\n",
      "loss: 1.525957  [30144/50000]\n",
      "loss: 1.520097  [30784/50000]\n",
      "loss: 1.513587  [31424/50000]\n",
      "loss: 1.332911  [32064/50000]\n",
      "loss: 1.403707  [32704/50000]\n",
      "loss: 1.400050  [33344/50000]\n",
      "loss: 1.495945  [33984/50000]\n",
      "loss: 1.514012  [34624/50000]\n",
      "loss: 1.367962  [35264/50000]\n",
      "loss: 1.189527  [35904/50000]\n",
      "loss: 1.488739  [36544/50000]\n",
      "loss: 1.474255  [37184/50000]\n",
      "loss: 1.272920  [37824/50000]\n",
      "loss: 1.622200  [38464/50000]\n",
      "loss: 1.530324  [39104/50000]\n",
      "loss: 1.291750  [39744/50000]\n",
      "loss: 1.377044  [40384/50000]\n",
      "loss: 1.162795  [41024/50000]\n",
      "loss: 1.418669  [41664/50000]\n",
      "loss: 1.368941  [42304/50000]\n",
      "loss: 1.444098  [42944/50000]\n",
      "loss: 1.687013  [43584/50000]\n",
      "loss: 1.295613  [44224/50000]\n",
      "loss: 1.470964  [44864/50000]\n",
      "loss: 1.677557  [45504/50000]\n",
      "loss: 1.294630  [46144/50000]\n",
      "loss: 1.284686  [46784/50000]\n",
      "loss: 1.106322  [47424/50000]\n",
      "loss: 1.499129  [48064/50000]\n",
      "loss: 1.287086  [48704/50000]\n",
      "loss: 1.572224  [49344/50000]\n",
      "loss: 1.332870  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.869753 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.239215  [   64/50000]\n",
      "loss: 1.450497  [  704/50000]\n",
      "loss: 1.298466  [ 1344/50000]\n",
      "loss: 1.523039  [ 1984/50000]\n",
      "loss: 1.594683  [ 2624/50000]\n",
      "loss: 1.422193  [ 3264/50000]\n",
      "loss: 1.506154  [ 3904/50000]\n",
      "loss: 1.549529  [ 4544/50000]\n",
      "loss: 1.140243  [ 5184/50000]\n",
      "loss: 1.519807  [ 5824/50000]\n",
      "loss: 0.927257  [ 6464/50000]\n",
      "loss: 1.406958  [ 7104/50000]\n",
      "loss: 1.415227  [ 7744/50000]\n",
      "loss: 1.414952  [ 8384/50000]\n",
      "loss: 1.416608  [ 9024/50000]\n",
      "loss: 1.519904  [ 9664/50000]\n",
      "loss: 1.314222  [10304/50000]\n",
      "loss: 1.411487  [10944/50000]\n",
      "loss: 1.429168  [11584/50000]\n",
      "loss: 1.271512  [12224/50000]\n",
      "loss: 1.291749  [12864/50000]\n",
      "loss: 1.478719  [13504/50000]\n",
      "loss: 1.259354  [14144/50000]\n",
      "loss: 1.472083  [14784/50000]\n",
      "loss: 1.208539  [15424/50000]\n",
      "loss: 1.443363  [16064/50000]\n",
      "loss: 1.393071  [16704/50000]\n",
      "loss: 1.320756  [17344/50000]\n",
      "loss: 1.518031  [17984/50000]\n",
      "loss: 1.396631  [18624/50000]\n",
      "loss: 1.473144  [19264/50000]\n",
      "loss: 1.187494  [19904/50000]\n",
      "loss: 1.269918  [20544/50000]\n",
      "loss: 1.458351  [21184/50000]\n",
      "loss: 1.633484  [21824/50000]\n",
      "loss: 1.244966  [22464/50000]\n",
      "loss: 1.434110  [23104/50000]\n",
      "loss: 1.368243  [23744/50000]\n",
      "loss: 1.509799  [24384/50000]\n",
      "loss: 1.357736  [25024/50000]\n",
      "loss: 1.394762  [25664/50000]\n",
      "loss: 1.509378  [26304/50000]\n",
      "loss: 1.421309  [26944/50000]\n",
      "loss: 1.529040  [27584/50000]\n",
      "loss: 1.282562  [28224/50000]\n",
      "loss: 1.614395  [28864/50000]\n",
      "loss: 1.541754  [29504/50000]\n",
      "loss: 1.239013  [30144/50000]\n",
      "loss: 1.269292  [30784/50000]\n",
      "loss: 1.513885  [31424/50000]\n",
      "loss: 1.542800  [32064/50000]\n",
      "loss: 1.351149  [32704/50000]\n",
      "loss: 1.451627  [33344/50000]\n",
      "loss: 1.431082  [33984/50000]\n",
      "loss: 1.207446  [34624/50000]\n",
      "loss: 1.491900  [35264/50000]\n",
      "loss: 1.254326  [35904/50000]\n",
      "loss: 1.356457  [36544/50000]\n",
      "loss: 1.313583  [37184/50000]\n",
      "loss: 1.613033  [37824/50000]\n",
      "loss: 1.269557  [38464/50000]\n",
      "loss: 1.374060  [39104/50000]\n",
      "loss: 1.387151  [39744/50000]\n",
      "loss: 1.512813  [40384/50000]\n",
      "loss: 1.598304  [41024/50000]\n",
      "loss: 1.550882  [41664/50000]\n",
      "loss: 1.350276  [42304/50000]\n",
      "loss: 1.209103  [42944/50000]\n",
      "loss: 1.469756  [43584/50000]\n",
      "loss: 1.314094  [44224/50000]\n",
      "loss: 1.491686  [44864/50000]\n",
      "loss: 1.536987  [45504/50000]\n",
      "loss: 1.316152  [46144/50000]\n",
      "loss: 1.304096  [46784/50000]\n",
      "loss: 1.491783  [47424/50000]\n",
      "loss: 1.675674  [48064/50000]\n",
      "loss: 1.224833  [48704/50000]\n",
      "loss: 1.432707  [49344/50000]\n",
      "loss: 1.789551  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.857836 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.281397  [   64/50000]\n",
      "loss: 1.196707  [  704/50000]\n",
      "loss: 1.271593  [ 1344/50000]\n",
      "loss: 1.434778  [ 1984/50000]\n",
      "loss: 1.484493  [ 2624/50000]\n",
      "loss: 1.245919  [ 3264/50000]\n",
      "loss: 1.437246  [ 3904/50000]\n",
      "loss: 1.376127  [ 4544/50000]\n",
      "loss: 1.333250  [ 5184/50000]\n",
      "loss: 1.473430  [ 5824/50000]\n",
      "loss: 1.564435  [ 6464/50000]\n",
      "loss: 1.686653  [ 7104/50000]\n",
      "loss: 1.552791  [ 7744/50000]\n",
      "loss: 1.395364  [ 8384/50000]\n",
      "loss: 1.384228  [ 9024/50000]\n",
      "loss: 1.519004  [ 9664/50000]\n",
      "loss: 1.542262  [10304/50000]\n",
      "loss: 1.244828  [10944/50000]\n",
      "loss: 1.649326  [11584/50000]\n",
      "loss: 1.398097  [12224/50000]\n",
      "loss: 1.504931  [12864/50000]\n",
      "loss: 1.549131  [13504/50000]\n",
      "loss: 1.510070  [14144/50000]\n",
      "loss: 1.663332  [14784/50000]\n",
      "loss: 1.593095  [15424/50000]\n",
      "loss: 1.539382  [16064/50000]\n",
      "loss: 1.513366  [16704/50000]\n",
      "loss: 1.434623  [17344/50000]\n",
      "loss: 1.355189  [17984/50000]\n",
      "loss: 1.738055  [18624/50000]\n",
      "loss: 1.231115  [19264/50000]\n",
      "loss: 1.292791  [19904/50000]\n",
      "loss: 1.386169  [20544/50000]\n",
      "loss: 1.479628  [21184/50000]\n",
      "loss: 1.387755  [21824/50000]\n",
      "loss: 1.471812  [22464/50000]\n",
      "loss: 1.693512  [23104/50000]\n",
      "loss: 1.439411  [23744/50000]\n",
      "loss: 1.448936  [24384/50000]\n",
      "loss: 1.556540  [25024/50000]\n",
      "loss: 1.413237  [25664/50000]\n",
      "loss: 1.484338  [26304/50000]\n",
      "loss: 1.165527  [26944/50000]\n",
      "loss: 1.489760  [27584/50000]\n",
      "loss: 1.488255  [28224/50000]\n",
      "loss: 1.459768  [28864/50000]\n",
      "loss: 1.635875  [29504/50000]\n",
      "loss: 1.314570  [30144/50000]\n",
      "loss: 1.115345  [30784/50000]\n",
      "loss: 1.335392  [31424/50000]\n",
      "loss: 1.372995  [32064/50000]\n",
      "loss: 1.025336  [32704/50000]\n",
      "loss: 1.425407  [33344/50000]\n",
      "loss: 1.474182  [33984/50000]\n",
      "loss: 1.486495  [34624/50000]\n",
      "loss: 1.516182  [35264/50000]\n",
      "loss: 1.220782  [35904/50000]\n",
      "loss: 1.436287  [36544/50000]\n",
      "loss: 1.357743  [37184/50000]\n",
      "loss: 1.247489  [37824/50000]\n",
      "loss: 1.568581  [38464/50000]\n",
      "loss: 1.110979  [39104/50000]\n",
      "loss: 1.326181  [39744/50000]\n",
      "loss: 1.394104  [40384/50000]\n",
      "loss: 1.349550  [41024/50000]\n",
      "loss: 1.678461  [41664/50000]\n",
      "loss: 1.360214  [42304/50000]\n",
      "loss: 1.336024  [42944/50000]\n",
      "loss: 1.382981  [43584/50000]\n",
      "loss: 1.349447  [44224/50000]\n",
      "loss: 1.205237  [44864/50000]\n",
      "loss: 1.542062  [45504/50000]\n",
      "loss: 1.439641  [46144/50000]\n",
      "loss: 1.362330  [46784/50000]\n",
      "loss: 1.496192  [47424/50000]\n",
      "loss: 1.328123  [48064/50000]\n",
      "loss: 1.578605  [48704/50000]\n",
      "loss: 1.183158  [49344/50000]\n",
      "loss: 1.575296  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.886021 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.509548  [   64/50000]\n",
      "loss: 1.331316  [  704/50000]\n",
      "loss: 1.370218  [ 1344/50000]\n",
      "loss: 1.191721  [ 1984/50000]\n",
      "loss: 1.217857  [ 2624/50000]\n",
      "loss: 1.446466  [ 3264/50000]\n",
      "loss: 1.311390  [ 3904/50000]\n",
      "loss: 1.478584  [ 4544/50000]\n",
      "loss: 1.090377  [ 5184/50000]\n",
      "loss: 1.592927  [ 5824/50000]\n",
      "loss: 1.391439  [ 6464/50000]\n",
      "loss: 1.150610  [ 7104/50000]\n",
      "loss: 1.540069  [ 7744/50000]\n",
      "loss: 1.461511  [ 8384/50000]\n",
      "loss: 1.399087  [ 9024/50000]\n",
      "loss: 1.491978  [ 9664/50000]\n",
      "loss: 1.282558  [10304/50000]\n",
      "loss: 1.154656  [10944/50000]\n",
      "loss: 1.376204  [11584/50000]\n",
      "loss: 1.065167  [12224/50000]\n",
      "loss: 1.615145  [12864/50000]\n",
      "loss: 1.329804  [13504/50000]\n",
      "loss: 1.387679  [14144/50000]\n",
      "loss: 1.233141  [14784/50000]\n",
      "loss: 1.395678  [15424/50000]\n",
      "loss: 1.345097  [16064/50000]\n",
      "loss: 1.255473  [16704/50000]\n",
      "loss: 1.507589  [17344/50000]\n",
      "loss: 1.442472  [17984/50000]\n",
      "loss: 1.548184  [18624/50000]\n",
      "loss: 1.361629  [19264/50000]\n",
      "loss: 1.350209  [19904/50000]\n",
      "loss: 1.442426  [20544/50000]\n",
      "loss: 1.268750  [21184/50000]\n",
      "loss: 1.429308  [21824/50000]\n",
      "loss: 1.413013  [22464/50000]\n",
      "loss: 1.201899  [23104/50000]\n",
      "loss: 1.575661  [23744/50000]\n",
      "loss: 1.533554  [24384/50000]\n",
      "loss: 1.204631  [25024/50000]\n",
      "loss: 1.222703  [25664/50000]\n",
      "loss: 1.315693  [26304/50000]\n",
      "loss: 1.230038  [26944/50000]\n",
      "loss: 1.331353  [27584/50000]\n",
      "loss: 1.476058  [28224/50000]\n",
      "loss: 1.299212  [28864/50000]\n",
      "loss: 1.333900  [29504/50000]\n",
      "loss: 1.555051  [30144/50000]\n",
      "loss: 1.359298  [30784/50000]\n",
      "loss: 1.347319  [31424/50000]\n",
      "loss: 1.504597  [32064/50000]\n",
      "loss: 1.354495  [32704/50000]\n",
      "loss: 1.347520  [33344/50000]\n",
      "loss: 1.379011  [33984/50000]\n",
      "loss: 1.175587  [34624/50000]\n",
      "loss: 1.519961  [35264/50000]\n",
      "loss: 1.437987  [35904/50000]\n",
      "loss: 1.437890  [36544/50000]\n",
      "loss: 1.480561  [37184/50000]\n",
      "loss: 1.325256  [37824/50000]\n",
      "loss: 1.661402  [38464/50000]\n",
      "loss: 1.265544  [39104/50000]\n",
      "loss: 1.497896  [39744/50000]\n",
      "loss: 1.116844  [40384/50000]\n",
      "loss: 1.167050  [41024/50000]\n",
      "loss: 1.514267  [41664/50000]\n",
      "loss: 1.185406  [42304/50000]\n",
      "loss: 1.491015  [42944/50000]\n",
      "loss: 1.461070  [43584/50000]\n",
      "loss: 1.320152  [44224/50000]\n",
      "loss: 1.386448  [44864/50000]\n",
      "loss: 1.351898  [45504/50000]\n",
      "loss: 1.440304  [46144/50000]\n",
      "loss: 1.230805  [46784/50000]\n",
      "loss: 1.485078  [47424/50000]\n",
      "loss: 1.294326  [48064/50000]\n",
      "loss: 1.261049  [48704/50000]\n",
      "loss: 1.093347  [49344/50000]\n",
      "loss: 1.399364  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.825697 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.566255  [   64/50000]\n",
      "loss: 1.393221  [  704/50000]\n",
      "loss: 1.300065  [ 1344/50000]\n",
      "loss: 1.385863  [ 1984/50000]\n",
      "loss: 1.444651  [ 2624/50000]\n",
      "loss: 1.529856  [ 3264/50000]\n",
      "loss: 1.288248  [ 3904/50000]\n",
      "loss: 1.479855  [ 4544/50000]\n",
      "loss: 1.344102  [ 5184/50000]\n",
      "loss: 1.311731  [ 5824/50000]\n",
      "loss: 1.394814  [ 6464/50000]\n",
      "loss: 1.269246  [ 7104/50000]\n",
      "loss: 1.433857  [ 7744/50000]\n",
      "loss: 1.423544  [ 8384/50000]\n",
      "loss: 1.580255  [ 9024/50000]\n",
      "loss: 1.424451  [ 9664/50000]\n",
      "loss: 1.471326  [10304/50000]\n",
      "loss: 1.221957  [10944/50000]\n",
      "loss: 1.269987  [11584/50000]\n",
      "loss: 1.588371  [12224/50000]\n",
      "loss: 1.322719  [12864/50000]\n",
      "loss: 1.472314  [13504/50000]\n",
      "loss: 1.408668  [14144/50000]\n",
      "loss: 1.353290  [14784/50000]\n",
      "loss: 1.268790  [15424/50000]\n",
      "loss: 1.449372  [16064/50000]\n",
      "loss: 1.342024  [16704/50000]\n",
      "loss: 1.389809  [17344/50000]\n",
      "loss: 1.437899  [17984/50000]\n",
      "loss: 1.335270  [18624/50000]\n",
      "loss: 1.309514  [19264/50000]\n",
      "loss: 1.230249  [19904/50000]\n",
      "loss: 1.286692  [20544/50000]\n",
      "loss: 1.236912  [21184/50000]\n",
      "loss: 1.630318  [21824/50000]\n",
      "loss: 1.335024  [22464/50000]\n",
      "loss: 1.412652  [23104/50000]\n",
      "loss: 1.542377  [23744/50000]\n",
      "loss: 1.527667  [24384/50000]\n",
      "loss: 1.542504  [25024/50000]\n",
      "loss: 1.387446  [25664/50000]\n",
      "loss: 1.246796  [26304/50000]\n",
      "loss: 1.460905  [26944/50000]\n",
      "loss: 1.295114  [27584/50000]\n",
      "loss: 1.396490  [28224/50000]\n",
      "loss: 1.365486  [28864/50000]\n",
      "loss: 1.566246  [29504/50000]\n",
      "loss: 1.559805  [30144/50000]\n",
      "loss: 1.250869  [30784/50000]\n",
      "loss: 1.247313  [31424/50000]\n",
      "loss: 1.443028  [32064/50000]\n",
      "loss: 1.475151  [32704/50000]\n",
      "loss: 1.389827  [33344/50000]\n",
      "loss: 1.580835  [33984/50000]\n",
      "loss: 1.477813  [34624/50000]\n",
      "loss: 1.205851  [35264/50000]\n",
      "loss: 1.003483  [35904/50000]\n",
      "loss: 1.429171  [36544/50000]\n",
      "loss: 1.420431  [37184/50000]\n",
      "loss: 1.372141  [37824/50000]\n",
      "loss: 1.571542  [38464/50000]\n",
      "loss: 1.352462  [39104/50000]\n",
      "loss: 1.471013  [39744/50000]\n",
      "loss: 1.315916  [40384/50000]\n",
      "loss: 1.298721  [41024/50000]\n",
      "loss: 1.361225  [41664/50000]\n",
      "loss: 1.314260  [42304/50000]\n",
      "loss: 1.347520  [42944/50000]\n",
      "loss: 1.135133  [43584/50000]\n",
      "loss: 1.313758  [44224/50000]\n",
      "loss: 1.179554  [44864/50000]\n",
      "loss: 1.480518  [45504/50000]\n",
      "loss: 1.492260  [46144/50000]\n",
      "loss: 1.371736  [46784/50000]\n",
      "loss: 1.503895  [47424/50000]\n",
      "loss: 1.394940  [48064/50000]\n",
      "loss: 1.469925  [48704/50000]\n",
      "loss: 1.240531  [49344/50000]\n",
      "loss: 1.467372  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.859887 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.387115  [   64/50000]\n",
      "loss: 1.503771  [  704/50000]\n",
      "loss: 1.657915  [ 1344/50000]\n",
      "loss: 1.481737  [ 1984/50000]\n",
      "loss: 1.265322  [ 2624/50000]\n",
      "loss: 1.773694  [ 3264/50000]\n",
      "loss: 1.298126  [ 3904/50000]\n",
      "loss: 1.346252  [ 4544/50000]\n",
      "loss: 1.351667  [ 5184/50000]\n",
      "loss: 1.454706  [ 5824/50000]\n",
      "loss: 1.103331  [ 6464/50000]\n",
      "loss: 1.383582  [ 7104/50000]\n",
      "loss: 1.437053  [ 7744/50000]\n",
      "loss: 1.253937  [ 8384/50000]\n",
      "loss: 1.229350  [ 9024/50000]\n",
      "loss: 1.430592  [ 9664/50000]\n",
      "loss: 1.587024  [10304/50000]\n",
      "loss: 1.499387  [10944/50000]\n",
      "loss: 1.258503  [11584/50000]\n",
      "loss: 1.373085  [12224/50000]\n",
      "loss: 1.674182  [12864/50000]\n",
      "loss: 1.117950  [13504/50000]\n",
      "loss: 1.335647  [14144/50000]\n",
      "loss: 1.383902  [14784/50000]\n",
      "loss: 1.477714  [15424/50000]\n",
      "loss: 1.235737  [16064/50000]\n",
      "loss: 1.504837  [16704/50000]\n",
      "loss: 1.441995  [17344/50000]\n",
      "loss: 1.214471  [17984/50000]\n",
      "loss: 1.169536  [18624/50000]\n",
      "loss: 1.225411  [19264/50000]\n",
      "loss: 1.486712  [19904/50000]\n",
      "loss: 1.411726  [20544/50000]\n",
      "loss: 1.314267  [21184/50000]\n",
      "loss: 1.460722  [21824/50000]\n",
      "loss: 1.544023  [22464/50000]\n",
      "loss: 1.438513  [23104/50000]\n",
      "loss: 1.410943  [23744/50000]\n",
      "loss: 1.455652  [24384/50000]\n",
      "loss: 1.569814  [25024/50000]\n",
      "loss: 1.239703  [25664/50000]\n",
      "loss: 1.286941  [26304/50000]\n",
      "loss: 1.389285  [26944/50000]\n",
      "loss: 1.429413  [27584/50000]\n",
      "loss: 1.362124  [28224/50000]\n",
      "loss: 1.493851  [28864/50000]\n",
      "loss: 1.457604  [29504/50000]\n",
      "loss: 1.494721  [30144/50000]\n",
      "loss: 1.473256  [30784/50000]\n",
      "loss: 1.375549  [31424/50000]\n",
      "loss: 1.521706  [32064/50000]\n",
      "loss: 1.249875  [32704/50000]\n",
      "loss: 1.796728  [33344/50000]\n",
      "loss: 1.456426  [33984/50000]\n",
      "loss: 1.547468  [34624/50000]\n",
      "loss: 1.304985  [35264/50000]\n",
      "loss: 1.525012  [35904/50000]\n",
      "loss: 1.207527  [36544/50000]\n",
      "loss: 1.156589  [37184/50000]\n",
      "loss: 1.264636  [37824/50000]\n",
      "loss: 1.217994  [38464/50000]\n",
      "loss: 1.455348  [39104/50000]\n",
      "loss: 1.175421  [39744/50000]\n",
      "loss: 1.383866  [40384/50000]\n",
      "loss: 1.314216  [41024/50000]\n",
      "loss: 1.467438  [41664/50000]\n",
      "loss: 1.631190  [42304/50000]\n",
      "loss: 1.511762  [42944/50000]\n",
      "loss: 1.505639  [43584/50000]\n",
      "loss: 1.344748  [44224/50000]\n",
      "loss: 1.020333  [44864/50000]\n",
      "loss: 1.525654  [45504/50000]\n",
      "loss: 1.622982  [46144/50000]\n",
      "loss: 1.437837  [46784/50000]\n",
      "loss: 1.348668  [47424/50000]\n",
      "loss: 1.486019  [48064/50000]\n",
      "loss: 1.196440  [48704/50000]\n",
      "loss: 1.646537  [49344/50000]\n",
      "loss: 1.296899  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.845136 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▃▄▄▅▆▆▆▇▇▇█▇███▇███</td></tr><tr><td>test_loss</td><td>█▆▅▅▄▄▃▃▂▃▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.6994</td></tr><tr><td>test_loss</td><td>0.84514</td></tr><tr><td>train_loss</td><td>1.38146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_2</strong> at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1/runs/2dwm3e2g' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1/runs/2dwm3e2g</a><br> View project at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250502_114215-2dwm3e2g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "\n",
    "trainset, testset = get_data()\n",
    "\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "params = dict(\n",
    "  lr = 1e-3,\n",
    "  weight_decay= 1e-8\n",
    ")\n",
    "optimizer = torch.optim.Adam(net.parameters(), **params)\n",
    "\n",
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"ML2_4_1\",\n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      name=\"experiment_2\"\n",
    "      )\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, net, loss_fn, optimizer, device)\n",
    "    test_loop(testloader, net, loss_fn, device)\n",
    "\n",
    "torch.save(net.state_dict(), 'model_weights.pth')\n",
    "torch.save(optimizer.state_dict(), \"optimizer_settings.pth\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgtMCkrBBAJL"
   },
   "source": [
    "#Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaaXFI2WVja9"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, vgg13, mobilenet_v3_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r549vmfG2QpQ"
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRmuFBJBytsV"
   },
   "outputs": [],
   "source": [
    "resnet_model = resnet18(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rwq7k6P039eZ"
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3234858,
     "status": "ok",
     "timestamp": 1746202121475,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "sRQt5-1R47fm",
    "outputId": "f12a1f92-8f49-4cc1-a2c5-ab87e528a616"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshadaevf\u001b[0m (\u001b[33mshadaevf-rtu-mirea\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250502_151449-8hocx09h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/8hocx09h' target=\"_blank\">resnet_2</a></strong> to <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/8hocx09h' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/8hocx09h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.443051  [   64/50000]\n",
      "loss: 2.058531  [  704/50000]\n",
      "loss: 2.232089  [ 1344/50000]\n",
      "loss: 1.791043  [ 1984/50000]\n",
      "loss: 1.947425  [ 2624/50000]\n",
      "loss: 1.924714  [ 3264/50000]\n",
      "loss: 1.971899  [ 3904/50000]\n",
      "loss: 1.871034  [ 4544/50000]\n",
      "loss: 1.550727  [ 5184/50000]\n",
      "loss: 1.650631  [ 5824/50000]\n",
      "loss: 1.694695  [ 6464/50000]\n",
      "loss: 1.797446  [ 7104/50000]\n",
      "loss: 1.586695  [ 7744/50000]\n",
      "loss: 1.580157  [ 8384/50000]\n",
      "loss: 1.899321  [ 9024/50000]\n",
      "loss: 1.731528  [ 9664/50000]\n",
      "loss: 1.776158  [10304/50000]\n",
      "loss: 1.696362  [10944/50000]\n",
      "loss: 1.711059  [11584/50000]\n",
      "loss: 1.409442  [12224/50000]\n",
      "loss: 1.575964  [12864/50000]\n",
      "loss: 1.328331  [13504/50000]\n",
      "loss: 1.631142  [14144/50000]\n",
      "loss: 1.634313  [14784/50000]\n",
      "loss: 1.467301  [15424/50000]\n",
      "loss: 1.474132  [16064/50000]\n",
      "loss: 1.353265  [16704/50000]\n",
      "loss: 1.481780  [17344/50000]\n",
      "loss: 1.550336  [17984/50000]\n",
      "loss: 1.305186  [18624/50000]\n",
      "loss: 1.550796  [19264/50000]\n",
      "loss: 1.431692  [19904/50000]\n",
      "loss: 1.541286  [20544/50000]\n",
      "loss: 1.408274  [21184/50000]\n",
      "loss: 1.306437  [21824/50000]\n",
      "loss: 1.046904  [22464/50000]\n",
      "loss: 1.198808  [23104/50000]\n",
      "loss: 1.353910  [23744/50000]\n",
      "loss: 1.149304  [24384/50000]\n",
      "loss: 1.445445  [25024/50000]\n",
      "loss: 1.465719  [25664/50000]\n",
      "loss: 1.167576  [26304/50000]\n",
      "loss: 1.158574  [26944/50000]\n",
      "loss: 1.061306  [27584/50000]\n",
      "loss: 1.147688  [28224/50000]\n",
      "loss: 1.213897  [28864/50000]\n",
      "loss: 1.030235  [29504/50000]\n",
      "loss: 1.506285  [30144/50000]\n",
      "loss: 0.957438  [30784/50000]\n",
      "loss: 1.214586  [31424/50000]\n",
      "loss: 1.008027  [32064/50000]\n",
      "loss: 1.260279  [32704/50000]\n",
      "loss: 1.257192  [33344/50000]\n",
      "loss: 1.123977  [33984/50000]\n",
      "loss: 1.005165  [34624/50000]\n",
      "loss: 0.965783  [35264/50000]\n",
      "loss: 1.198014  [35904/50000]\n",
      "loss: 1.125933  [36544/50000]\n",
      "loss: 1.084422  [37184/50000]\n",
      "loss: 0.951969  [37824/50000]\n",
      "loss: 1.024769  [38464/50000]\n",
      "loss: 0.972759  [39104/50000]\n",
      "loss: 1.125861  [39744/50000]\n",
      "loss: 1.055739  [40384/50000]\n",
      "loss: 0.840240  [41024/50000]\n",
      "loss: 0.988918  [41664/50000]\n",
      "loss: 1.227836  [42304/50000]\n",
      "loss: 1.141697  [42944/50000]\n",
      "loss: 1.192409  [43584/50000]\n",
      "loss: 0.994588  [44224/50000]\n",
      "loss: 1.060873  [44864/50000]\n",
      "loss: 1.134918  [45504/50000]\n",
      "loss: 1.127364  [46144/50000]\n",
      "loss: 1.031900  [46784/50000]\n",
      "loss: 0.847362  [47424/50000]\n",
      "loss: 1.085510  [48064/50000]\n",
      "loss: 0.894515  [48704/50000]\n",
      "loss: 0.845976  [49344/50000]\n",
      "loss: 1.222894  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.170931 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.005589  [   64/50000]\n",
      "loss: 0.764147  [  704/50000]\n",
      "loss: 0.784737  [ 1344/50000]\n",
      "loss: 0.996050  [ 1984/50000]\n",
      "loss: 0.736561  [ 2624/50000]\n",
      "loss: 1.230517  [ 3264/50000]\n",
      "loss: 1.169396  [ 3904/50000]\n",
      "loss: 1.225167  [ 4544/50000]\n",
      "loss: 0.804163  [ 5184/50000]\n",
      "loss: 0.798212  [ 5824/50000]\n",
      "loss: 1.037405  [ 6464/50000]\n",
      "loss: 0.877010  [ 7104/50000]\n",
      "loss: 1.077667  [ 7744/50000]\n",
      "loss: 0.953075  [ 8384/50000]\n",
      "loss: 0.765335  [ 9024/50000]\n",
      "loss: 0.975458  [ 9664/50000]\n",
      "loss: 0.584820  [10304/50000]\n",
      "loss: 1.081077  [10944/50000]\n",
      "loss: 0.873164  [11584/50000]\n",
      "loss: 0.760958  [12224/50000]\n",
      "loss: 0.702043  [12864/50000]\n",
      "loss: 0.733667  [13504/50000]\n",
      "loss: 0.981683  [14144/50000]\n",
      "loss: 0.961766  [14784/50000]\n",
      "loss: 0.922067  [15424/50000]\n",
      "loss: 0.600865  [16064/50000]\n",
      "loss: 0.796449  [16704/50000]\n",
      "loss: 0.953887  [17344/50000]\n",
      "loss: 0.837255  [17984/50000]\n",
      "loss: 0.880523  [18624/50000]\n",
      "loss: 0.823273  [19264/50000]\n",
      "loss: 0.697366  [19904/50000]\n",
      "loss: 0.972979  [20544/50000]\n",
      "loss: 0.786945  [21184/50000]\n",
      "loss: 0.909240  [21824/50000]\n",
      "loss: 1.042663  [22464/50000]\n",
      "loss: 0.931317  [23104/50000]\n",
      "loss: 0.774740  [23744/50000]\n",
      "loss: 0.829908  [24384/50000]\n",
      "loss: 0.670904  [25024/50000]\n",
      "loss: 0.801767  [25664/50000]\n",
      "loss: 0.940285  [26304/50000]\n",
      "loss: 0.806841  [26944/50000]\n",
      "loss: 0.869596  [27584/50000]\n",
      "loss: 0.894002  [28224/50000]\n",
      "loss: 0.762196  [28864/50000]\n",
      "loss: 0.711065  [29504/50000]\n",
      "loss: 0.780180  [30144/50000]\n",
      "loss: 0.651461  [30784/50000]\n",
      "loss: 0.988469  [31424/50000]\n",
      "loss: 1.050265  [32064/50000]\n",
      "loss: 0.880453  [32704/50000]\n",
      "loss: 0.868665  [33344/50000]\n",
      "loss: 0.630511  [33984/50000]\n",
      "loss: 0.809155  [34624/50000]\n",
      "loss: 0.719168  [35264/50000]\n",
      "loss: 0.766841  [35904/50000]\n",
      "loss: 0.989287  [36544/50000]\n",
      "loss: 1.023979  [37184/50000]\n",
      "loss: 0.849892  [37824/50000]\n",
      "loss: 0.961201  [38464/50000]\n",
      "loss: 0.915816  [39104/50000]\n",
      "loss: 0.761758  [39744/50000]\n",
      "loss: 0.647909  [40384/50000]\n",
      "loss: 0.986318  [41024/50000]\n",
      "loss: 0.583972  [41664/50000]\n",
      "loss: 0.808318  [42304/50000]\n",
      "loss: 0.851817  [42944/50000]\n",
      "loss: 0.689990  [43584/50000]\n",
      "loss: 0.587328  [44224/50000]\n",
      "loss: 0.535057  [44864/50000]\n",
      "loss: 0.757834  [45504/50000]\n",
      "loss: 0.694128  [46144/50000]\n",
      "loss: 0.801380  [46784/50000]\n",
      "loss: 0.720415  [47424/50000]\n",
      "loss: 0.804852  [48064/50000]\n",
      "loss: 0.721105  [48704/50000]\n",
      "loss: 0.551386  [49344/50000]\n",
      "loss: 0.899855  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.752233 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.756161  [   64/50000]\n",
      "loss: 0.606036  [  704/50000]\n",
      "loss: 0.592836  [ 1344/50000]\n",
      "loss: 0.628578  [ 1984/50000]\n",
      "loss: 0.512871  [ 2624/50000]\n",
      "loss: 0.572658  [ 3264/50000]\n",
      "loss: 0.526952  [ 3904/50000]\n",
      "loss: 0.568789  [ 4544/50000]\n",
      "loss: 0.866030  [ 5184/50000]\n",
      "loss: 0.425978  [ 5824/50000]\n",
      "loss: 0.926300  [ 6464/50000]\n",
      "loss: 0.938747  [ 7104/50000]\n",
      "loss: 0.651959  [ 7744/50000]\n",
      "loss: 0.691403  [ 8384/50000]\n",
      "loss: 0.660411  [ 9024/50000]\n",
      "loss: 0.621977  [ 9664/50000]\n",
      "loss: 0.619209  [10304/50000]\n",
      "loss: 0.604107  [10944/50000]\n",
      "loss: 0.571209  [11584/50000]\n",
      "loss: 0.529687  [12224/50000]\n",
      "loss: 0.541980  [12864/50000]\n",
      "loss: 0.774727  [13504/50000]\n",
      "loss: 0.602171  [14144/50000]\n",
      "loss: 0.510249  [14784/50000]\n",
      "loss: 0.480391  [15424/50000]\n",
      "loss: 0.753716  [16064/50000]\n",
      "loss: 0.838159  [16704/50000]\n",
      "loss: 0.472192  [17344/50000]\n",
      "loss: 0.660871  [17984/50000]\n",
      "loss: 0.581824  [18624/50000]\n",
      "loss: 0.708752  [19264/50000]\n",
      "loss: 0.572984  [19904/50000]\n",
      "loss: 0.622886  [20544/50000]\n",
      "loss: 0.763965  [21184/50000]\n",
      "loss: 0.565047  [21824/50000]\n",
      "loss: 0.720818  [22464/50000]\n",
      "loss: 0.715890  [23104/50000]\n",
      "loss: 0.762474  [23744/50000]\n",
      "loss: 0.589639  [24384/50000]\n",
      "loss: 0.449328  [25024/50000]\n",
      "loss: 0.562778  [25664/50000]\n",
      "loss: 0.638668  [26304/50000]\n",
      "loss: 0.501459  [26944/50000]\n",
      "loss: 0.697178  [27584/50000]\n",
      "loss: 0.644826  [28224/50000]\n",
      "loss: 0.707831  [28864/50000]\n",
      "loss: 0.474367  [29504/50000]\n",
      "loss: 0.741273  [30144/50000]\n",
      "loss: 0.602623  [30784/50000]\n",
      "loss: 0.517805  [31424/50000]\n",
      "loss: 0.361530  [32064/50000]\n",
      "loss: 0.761824  [32704/50000]\n",
      "loss: 0.441157  [33344/50000]\n",
      "loss: 0.720390  [33984/50000]\n",
      "loss: 0.507941  [34624/50000]\n",
      "loss: 0.762346  [35264/50000]\n",
      "loss: 0.676097  [35904/50000]\n",
      "loss: 0.622576  [36544/50000]\n",
      "loss: 0.596805  [37184/50000]\n",
      "loss: 0.487760  [37824/50000]\n",
      "loss: 0.725668  [38464/50000]\n",
      "loss: 0.387374  [39104/50000]\n",
      "loss: 0.606949  [39744/50000]\n",
      "loss: 0.694025  [40384/50000]\n",
      "loss: 0.501547  [41024/50000]\n",
      "loss: 0.700360  [41664/50000]\n",
      "loss: 0.858276  [42304/50000]\n",
      "loss: 0.635056  [42944/50000]\n",
      "loss: 0.514030  [43584/50000]\n",
      "loss: 0.499812  [44224/50000]\n",
      "loss: 0.700732  [44864/50000]\n",
      "loss: 0.856757  [45504/50000]\n",
      "loss: 0.463530  [46144/50000]\n",
      "loss: 0.562718  [46784/50000]\n",
      "loss: 0.773626  [47424/50000]\n",
      "loss: 0.823929  [48064/50000]\n",
      "loss: 0.518373  [48704/50000]\n",
      "loss: 0.563425  [49344/50000]\n",
      "loss: 0.489243  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.706284 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.702976  [   64/50000]\n",
      "loss: 0.581212  [  704/50000]\n",
      "loss: 0.526378  [ 1344/50000]\n",
      "loss: 0.305304  [ 1984/50000]\n",
      "loss: 0.378563  [ 2624/50000]\n",
      "loss: 0.394009  [ 3264/50000]\n",
      "loss: 0.550114  [ 3904/50000]\n",
      "loss: 0.423869  [ 4544/50000]\n",
      "loss: 0.706447  [ 5184/50000]\n",
      "loss: 0.321451  [ 5824/50000]\n",
      "loss: 0.296933  [ 6464/50000]\n",
      "loss: 0.424293  [ 7104/50000]\n",
      "loss: 0.674721  [ 7744/50000]\n",
      "loss: 0.653003  [ 8384/50000]\n",
      "loss: 0.596900  [ 9024/50000]\n",
      "loss: 0.518823  [ 9664/50000]\n",
      "loss: 0.773544  [10304/50000]\n",
      "loss: 0.380997  [10944/50000]\n",
      "loss: 0.506586  [11584/50000]\n",
      "loss: 0.520933  [12224/50000]\n",
      "loss: 0.441086  [12864/50000]\n",
      "loss: 0.286666  [13504/50000]\n",
      "loss: 0.534771  [14144/50000]\n",
      "loss: 0.576604  [14784/50000]\n",
      "loss: 0.471113  [15424/50000]\n",
      "loss: 0.395238  [16064/50000]\n",
      "loss: 0.474399  [16704/50000]\n",
      "loss: 0.677286  [17344/50000]\n",
      "loss: 0.648918  [17984/50000]\n",
      "loss: 0.221353  [18624/50000]\n",
      "loss: 0.580282  [19264/50000]\n",
      "loss: 0.665521  [19904/50000]\n",
      "loss: 0.709439  [20544/50000]\n",
      "loss: 0.339271  [21184/50000]\n",
      "loss: 0.310171  [21824/50000]\n",
      "loss: 0.365435  [22464/50000]\n",
      "loss: 0.635177  [23104/50000]\n",
      "loss: 0.598856  [23744/50000]\n",
      "loss: 0.277009  [24384/50000]\n",
      "loss: 0.521972  [25024/50000]\n",
      "loss: 0.403402  [25664/50000]\n",
      "loss: 0.616737  [26304/50000]\n",
      "loss: 0.392263  [26944/50000]\n",
      "loss: 0.425847  [27584/50000]\n",
      "loss: 0.545105  [28224/50000]\n",
      "loss: 0.737276  [28864/50000]\n",
      "loss: 0.405548  [29504/50000]\n",
      "loss: 0.444801  [30144/50000]\n",
      "loss: 0.351289  [30784/50000]\n",
      "loss: 0.628536  [31424/50000]\n",
      "loss: 0.712037  [32064/50000]\n",
      "loss: 0.366320  [32704/50000]\n",
      "loss: 0.362224  [33344/50000]\n",
      "loss: 0.465206  [33984/50000]\n",
      "loss: 0.436179  [34624/50000]\n",
      "loss: 0.608909  [35264/50000]\n",
      "loss: 0.628906  [35904/50000]\n",
      "loss: 0.506233  [36544/50000]\n",
      "loss: 0.459846  [37184/50000]\n",
      "loss: 0.383748  [37824/50000]\n",
      "loss: 0.424105  [38464/50000]\n",
      "loss: 0.554495  [39104/50000]\n",
      "loss: 0.464927  [39744/50000]\n",
      "loss: 0.363705  [40384/50000]\n",
      "loss: 0.710418  [41024/50000]\n",
      "loss: 0.379097  [41664/50000]\n",
      "loss: 0.451091  [42304/50000]\n",
      "loss: 0.597132  [42944/50000]\n",
      "loss: 0.370124  [43584/50000]\n",
      "loss: 0.533361  [44224/50000]\n",
      "loss: 0.495914  [44864/50000]\n",
      "loss: 0.823816  [45504/50000]\n",
      "loss: 0.325765  [46144/50000]\n",
      "loss: 0.505397  [46784/50000]\n",
      "loss: 0.509283  [47424/50000]\n",
      "loss: 0.471181  [48064/50000]\n",
      "loss: 0.927130  [48704/50000]\n",
      "loss: 0.517797  [49344/50000]\n",
      "loss: 0.567951  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.552014 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.420444  [   64/50000]\n",
      "loss: 0.443001  [  704/50000]\n",
      "loss: 0.497725  [ 1344/50000]\n",
      "loss: 0.364937  [ 1984/50000]\n",
      "loss: 0.287373  [ 2624/50000]\n",
      "loss: 0.365893  [ 3264/50000]\n",
      "loss: 0.383242  [ 3904/50000]\n",
      "loss: 0.316484  [ 4544/50000]\n",
      "loss: 0.319579  [ 5184/50000]\n",
      "loss: 0.197363  [ 5824/50000]\n",
      "loss: 0.296566  [ 6464/50000]\n",
      "loss: 0.436725  [ 7104/50000]\n",
      "loss: 0.512416  [ 7744/50000]\n",
      "loss: 0.267767  [ 8384/50000]\n",
      "loss: 0.534240  [ 9024/50000]\n",
      "loss: 0.550504  [ 9664/50000]\n",
      "loss: 0.384766  [10304/50000]\n",
      "loss: 0.349470  [10944/50000]\n",
      "loss: 0.308197  [11584/50000]\n",
      "loss: 0.344955  [12224/50000]\n",
      "loss: 0.526642  [12864/50000]\n",
      "loss: 0.347196  [13504/50000]\n",
      "loss: 0.261110  [14144/50000]\n",
      "loss: 0.346315  [14784/50000]\n",
      "loss: 0.427896  [15424/50000]\n",
      "loss: 0.341125  [16064/50000]\n",
      "loss: 0.442681  [16704/50000]\n",
      "loss: 0.459461  [17344/50000]\n",
      "loss: 0.360376  [17984/50000]\n",
      "loss: 0.260232  [18624/50000]\n",
      "loss: 0.342110  [19264/50000]\n",
      "loss: 0.274587  [19904/50000]\n",
      "loss: 0.479967  [20544/50000]\n",
      "loss: 0.350334  [21184/50000]\n",
      "loss: 0.379871  [21824/50000]\n",
      "loss: 0.304206  [22464/50000]\n",
      "loss: 0.523081  [23104/50000]\n",
      "loss: 0.577285  [23744/50000]\n",
      "loss: 0.426761  [24384/50000]\n",
      "loss: 0.338192  [25024/50000]\n",
      "loss: 0.550671  [25664/50000]\n",
      "loss: 0.347192  [26304/50000]\n",
      "loss: 0.294328  [26944/50000]\n",
      "loss: 0.392279  [27584/50000]\n",
      "loss: 0.473241  [28224/50000]\n",
      "loss: 0.623017  [28864/50000]\n",
      "loss: 0.386053  [29504/50000]\n",
      "loss: 0.471232  [30144/50000]\n",
      "loss: 0.166405  [30784/50000]\n",
      "loss: 0.404046  [31424/50000]\n",
      "loss: 0.287636  [32064/50000]\n",
      "loss: 0.415875  [32704/50000]\n",
      "loss: 0.500357  [33344/50000]\n",
      "loss: 0.370421  [33984/50000]\n",
      "loss: 0.421981  [34624/50000]\n",
      "loss: 0.418033  [35264/50000]\n",
      "loss: 0.434023  [35904/50000]\n",
      "loss: 0.331368  [36544/50000]\n",
      "loss: 0.254634  [37184/50000]\n",
      "loss: 0.374653  [37824/50000]\n",
      "loss: 0.422783  [38464/50000]\n",
      "loss: 0.336700  [39104/50000]\n",
      "loss: 0.452675  [39744/50000]\n",
      "loss: 0.327625  [40384/50000]\n",
      "loss: 0.350783  [41024/50000]\n",
      "loss: 0.338333  [41664/50000]\n",
      "loss: 0.341993  [42304/50000]\n",
      "loss: 0.414369  [42944/50000]\n",
      "loss: 0.331671  [43584/50000]\n",
      "loss: 0.365631  [44224/50000]\n",
      "loss: 0.225868  [44864/50000]\n",
      "loss: 0.603288  [45504/50000]\n",
      "loss: 0.365849  [46144/50000]\n",
      "loss: 0.405973  [46784/50000]\n",
      "loss: 0.449343  [47424/50000]\n",
      "loss: 0.496208  [48064/50000]\n",
      "loss: 0.657276  [48704/50000]\n",
      "loss: 0.328953  [49344/50000]\n",
      "loss: 0.456493  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.619356 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.181983  [   64/50000]\n",
      "loss: 0.360946  [  704/50000]\n",
      "loss: 0.233162  [ 1344/50000]\n",
      "loss: 0.215705  [ 1984/50000]\n",
      "loss: 0.510604  [ 2624/50000]\n",
      "loss: 0.234842  [ 3264/50000]\n",
      "loss: 0.448188  [ 3904/50000]\n",
      "loss: 0.369972  [ 4544/50000]\n",
      "loss: 0.394759  [ 5184/50000]\n",
      "loss: 0.366845  [ 5824/50000]\n",
      "loss: 0.262893  [ 6464/50000]\n",
      "loss: 0.249670  [ 7104/50000]\n",
      "loss: 0.135085  [ 7744/50000]\n",
      "loss: 0.321720  [ 8384/50000]\n",
      "loss: 0.410585  [ 9024/50000]\n",
      "loss: 0.359776  [ 9664/50000]\n",
      "loss: 0.175153  [10304/50000]\n",
      "loss: 0.266897  [10944/50000]\n",
      "loss: 0.315775  [11584/50000]\n",
      "loss: 0.255008  [12224/50000]\n",
      "loss: 0.281398  [12864/50000]\n",
      "loss: 0.235673  [13504/50000]\n",
      "loss: 0.252956  [14144/50000]\n",
      "loss: 0.208774  [14784/50000]\n",
      "loss: 0.373242  [15424/50000]\n",
      "loss: 0.205014  [16064/50000]\n",
      "loss: 0.274003  [16704/50000]\n",
      "loss: 0.345215  [17344/50000]\n",
      "loss: 0.343121  [17984/50000]\n",
      "loss: 0.365826  [18624/50000]\n",
      "loss: 0.232300  [19264/50000]\n",
      "loss: 0.329314  [19904/50000]\n",
      "loss: 0.288964  [20544/50000]\n",
      "loss: 0.323896  [21184/50000]\n",
      "loss: 0.340999  [21824/50000]\n",
      "loss: 0.436703  [22464/50000]\n",
      "loss: 0.191000  [23104/50000]\n",
      "loss: 0.370426  [23744/50000]\n",
      "loss: 0.314026  [24384/50000]\n",
      "loss: 0.339305  [25024/50000]\n",
      "loss: 0.202487  [25664/50000]\n",
      "loss: 0.291974  [26304/50000]\n",
      "loss: 0.538902  [26944/50000]\n",
      "loss: 0.360726  [27584/50000]\n",
      "loss: 0.406658  [28224/50000]\n",
      "loss: 0.232093  [28864/50000]\n",
      "loss: 0.291091  [29504/50000]\n",
      "loss: 0.389522  [30144/50000]\n",
      "loss: 0.361203  [30784/50000]\n",
      "loss: 0.288631  [31424/50000]\n",
      "loss: 0.291235  [32064/50000]\n",
      "loss: 0.290025  [32704/50000]\n",
      "loss: 0.303719  [33344/50000]\n",
      "loss: 0.364548  [33984/50000]\n",
      "loss: 0.222266  [34624/50000]\n",
      "loss: 0.453014  [35264/50000]\n",
      "loss: 0.378733  [35904/50000]\n",
      "loss: 0.292853  [36544/50000]\n",
      "loss: 0.229640  [37184/50000]\n",
      "loss: 0.429047  [37824/50000]\n",
      "loss: 0.302824  [38464/50000]\n",
      "loss: 0.276714  [39104/50000]\n",
      "loss: 0.399553  [39744/50000]\n",
      "loss: 0.492194  [40384/50000]\n",
      "loss: 0.312615  [41024/50000]\n",
      "loss: 0.330524  [41664/50000]\n",
      "loss: 0.189806  [42304/50000]\n",
      "loss: 0.308836  [42944/50000]\n",
      "loss: 0.371592  [43584/50000]\n",
      "loss: 0.277017  [44224/50000]\n",
      "loss: 0.384954  [44864/50000]\n",
      "loss: 0.208749  [45504/50000]\n",
      "loss: 0.255169  [46144/50000]\n",
      "loss: 0.342944  [46784/50000]\n",
      "loss: 0.325147  [47424/50000]\n",
      "loss: 0.355770  [48064/50000]\n",
      "loss: 0.405559  [48704/50000]\n",
      "loss: 0.355190  [49344/50000]\n",
      "loss: 0.343798  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.600497 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.408287  [   64/50000]\n",
      "loss: 0.254190  [  704/50000]\n",
      "loss: 0.325925  [ 1344/50000]\n",
      "loss: 0.394964  [ 1984/50000]\n",
      "loss: 0.177643  [ 2624/50000]\n",
      "loss: 0.247827  [ 3264/50000]\n",
      "loss: 0.233977  [ 3904/50000]\n",
      "loss: 0.226660  [ 4544/50000]\n",
      "loss: 0.236513  [ 5184/50000]\n",
      "loss: 0.274179  [ 5824/50000]\n",
      "loss: 0.268689  [ 6464/50000]\n",
      "loss: 0.301987  [ 7104/50000]\n",
      "loss: 0.120635  [ 7744/50000]\n",
      "loss: 0.163467  [ 8384/50000]\n",
      "loss: 0.200467  [ 9024/50000]\n",
      "loss: 0.283197  [ 9664/50000]\n",
      "loss: 0.236693  [10304/50000]\n",
      "loss: 0.139227  [10944/50000]\n",
      "loss: 0.211654  [11584/50000]\n",
      "loss: 0.386772  [12224/50000]\n",
      "loss: 0.357763  [12864/50000]\n",
      "loss: 0.294708  [13504/50000]\n",
      "loss: 0.263573  [14144/50000]\n",
      "loss: 0.095600  [14784/50000]\n",
      "loss: 0.153006  [15424/50000]\n",
      "loss: 0.219740  [16064/50000]\n",
      "loss: 0.176568  [16704/50000]\n",
      "loss: 0.261487  [17344/50000]\n",
      "loss: 0.292258  [17984/50000]\n",
      "loss: 0.165339  [18624/50000]\n",
      "loss: 0.199661  [19264/50000]\n",
      "loss: 0.308125  [19904/50000]\n",
      "loss: 0.420688  [20544/50000]\n",
      "loss: 0.287527  [21184/50000]\n",
      "loss: 0.245011  [21824/50000]\n",
      "loss: 0.171599  [22464/50000]\n",
      "loss: 0.178604  [23104/50000]\n",
      "loss: 0.290442  [23744/50000]\n",
      "loss: 0.215476  [24384/50000]\n",
      "loss: 0.335150  [25024/50000]\n",
      "loss: 0.256054  [25664/50000]\n",
      "loss: 0.189594  [26304/50000]\n",
      "loss: 0.191210  [26944/50000]\n",
      "loss: 0.189226  [27584/50000]\n",
      "loss: 0.319900  [28224/50000]\n",
      "loss: 0.140070  [28864/50000]\n",
      "loss: 0.211211  [29504/50000]\n",
      "loss: 0.159882  [30144/50000]\n",
      "loss: 0.341447  [30784/50000]\n",
      "loss: 0.385878  [31424/50000]\n",
      "loss: 0.134089  [32064/50000]\n",
      "loss: 0.324761  [32704/50000]\n",
      "loss: 0.355109  [33344/50000]\n",
      "loss: 0.231967  [33984/50000]\n",
      "loss: 0.239026  [34624/50000]\n",
      "loss: 0.361590  [35264/50000]\n",
      "loss: 0.336655  [35904/50000]\n",
      "loss: 0.192516  [36544/50000]\n",
      "loss: 0.210932  [37184/50000]\n",
      "loss: 0.160669  [37824/50000]\n",
      "loss: 0.209967  [38464/50000]\n",
      "loss: 0.191112  [39104/50000]\n",
      "loss: 0.423490  [39744/50000]\n",
      "loss: 0.247924  [40384/50000]\n",
      "loss: 0.127346  [41024/50000]\n",
      "loss: 0.258420  [41664/50000]\n",
      "loss: 0.297163  [42304/50000]\n",
      "loss: 0.236070  [42944/50000]\n",
      "loss: 0.235712  [43584/50000]\n",
      "loss: 0.142521  [44224/50000]\n",
      "loss: 0.239788  [44864/50000]\n",
      "loss: 0.273733  [45504/50000]\n",
      "loss: 0.342186  [46144/50000]\n",
      "loss: 0.235778  [46784/50000]\n",
      "loss: 0.261169  [47424/50000]\n",
      "loss: 0.193964  [48064/50000]\n",
      "loss: 0.177865  [48704/50000]\n",
      "loss: 0.240723  [49344/50000]\n",
      "loss: 0.156703  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.581149 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.103978  [   64/50000]\n",
      "loss: 0.221549  [  704/50000]\n",
      "loss: 0.145915  [ 1344/50000]\n",
      "loss: 0.187852  [ 1984/50000]\n",
      "loss: 0.129970  [ 2624/50000]\n",
      "loss: 0.079703  [ 3264/50000]\n",
      "loss: 0.096742  [ 3904/50000]\n",
      "loss: 0.145411  [ 4544/50000]\n",
      "loss: 0.074476  [ 5184/50000]\n",
      "loss: 0.109767  [ 5824/50000]\n",
      "loss: 0.202963  [ 6464/50000]\n",
      "loss: 0.094273  [ 7104/50000]\n",
      "loss: 0.092445  [ 7744/50000]\n",
      "loss: 0.212931  [ 8384/50000]\n",
      "loss: 0.173984  [ 9024/50000]\n",
      "loss: 0.122903  [ 9664/50000]\n",
      "loss: 0.237183  [10304/50000]\n",
      "loss: 0.146615  [10944/50000]\n",
      "loss: 0.217282  [11584/50000]\n",
      "loss: 0.081563  [12224/50000]\n",
      "loss: 0.227474  [12864/50000]\n",
      "loss: 0.093709  [13504/50000]\n",
      "loss: 0.205182  [14144/50000]\n",
      "loss: 0.063801  [14784/50000]\n",
      "loss: 0.218288  [15424/50000]\n",
      "loss: 0.158068  [16064/50000]\n",
      "loss: 0.140212  [16704/50000]\n",
      "loss: 0.307317  [17344/50000]\n",
      "loss: 0.257072  [17984/50000]\n",
      "loss: 0.287496  [18624/50000]\n",
      "loss: 0.108177  [19264/50000]\n",
      "loss: 0.239996  [19904/50000]\n",
      "loss: 0.192659  [20544/50000]\n",
      "loss: 0.252244  [21184/50000]\n",
      "loss: 0.278538  [21824/50000]\n",
      "loss: 0.150696  [22464/50000]\n",
      "loss: 0.175855  [23104/50000]\n",
      "loss: 0.211511  [23744/50000]\n",
      "loss: 0.103398  [24384/50000]\n",
      "loss: 0.226231  [25024/50000]\n",
      "loss: 0.105286  [25664/50000]\n",
      "loss: 0.161085  [26304/50000]\n",
      "loss: 0.150855  [26944/50000]\n",
      "loss: 0.166636  [27584/50000]\n",
      "loss: 0.235981  [28224/50000]\n",
      "loss: 0.177335  [28864/50000]\n",
      "loss: 0.166210  [29504/50000]\n",
      "loss: 0.191500  [30144/50000]\n",
      "loss: 0.298924  [30784/50000]\n",
      "loss: 0.158846  [31424/50000]\n",
      "loss: 0.171365  [32064/50000]\n",
      "loss: 0.269494  [32704/50000]\n",
      "loss: 0.199412  [33344/50000]\n",
      "loss: 0.150656  [33984/50000]\n",
      "loss: 0.182831  [34624/50000]\n",
      "loss: 0.156060  [35264/50000]\n",
      "loss: 0.264202  [35904/50000]\n",
      "loss: 0.114860  [36544/50000]\n",
      "loss: 0.227236  [37184/50000]\n",
      "loss: 0.301948  [37824/50000]\n",
      "loss: 0.185092  [38464/50000]\n",
      "loss: 0.280182  [39104/50000]\n",
      "loss: 0.317087  [39744/50000]\n",
      "loss: 0.275896  [40384/50000]\n",
      "loss: 0.285571  [41024/50000]\n",
      "loss: 0.207827  [41664/50000]\n",
      "loss: 0.288149  [42304/50000]\n",
      "loss: 0.147353  [42944/50000]\n",
      "loss: 0.060382  [43584/50000]\n",
      "loss: 0.150790  [44224/50000]\n",
      "loss: 0.390172  [44864/50000]\n",
      "loss: 0.197571  [45504/50000]\n",
      "loss: 0.127216  [46144/50000]\n",
      "loss: 0.335033  [46784/50000]\n",
      "loss: 0.177986  [47424/50000]\n",
      "loss: 0.161501  [48064/50000]\n",
      "loss: 0.087166  [48704/50000]\n",
      "loss: 0.339856  [49344/50000]\n",
      "loss: 0.122962  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.498234 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.126920  [   64/50000]\n",
      "loss: 0.066838  [  704/50000]\n",
      "loss: 0.111934  [ 1344/50000]\n",
      "loss: 0.102337  [ 1984/50000]\n",
      "loss: 0.176043  [ 2624/50000]\n",
      "loss: 0.042130  [ 3264/50000]\n",
      "loss: 0.135588  [ 3904/50000]\n",
      "loss: 0.054039  [ 4544/50000]\n",
      "loss: 0.214354  [ 5184/50000]\n",
      "loss: 0.166385  [ 5824/50000]\n",
      "loss: 0.125459  [ 6464/50000]\n",
      "loss: 0.074006  [ 7104/50000]\n",
      "loss: 0.047008  [ 7744/50000]\n",
      "loss: 0.040199  [ 8384/50000]\n",
      "loss: 0.153661  [ 9024/50000]\n",
      "loss: 0.247430  [ 9664/50000]\n",
      "loss: 0.139786  [10304/50000]\n",
      "loss: 0.099328  [10944/50000]\n",
      "loss: 0.104121  [11584/50000]\n",
      "loss: 0.216353  [12224/50000]\n",
      "loss: 0.071758  [12864/50000]\n",
      "loss: 0.197937  [13504/50000]\n",
      "loss: 0.076539  [14144/50000]\n",
      "loss: 0.055299  [14784/50000]\n",
      "loss: 0.106186  [15424/50000]\n",
      "loss: 0.083695  [16064/50000]\n",
      "loss: 0.050648  [16704/50000]\n",
      "loss: 0.049420  [17344/50000]\n",
      "loss: 0.121631  [17984/50000]\n",
      "loss: 0.102519  [18624/50000]\n",
      "loss: 0.101101  [19264/50000]\n",
      "loss: 0.085141  [19904/50000]\n",
      "loss: 0.136851  [20544/50000]\n",
      "loss: 0.151398  [21184/50000]\n",
      "loss: 0.081534  [21824/50000]\n",
      "loss: 0.104940  [22464/50000]\n",
      "loss: 0.041826  [23104/50000]\n",
      "loss: 0.162614  [23744/50000]\n",
      "loss: 0.088363  [24384/50000]\n",
      "loss: 0.111917  [25024/50000]\n",
      "loss: 0.157419  [25664/50000]\n",
      "loss: 0.160511  [26304/50000]\n",
      "loss: 0.082572  [26944/50000]\n",
      "loss: 0.145398  [27584/50000]\n",
      "loss: 0.181148  [28224/50000]\n",
      "loss: 0.130623  [28864/50000]\n",
      "loss: 0.202470  [29504/50000]\n",
      "loss: 0.168249  [30144/50000]\n",
      "loss: 0.152040  [30784/50000]\n",
      "loss: 0.061418  [31424/50000]\n",
      "loss: 0.143140  [32064/50000]\n",
      "loss: 0.207596  [32704/50000]\n",
      "loss: 0.057833  [33344/50000]\n",
      "loss: 0.100008  [33984/50000]\n",
      "loss: 0.055745  [34624/50000]\n",
      "loss: 0.158081  [35264/50000]\n",
      "loss: 0.094546  [35904/50000]\n",
      "loss: 0.143726  [36544/50000]\n",
      "loss: 0.149309  [37184/50000]\n",
      "loss: 0.122535  [37824/50000]\n",
      "loss: 0.134433  [38464/50000]\n",
      "loss: 0.046461  [39104/50000]\n",
      "loss: 0.159162  [39744/50000]\n",
      "loss: 0.254005  [40384/50000]\n",
      "loss: 0.232875  [41024/50000]\n",
      "loss: 0.168579  [41664/50000]\n",
      "loss: 0.093477  [42304/50000]\n",
      "loss: 0.163853  [42944/50000]\n",
      "loss: 0.182934  [43584/50000]\n",
      "loss: 0.137635  [44224/50000]\n",
      "loss: 0.199475  [44864/50000]\n",
      "loss: 0.099985  [45504/50000]\n",
      "loss: 0.278241  [46144/50000]\n",
      "loss: 0.112777  [46784/50000]\n",
      "loss: 0.154518  [47424/50000]\n",
      "loss: 0.131476  [48064/50000]\n",
      "loss: 0.073019  [48704/50000]\n",
      "loss: 0.161726  [49344/50000]\n",
      "loss: 0.131954  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.593974 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.032616  [   64/50000]\n",
      "loss: 0.048822  [  704/50000]\n",
      "loss: 0.139602  [ 1344/50000]\n",
      "loss: 0.079567  [ 1984/50000]\n",
      "loss: 0.078030  [ 2624/50000]\n",
      "loss: 0.040835  [ 3264/50000]\n",
      "loss: 0.026172  [ 3904/50000]\n",
      "loss: 0.106473  [ 4544/50000]\n",
      "loss: 0.019466  [ 5184/50000]\n",
      "loss: 0.136942  [ 5824/50000]\n",
      "loss: 0.147648  [ 6464/50000]\n",
      "loss: 0.103301  [ 7104/50000]\n",
      "loss: 0.045814  [ 7744/50000]\n",
      "loss: 0.042816  [ 8384/50000]\n",
      "loss: 0.046406  [ 9024/50000]\n",
      "loss: 0.020309  [ 9664/50000]\n",
      "loss: 0.013104  [10304/50000]\n",
      "loss: 0.068349  [10944/50000]\n",
      "loss: 0.026252  [11584/50000]\n",
      "loss: 0.026151  [12224/50000]\n",
      "loss: 0.164125  [12864/50000]\n",
      "loss: 0.041755  [13504/50000]\n",
      "loss: 0.034581  [14144/50000]\n",
      "loss: 0.032619  [14784/50000]\n",
      "loss: 0.122787  [15424/50000]\n",
      "loss: 0.029664  [16064/50000]\n",
      "loss: 0.097843  [16704/50000]\n",
      "loss: 0.030768  [17344/50000]\n",
      "loss: 0.027771  [17984/50000]\n",
      "loss: 0.104367  [18624/50000]\n",
      "loss: 0.067812  [19264/50000]\n",
      "loss: 0.055790  [19904/50000]\n",
      "loss: 0.045579  [20544/50000]\n",
      "loss: 0.037355  [21184/50000]\n",
      "loss: 0.078667  [21824/50000]\n",
      "loss: 0.102082  [22464/50000]\n",
      "loss: 0.096491  [23104/50000]\n",
      "loss: 0.124326  [23744/50000]\n",
      "loss: 0.048144  [24384/50000]\n",
      "loss: 0.058045  [25024/50000]\n",
      "loss: 0.035259  [25664/50000]\n",
      "loss: 0.102861  [26304/50000]\n",
      "loss: 0.055849  [26944/50000]\n",
      "loss: 0.115204  [27584/50000]\n",
      "loss: 0.090724  [28224/50000]\n",
      "loss: 0.011374  [28864/50000]\n",
      "loss: 0.164779  [29504/50000]\n",
      "loss: 0.090267  [30144/50000]\n",
      "loss: 0.137713  [30784/50000]\n",
      "loss: 0.120408  [31424/50000]\n",
      "loss: 0.250895  [32064/50000]\n",
      "loss: 0.192147  [32704/50000]\n",
      "loss: 0.085283  [33344/50000]\n",
      "loss: 0.080656  [33984/50000]\n",
      "loss: 0.149046  [34624/50000]\n",
      "loss: 0.113944  [35264/50000]\n",
      "loss: 0.168214  [35904/50000]\n",
      "loss: 0.115997  [36544/50000]\n",
      "loss: 0.080094  [37184/50000]\n",
      "loss: 0.127388  [37824/50000]\n",
      "loss: 0.105700  [38464/50000]\n",
      "loss: 0.135765  [39104/50000]\n",
      "loss: 0.164074  [39744/50000]\n",
      "loss: 0.065170  [40384/50000]\n",
      "loss: 0.021815  [41024/50000]\n",
      "loss: 0.189273  [41664/50000]\n",
      "loss: 0.041852  [42304/50000]\n",
      "loss: 0.225735  [42944/50000]\n",
      "loss: 0.090383  [43584/50000]\n",
      "loss: 0.137176  [44224/50000]\n",
      "loss: 0.198315  [44864/50000]\n",
      "loss: 0.029065  [45504/50000]\n",
      "loss: 0.137036  [46144/50000]\n",
      "loss: 0.158078  [46784/50000]\n",
      "loss: 0.049187  [47424/50000]\n",
      "loss: 0.188248  [48064/50000]\n",
      "loss: 0.088395  [48704/50000]\n",
      "loss: 0.140789  [49344/50000]\n",
      "loss: 0.113449  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.729968 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.071186  [   64/50000]\n",
      "loss: 0.063405  [  704/50000]\n",
      "loss: 0.089951  [ 1344/50000]\n",
      "loss: 0.052887  [ 1984/50000]\n",
      "loss: 0.127384  [ 2624/50000]\n",
      "loss: 0.046589  [ 3264/50000]\n",
      "loss: 0.051238  [ 3904/50000]\n",
      "loss: 0.072917  [ 4544/50000]\n",
      "loss: 0.050456  [ 5184/50000]\n",
      "loss: 0.026872  [ 5824/50000]\n",
      "loss: 0.100316  [ 6464/50000]\n",
      "loss: 0.029360  [ 7104/50000]\n",
      "loss: 0.032339  [ 7744/50000]\n",
      "loss: 0.042055  [ 8384/50000]\n",
      "loss: 0.014313  [ 9024/50000]\n",
      "loss: 0.035135  [ 9664/50000]\n",
      "loss: 0.089252  [10304/50000]\n",
      "loss: 0.053147  [10944/50000]\n",
      "loss: 0.095097  [11584/50000]\n",
      "loss: 0.018384  [12224/50000]\n",
      "loss: 0.089043  [12864/50000]\n",
      "loss: 0.063335  [13504/50000]\n",
      "loss: 0.059131  [14144/50000]\n",
      "loss: 0.044574  [14784/50000]\n",
      "loss: 0.090542  [15424/50000]\n",
      "loss: 0.060661  [16064/50000]\n",
      "loss: 0.078607  [16704/50000]\n",
      "loss: 0.025324  [17344/50000]\n",
      "loss: 0.059810  [17984/50000]\n",
      "loss: 0.027083  [18624/50000]\n",
      "loss: 0.012301  [19264/50000]\n",
      "loss: 0.029052  [19904/50000]\n",
      "loss: 0.053260  [20544/50000]\n",
      "loss: 0.123844  [21184/50000]\n",
      "loss: 0.028827  [21824/50000]\n",
      "loss: 0.115720  [22464/50000]\n",
      "loss: 0.090739  [23104/50000]\n",
      "loss: 0.027732  [23744/50000]\n",
      "loss: 0.058709  [24384/50000]\n",
      "loss: 0.077198  [25024/50000]\n",
      "loss: 0.075245  [25664/50000]\n",
      "loss: 0.052986  [26304/50000]\n",
      "loss: 0.045338  [26944/50000]\n",
      "loss: 0.085814  [27584/50000]\n",
      "loss: 0.015672  [28224/50000]\n",
      "loss: 0.203299  [28864/50000]\n",
      "loss: 0.059263  [29504/50000]\n",
      "loss: 0.081030  [30144/50000]\n",
      "loss: 0.147105  [30784/50000]\n",
      "loss: 0.046065  [31424/50000]\n",
      "loss: 0.118133  [32064/50000]\n",
      "loss: 0.102681  [32704/50000]\n",
      "loss: 0.048970  [33344/50000]\n",
      "loss: 0.042392  [33984/50000]\n",
      "loss: 0.090565  [34624/50000]\n",
      "loss: 0.088323  [35264/50000]\n",
      "loss: 0.164255  [35904/50000]\n",
      "loss: 0.230438  [36544/50000]\n",
      "loss: 0.030651  [37184/50000]\n",
      "loss: 0.037055  [37824/50000]\n",
      "loss: 0.046644  [38464/50000]\n",
      "loss: 0.033789  [39104/50000]\n",
      "loss: 0.083727  [39744/50000]\n",
      "loss: 0.137242  [40384/50000]\n",
      "loss: 0.203944  [41024/50000]\n",
      "loss: 0.022854  [41664/50000]\n",
      "loss: 0.198265  [42304/50000]\n",
      "loss: 0.190745  [42944/50000]\n",
      "loss: 0.122984  [43584/50000]\n",
      "loss: 0.045121  [44224/50000]\n",
      "loss: 0.129667  [44864/50000]\n",
      "loss: 0.138326  [45504/50000]\n",
      "loss: 0.146495  [46144/50000]\n",
      "loss: 0.152486  [46784/50000]\n",
      "loss: 0.070906  [47424/50000]\n",
      "loss: 0.113618  [48064/50000]\n",
      "loss: 0.091182  [48704/50000]\n",
      "loss: 0.089285  [49344/50000]\n",
      "loss: 0.076201  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.664196 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.053672  [   64/50000]\n",
      "loss: 0.076026  [  704/50000]\n",
      "loss: 0.014168  [ 1344/50000]\n",
      "loss: 0.056447  [ 1984/50000]\n",
      "loss: 0.077180  [ 2624/50000]\n",
      "loss: 0.166709  [ 3264/50000]\n",
      "loss: 0.050464  [ 3904/50000]\n",
      "loss: 0.061536  [ 4544/50000]\n",
      "loss: 0.013460  [ 5184/50000]\n",
      "loss: 0.143439  [ 5824/50000]\n",
      "loss: 0.076070  [ 6464/50000]\n",
      "loss: 0.062142  [ 7104/50000]\n",
      "loss: 0.035538  [ 7744/50000]\n",
      "loss: 0.087977  [ 8384/50000]\n",
      "loss: 0.120472  [ 9024/50000]\n",
      "loss: 0.082157  [ 9664/50000]\n",
      "loss: 0.050451  [10304/50000]\n",
      "loss: 0.022932  [10944/50000]\n",
      "loss: 0.042683  [11584/50000]\n",
      "loss: 0.150585  [12224/50000]\n",
      "loss: 0.063326  [12864/50000]\n",
      "loss: 0.023462  [13504/50000]\n",
      "loss: 0.028714  [14144/50000]\n",
      "loss: 0.019597  [14784/50000]\n",
      "loss: 0.019590  [15424/50000]\n",
      "loss: 0.066106  [16064/50000]\n",
      "loss: 0.028704  [16704/50000]\n",
      "loss: 0.186929  [17344/50000]\n",
      "loss: 0.056683  [17984/50000]\n",
      "loss: 0.115699  [18624/50000]\n",
      "loss: 0.014304  [19264/50000]\n",
      "loss: 0.065407  [19904/50000]\n",
      "loss: 0.092252  [20544/50000]\n",
      "loss: 0.025385  [21184/50000]\n",
      "loss: 0.147465  [21824/50000]\n",
      "loss: 0.338985  [22464/50000]\n",
      "loss: 0.072211  [23104/50000]\n",
      "loss: 0.066921  [23744/50000]\n",
      "loss: 0.143060  [24384/50000]\n",
      "loss: 0.227774  [25024/50000]\n",
      "loss: 0.038013  [25664/50000]\n",
      "loss: 0.044851  [26304/50000]\n",
      "loss: 0.055348  [26944/50000]\n",
      "loss: 0.087264  [27584/50000]\n",
      "loss: 0.066207  [28224/50000]\n",
      "loss: 0.058289  [28864/50000]\n",
      "loss: 0.049360  [29504/50000]\n",
      "loss: 0.102353  [30144/50000]\n",
      "loss: 0.019050  [30784/50000]\n",
      "loss: 0.043817  [31424/50000]\n",
      "loss: 0.040351  [32064/50000]\n",
      "loss: 0.111160  [32704/50000]\n",
      "loss: 0.106137  [33344/50000]\n",
      "loss: 0.120660  [33984/50000]\n",
      "loss: 0.100878  [34624/50000]\n",
      "loss: 0.076678  [35264/50000]\n",
      "loss: 0.040783  [35904/50000]\n",
      "loss: 0.041032  [36544/50000]\n",
      "loss: 0.213909  [37184/50000]\n",
      "loss: 0.073517  [37824/50000]\n",
      "loss: 0.059823  [38464/50000]\n",
      "loss: 0.040439  [39104/50000]\n",
      "loss: 0.057387  [39744/50000]\n",
      "loss: 0.034486  [40384/50000]\n",
      "loss: 0.064931  [41024/50000]\n",
      "loss: 0.020233  [41664/50000]\n",
      "loss: 0.040145  [42304/50000]\n",
      "loss: 0.079563  [42944/50000]\n",
      "loss: 0.022003  [43584/50000]\n",
      "loss: 0.056447  [44224/50000]\n",
      "loss: 0.130686  [44864/50000]\n",
      "loss: 0.173727  [45504/50000]\n",
      "loss: 0.113770  [46144/50000]\n",
      "loss: 0.042643  [46784/50000]\n",
      "loss: 0.151540  [47424/50000]\n",
      "loss: 0.005651  [48064/50000]\n",
      "loss: 0.023522  [48704/50000]\n",
      "loss: 0.231949  [49344/50000]\n",
      "loss: 0.099511  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.629167 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.006702  [   64/50000]\n",
      "loss: 0.117519  [  704/50000]\n",
      "loss: 0.056827  [ 1344/50000]\n",
      "loss: 0.039974  [ 1984/50000]\n",
      "loss: 0.023818  [ 2624/50000]\n",
      "loss: 0.036785  [ 3264/50000]\n",
      "loss: 0.021295  [ 3904/50000]\n",
      "loss: 0.053232  [ 4544/50000]\n",
      "loss: 0.008049  [ 5184/50000]\n",
      "loss: 0.007649  [ 5824/50000]\n",
      "loss: 0.046061  [ 6464/50000]\n",
      "loss: 0.029566  [ 7104/50000]\n",
      "loss: 0.068991  [ 7744/50000]\n",
      "loss: 0.002172  [ 8384/50000]\n",
      "loss: 0.080803  [ 9024/50000]\n",
      "loss: 0.007085  [ 9664/50000]\n",
      "loss: 0.038904  [10304/50000]\n",
      "loss: 0.008868  [10944/50000]\n",
      "loss: 0.082566  [11584/50000]\n",
      "loss: 0.097322  [12224/50000]\n",
      "loss: 0.037889  [12864/50000]\n",
      "loss: 0.027983  [13504/50000]\n",
      "loss: 0.036268  [14144/50000]\n",
      "loss: 0.014427  [14784/50000]\n",
      "loss: 0.052028  [15424/50000]\n",
      "loss: 0.014477  [16064/50000]\n",
      "loss: 0.011756  [16704/50000]\n",
      "loss: 0.022800  [17344/50000]\n",
      "loss: 0.067413  [17984/50000]\n",
      "loss: 0.123964  [18624/50000]\n",
      "loss: 0.047428  [19264/50000]\n",
      "loss: 0.026966  [19904/50000]\n",
      "loss: 0.044407  [20544/50000]\n",
      "loss: 0.095406  [21184/50000]\n",
      "loss: 0.017805  [21824/50000]\n",
      "loss: 0.024061  [22464/50000]\n",
      "loss: 0.016059  [23104/50000]\n",
      "loss: 0.147187  [23744/50000]\n",
      "loss: 0.019874  [24384/50000]\n",
      "loss: 0.015563  [25024/50000]\n",
      "loss: 0.061841  [25664/50000]\n",
      "loss: 0.103585  [26304/50000]\n",
      "loss: 0.137853  [26944/50000]\n",
      "loss: 0.029642  [27584/50000]\n",
      "loss: 0.014864  [28224/50000]\n",
      "loss: 0.012215  [28864/50000]\n",
      "loss: 0.007621  [29504/50000]\n",
      "loss: 0.113083  [30144/50000]\n",
      "loss: 0.031320  [30784/50000]\n",
      "loss: 0.011106  [31424/50000]\n",
      "loss: 0.075933  [32064/50000]\n",
      "loss: 0.017812  [32704/50000]\n",
      "loss: 0.077543  [33344/50000]\n",
      "loss: 0.004438  [33984/50000]\n",
      "loss: 0.084678  [34624/50000]\n",
      "loss: 0.039460  [35264/50000]\n",
      "loss: 0.086072  [35904/50000]\n",
      "loss: 0.071209  [36544/50000]\n",
      "loss: 0.030179  [37184/50000]\n",
      "loss: 0.047699  [37824/50000]\n",
      "loss: 0.010321  [38464/50000]\n",
      "loss: 0.055627  [39104/50000]\n",
      "loss: 0.030794  [39744/50000]\n",
      "loss: 0.040701  [40384/50000]\n",
      "loss: 0.024135  [41024/50000]\n",
      "loss: 0.012346  [41664/50000]\n",
      "loss: 0.019479  [42304/50000]\n",
      "loss: 0.113498  [42944/50000]\n",
      "loss: 0.069784  [43584/50000]\n",
      "loss: 0.074570  [44224/50000]\n",
      "loss: 0.159100  [44864/50000]\n",
      "loss: 0.096565  [45504/50000]\n",
      "loss: 0.130086  [46144/50000]\n",
      "loss: 0.153012  [46784/50000]\n",
      "loss: 0.021292  [47424/50000]\n",
      "loss: 0.032206  [48064/50000]\n",
      "loss: 0.095812  [48704/50000]\n",
      "loss: 0.011990  [49344/50000]\n",
      "loss: 0.041923  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.718319 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.045081  [   64/50000]\n",
      "loss: 0.199993  [  704/50000]\n",
      "loss: 0.048269  [ 1344/50000]\n",
      "loss: 0.050584  [ 1984/50000]\n",
      "loss: 0.007543  [ 2624/50000]\n",
      "loss: 0.035501  [ 3264/50000]\n",
      "loss: 0.049643  [ 3904/50000]\n",
      "loss: 0.056913  [ 4544/50000]\n",
      "loss: 0.021690  [ 5184/50000]\n",
      "loss: 0.039917  [ 5824/50000]\n",
      "loss: 0.014978  [ 6464/50000]\n",
      "loss: 0.090827  [ 7104/50000]\n",
      "loss: 0.006257  [ 7744/50000]\n",
      "loss: 0.032675  [ 8384/50000]\n",
      "loss: 0.014635  [ 9024/50000]\n",
      "loss: 0.032932  [ 9664/50000]\n",
      "loss: 0.127948  [10304/50000]\n",
      "loss: 0.049504  [10944/50000]\n",
      "loss: 0.008745  [11584/50000]\n",
      "loss: 0.096329  [12224/50000]\n",
      "loss: 0.021712  [12864/50000]\n",
      "loss: 0.009605  [13504/50000]\n",
      "loss: 0.006897  [14144/50000]\n",
      "loss: 0.059731  [14784/50000]\n",
      "loss: 0.010024  [15424/50000]\n",
      "loss: 0.024865  [16064/50000]\n",
      "loss: 0.029449  [16704/50000]\n",
      "loss: 0.035527  [17344/50000]\n",
      "loss: 0.017722  [17984/50000]\n",
      "loss: 0.007952  [18624/50000]\n",
      "loss: 0.022072  [19264/50000]\n",
      "loss: 0.011096  [19904/50000]\n",
      "loss: 0.027446  [20544/50000]\n",
      "loss: 0.014194  [21184/50000]\n",
      "loss: 0.030924  [21824/50000]\n",
      "loss: 0.004394  [22464/50000]\n",
      "loss: 0.075733  [23104/50000]\n",
      "loss: 0.003021  [23744/50000]\n",
      "loss: 0.024794  [24384/50000]\n",
      "loss: 0.019950  [25024/50000]\n",
      "loss: 0.009110  [25664/50000]\n",
      "loss: 0.039112  [26304/50000]\n",
      "loss: 0.050166  [26944/50000]\n",
      "loss: 0.031310  [27584/50000]\n",
      "loss: 0.018527  [28224/50000]\n",
      "loss: 0.024176  [28864/50000]\n",
      "loss: 0.038553  [29504/50000]\n",
      "loss: 0.054093  [30144/50000]\n",
      "loss: 0.045309  [30784/50000]\n",
      "loss: 0.023985  [31424/50000]\n",
      "loss: 0.048910  [32064/50000]\n",
      "loss: 0.015402  [32704/50000]\n",
      "loss: 0.184599  [33344/50000]\n",
      "loss: 0.032609  [33984/50000]\n",
      "loss: 0.058698  [34624/50000]\n",
      "loss: 0.038596  [35264/50000]\n",
      "loss: 0.178374  [35904/50000]\n",
      "loss: 0.060295  [36544/50000]\n",
      "loss: 0.040460  [37184/50000]\n",
      "loss: 0.052037  [37824/50000]\n",
      "loss: 0.029600  [38464/50000]\n",
      "loss: 0.021667  [39104/50000]\n",
      "loss: 0.015505  [39744/50000]\n",
      "loss: 0.031595  [40384/50000]\n",
      "loss: 0.114297  [41024/50000]\n",
      "loss: 0.031033  [41664/50000]\n",
      "loss: 0.128098  [42304/50000]\n",
      "loss: 0.050614  [42944/50000]\n",
      "loss: 0.046381  [43584/50000]\n",
      "loss: 0.019967  [44224/50000]\n",
      "loss: 0.093444  [44864/50000]\n",
      "loss: 0.025437  [45504/50000]\n",
      "loss: 0.033725  [46144/50000]\n",
      "loss: 0.083562  [46784/50000]\n",
      "loss: 0.033062  [47424/50000]\n",
      "loss: 0.045887  [48064/50000]\n",
      "loss: 0.035988  [48704/50000]\n",
      "loss: 0.086413  [49344/50000]\n",
      "loss: 0.004352  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.681481 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.003431  [   64/50000]\n",
      "loss: 0.036074  [  704/50000]\n",
      "loss: 0.100644  [ 1344/50000]\n",
      "loss: 0.047307  [ 1984/50000]\n",
      "loss: 0.019260  [ 2624/50000]\n",
      "loss: 0.039647  [ 3264/50000]\n",
      "loss: 0.014400  [ 3904/50000]\n",
      "loss: 0.036565  [ 4544/50000]\n",
      "loss: 0.037906  [ 5184/50000]\n",
      "loss: 0.030185  [ 5824/50000]\n",
      "loss: 0.031942  [ 6464/50000]\n",
      "loss: 0.027434  [ 7104/50000]\n",
      "loss: 0.032470  [ 7744/50000]\n",
      "loss: 0.119676  [ 8384/50000]\n",
      "loss: 0.051812  [ 9024/50000]\n",
      "loss: 0.026044  [ 9664/50000]\n",
      "loss: 0.021267  [10304/50000]\n",
      "loss: 0.031179  [10944/50000]\n",
      "loss: 0.083127  [11584/50000]\n",
      "loss: 0.002295  [12224/50000]\n",
      "loss: 0.004038  [12864/50000]\n",
      "loss: 0.095000  [13504/50000]\n",
      "loss: 0.028773  [14144/50000]\n",
      "loss: 0.013461  [14784/50000]\n",
      "loss: 0.045486  [15424/50000]\n",
      "loss: 0.034181  [16064/50000]\n",
      "loss: 0.043271  [16704/50000]\n",
      "loss: 0.020995  [17344/50000]\n",
      "loss: 0.010849  [17984/50000]\n",
      "loss: 0.008941  [18624/50000]\n",
      "loss: 0.024786  [19264/50000]\n",
      "loss: 0.168798  [19904/50000]\n",
      "loss: 0.009967  [20544/50000]\n",
      "loss: 0.062361  [21184/50000]\n",
      "loss: 0.071040  [21824/50000]\n",
      "loss: 0.045513  [22464/50000]\n",
      "loss: 0.005861  [23104/50000]\n",
      "loss: 0.115787  [23744/50000]\n",
      "loss: 0.026507  [24384/50000]\n",
      "loss: 0.012164  [25024/50000]\n",
      "loss: 0.003700  [25664/50000]\n",
      "loss: 0.041083  [26304/50000]\n",
      "loss: 0.044427  [26944/50000]\n",
      "loss: 0.102325  [27584/50000]\n",
      "loss: 0.065899  [28224/50000]\n",
      "loss: 0.008331  [28864/50000]\n",
      "loss: 0.015123  [29504/50000]\n",
      "loss: 0.062160  [30144/50000]\n",
      "loss: 0.033692  [30784/50000]\n",
      "loss: 0.137344  [31424/50000]\n",
      "loss: 0.085023  [32064/50000]\n",
      "loss: 0.036042  [32704/50000]\n",
      "loss: 0.012065  [33344/50000]\n",
      "loss: 0.079720  [33984/50000]\n",
      "loss: 0.149482  [34624/50000]\n",
      "loss: 0.023689  [35264/50000]\n",
      "loss: 0.044903  [35904/50000]\n",
      "loss: 0.052735  [36544/50000]\n",
      "loss: 0.016254  [37184/50000]\n",
      "loss: 0.027140  [37824/50000]\n",
      "loss: 0.033887  [38464/50000]\n",
      "loss: 0.124596  [39104/50000]\n",
      "loss: 0.067975  [39744/50000]\n",
      "loss: 0.057285  [40384/50000]\n",
      "loss: 0.100420  [41024/50000]\n",
      "loss: 0.219138  [41664/50000]\n",
      "loss: 0.018574  [42304/50000]\n",
      "loss: 0.017550  [42944/50000]\n",
      "loss: 0.078108  [43584/50000]\n",
      "loss: 0.034253  [44224/50000]\n",
      "loss: 0.011867  [44864/50000]\n",
      "loss: 0.008634  [45504/50000]\n",
      "loss: 0.145175  [46144/50000]\n",
      "loss: 0.026844  [46784/50000]\n",
      "loss: 0.048876  [47424/50000]\n",
      "loss: 0.167140  [48064/50000]\n",
      "loss: 0.016430  [48704/50000]\n",
      "loss: 0.058904  [49344/50000]\n",
      "loss: 0.027289  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.797002 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.021246  [   64/50000]\n",
      "loss: 0.026545  [  704/50000]\n",
      "loss: 0.099975  [ 1344/50000]\n",
      "loss: 0.017300  [ 1984/50000]\n",
      "loss: 0.015524  [ 2624/50000]\n",
      "loss: 0.022418  [ 3264/50000]\n",
      "loss: 0.039779  [ 3904/50000]\n",
      "loss: 0.014302  [ 4544/50000]\n",
      "loss: 0.140459  [ 5184/50000]\n",
      "loss: 0.016058  [ 5824/50000]\n",
      "loss: 0.007713  [ 6464/50000]\n",
      "loss: 0.018560  [ 7104/50000]\n",
      "loss: 0.004427  [ 7744/50000]\n",
      "loss: 0.059360  [ 8384/50000]\n",
      "loss: 0.007865  [ 9024/50000]\n",
      "loss: 0.074324  [ 9664/50000]\n",
      "loss: 0.017860  [10304/50000]\n",
      "loss: 0.015872  [10944/50000]\n",
      "loss: 0.002566  [11584/50000]\n",
      "loss: 0.021217  [12224/50000]\n",
      "loss: 0.032785  [12864/50000]\n",
      "loss: 0.024949  [13504/50000]\n",
      "loss: 0.007412  [14144/50000]\n",
      "loss: 0.025196  [14784/50000]\n",
      "loss: 0.031179  [15424/50000]\n",
      "loss: 0.013694  [16064/50000]\n",
      "loss: 0.038754  [16704/50000]\n",
      "loss: 0.010431  [17344/50000]\n",
      "loss: 0.062092  [17984/50000]\n",
      "loss: 0.015619  [18624/50000]\n",
      "loss: 0.002339  [19264/50000]\n",
      "loss: 0.026949  [19904/50000]\n",
      "loss: 0.063839  [20544/50000]\n",
      "loss: 0.044584  [21184/50000]\n",
      "loss: 0.002481  [21824/50000]\n",
      "loss: 0.054178  [22464/50000]\n",
      "loss: 0.122826  [23104/50000]\n",
      "loss: 0.079500  [23744/50000]\n",
      "loss: 0.009875  [24384/50000]\n",
      "loss: 0.058307  [25024/50000]\n",
      "loss: 0.014749  [25664/50000]\n",
      "loss: 0.008032  [26304/50000]\n",
      "loss: 0.011000  [26944/50000]\n",
      "loss: 0.005766  [27584/50000]\n",
      "loss: 0.015349  [28224/50000]\n",
      "loss: 0.054615  [28864/50000]\n",
      "loss: 0.010785  [29504/50000]\n",
      "loss: 0.058630  [30144/50000]\n",
      "loss: 0.036759  [30784/50000]\n",
      "loss: 0.004664  [31424/50000]\n",
      "loss: 0.003573  [32064/50000]\n",
      "loss: 0.104618  [32704/50000]\n",
      "loss: 0.035774  [33344/50000]\n",
      "loss: 0.017204  [33984/50000]\n",
      "loss: 0.027747  [34624/50000]\n",
      "loss: 0.022200  [35264/50000]\n",
      "loss: 0.099279  [35904/50000]\n",
      "loss: 0.096349  [36544/50000]\n",
      "loss: 0.045474  [37184/50000]\n",
      "loss: 0.004568  [37824/50000]\n",
      "loss: 0.018268  [38464/50000]\n",
      "loss: 0.028433  [39104/50000]\n",
      "loss: 0.189770  [39744/50000]\n",
      "loss: 0.056140  [40384/50000]\n",
      "loss: 0.043880  [41024/50000]\n",
      "loss: 0.044873  [41664/50000]\n",
      "loss: 0.050222  [42304/50000]\n",
      "loss: 0.029290  [42944/50000]\n",
      "loss: 0.013176  [43584/50000]\n",
      "loss: 0.051418  [44224/50000]\n",
      "loss: 0.103601  [44864/50000]\n",
      "loss: 0.037528  [45504/50000]\n",
      "loss: 0.004862  [46144/50000]\n",
      "loss: 0.062818  [46784/50000]\n",
      "loss: 0.130570  [47424/50000]\n",
      "loss: 0.030488  [48064/50000]\n",
      "loss: 0.083095  [48704/50000]\n",
      "loss: 0.008551  [49344/50000]\n",
      "loss: 0.085340  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.826769 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.070095  [   64/50000]\n",
      "loss: 0.061134  [  704/50000]\n",
      "loss: 0.067223  [ 1344/50000]\n",
      "loss: 0.071180  [ 1984/50000]\n",
      "loss: 0.019673  [ 2624/50000]\n",
      "loss: 0.026271  [ 3264/50000]\n",
      "loss: 0.032390  [ 3904/50000]\n",
      "loss: 0.087082  [ 4544/50000]\n",
      "loss: 0.003084  [ 5184/50000]\n",
      "loss: 0.018415  [ 5824/50000]\n",
      "loss: 0.011939  [ 6464/50000]\n",
      "loss: 0.005974  [ 7104/50000]\n",
      "loss: 0.009903  [ 7744/50000]\n",
      "loss: 0.021815  [ 8384/50000]\n",
      "loss: 0.021491  [ 9024/50000]\n",
      "loss: 0.026618  [ 9664/50000]\n",
      "loss: 0.040539  [10304/50000]\n",
      "loss: 0.038657  [10944/50000]\n",
      "loss: 0.054952  [11584/50000]\n",
      "loss: 0.025505  [12224/50000]\n",
      "loss: 0.014118  [12864/50000]\n",
      "loss: 0.009745  [13504/50000]\n",
      "loss: 0.024941  [14144/50000]\n",
      "loss: 0.016804  [14784/50000]\n",
      "loss: 0.018178  [15424/50000]\n",
      "loss: 0.038214  [16064/50000]\n",
      "loss: 0.040898  [16704/50000]\n",
      "loss: 0.001350  [17344/50000]\n",
      "loss: 0.013359  [17984/50000]\n",
      "loss: 0.004769  [18624/50000]\n",
      "loss: 0.019491  [19264/50000]\n",
      "loss: 0.027397  [19904/50000]\n",
      "loss: 0.019927  [20544/50000]\n",
      "loss: 0.020693  [21184/50000]\n",
      "loss: 0.075982  [21824/50000]\n",
      "loss: 0.008403  [22464/50000]\n",
      "loss: 0.059406  [23104/50000]\n",
      "loss: 0.007332  [23744/50000]\n",
      "loss: 0.040618  [24384/50000]\n",
      "loss: 0.017764  [25024/50000]\n",
      "loss: 0.014500  [25664/50000]\n",
      "loss: 0.007363  [26304/50000]\n",
      "loss: 0.098403  [26944/50000]\n",
      "loss: 0.020851  [27584/50000]\n",
      "loss: 0.007604  [28224/50000]\n",
      "loss: 0.038407  [28864/50000]\n",
      "loss: 0.022741  [29504/50000]\n",
      "loss: 0.021823  [30144/50000]\n",
      "loss: 0.120361  [30784/50000]\n",
      "loss: 0.026397  [31424/50000]\n",
      "loss: 0.038287  [32064/50000]\n",
      "loss: 0.090865  [32704/50000]\n",
      "loss: 0.022810  [33344/50000]\n",
      "loss: 0.048835  [33984/50000]\n",
      "loss: 0.021196  [34624/50000]\n",
      "loss: 0.016131  [35264/50000]\n",
      "loss: 0.016630  [35904/50000]\n",
      "loss: 0.021720  [36544/50000]\n",
      "loss: 0.002593  [37184/50000]\n",
      "loss: 0.054906  [37824/50000]\n",
      "loss: 0.096183  [38464/50000]\n",
      "loss: 0.013801  [39104/50000]\n",
      "loss: 0.056206  [39744/50000]\n",
      "loss: 0.337047  [40384/50000]\n",
      "loss: 0.053683  [41024/50000]\n",
      "loss: 0.014707  [41664/50000]\n",
      "loss: 0.063637  [42304/50000]\n",
      "loss: 0.023892  [42944/50000]\n",
      "loss: 0.020014  [43584/50000]\n",
      "loss: 0.039103  [44224/50000]\n",
      "loss: 0.003650  [44864/50000]\n",
      "loss: 0.051925  [45504/50000]\n",
      "loss: 0.007050  [46144/50000]\n",
      "loss: 0.052274  [46784/50000]\n",
      "loss: 0.027583  [47424/50000]\n",
      "loss: 0.062435  [48064/50000]\n",
      "loss: 0.069533  [48704/50000]\n",
      "loss: 0.045646  [49344/50000]\n",
      "loss: 0.008854  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.753997 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.160812  [   64/50000]\n",
      "loss: 0.014029  [  704/50000]\n",
      "loss: 0.076458  [ 1344/50000]\n",
      "loss: 0.034204  [ 1984/50000]\n",
      "loss: 0.009194  [ 2624/50000]\n",
      "loss: 0.044250  [ 3264/50000]\n",
      "loss: 0.001690  [ 3904/50000]\n",
      "loss: 0.011974  [ 4544/50000]\n",
      "loss: 0.002135  [ 5184/50000]\n",
      "loss: 0.004620  [ 5824/50000]\n",
      "loss: 0.012590  [ 6464/50000]\n",
      "loss: 0.001774  [ 7104/50000]\n",
      "loss: 0.028262  [ 7744/50000]\n",
      "loss: 0.024747  [ 8384/50000]\n",
      "loss: 0.017014  [ 9024/50000]\n",
      "loss: 0.032674  [ 9664/50000]\n",
      "loss: 0.013220  [10304/50000]\n",
      "loss: 0.010689  [10944/50000]\n",
      "loss: 0.030307  [11584/50000]\n",
      "loss: 0.063560  [12224/50000]\n",
      "loss: 0.042161  [12864/50000]\n",
      "loss: 0.005545  [13504/50000]\n",
      "loss: 0.040140  [14144/50000]\n",
      "loss: 0.056427  [14784/50000]\n",
      "loss: 0.092718  [15424/50000]\n",
      "loss: 0.024863  [16064/50000]\n",
      "loss: 0.055206  [16704/50000]\n",
      "loss: 0.041292  [17344/50000]\n",
      "loss: 0.021698  [17984/50000]\n",
      "loss: 0.005894  [18624/50000]\n",
      "loss: 0.016022  [19264/50000]\n",
      "loss: 0.009070  [19904/50000]\n",
      "loss: 0.008787  [20544/50000]\n",
      "loss: 0.004842  [21184/50000]\n",
      "loss: 0.001145  [21824/50000]\n",
      "loss: 0.003709  [22464/50000]\n",
      "loss: 0.008364  [23104/50000]\n",
      "loss: 0.007755  [23744/50000]\n",
      "loss: 0.041406  [24384/50000]\n",
      "loss: 0.000541  [25024/50000]\n",
      "loss: 0.022959  [25664/50000]\n",
      "loss: 0.061353  [26304/50000]\n",
      "loss: 0.034120  [26944/50000]\n",
      "loss: 0.004138  [27584/50000]\n",
      "loss: 0.168166  [28224/50000]\n",
      "loss: 0.053769  [28864/50000]\n",
      "loss: 0.010552  [29504/50000]\n",
      "loss: 0.054505  [30144/50000]\n",
      "loss: 0.201002  [30784/50000]\n",
      "loss: 0.095558  [31424/50000]\n",
      "loss: 0.007992  [32064/50000]\n",
      "loss: 0.049718  [32704/50000]\n",
      "loss: 0.065058  [33344/50000]\n",
      "loss: 0.027514  [33984/50000]\n",
      "loss: 0.099417  [34624/50000]\n",
      "loss: 0.056159  [35264/50000]\n",
      "loss: 0.004374  [35904/50000]\n",
      "loss: 0.006104  [36544/50000]\n",
      "loss: 0.007953  [37184/50000]\n",
      "loss: 0.001422  [37824/50000]\n",
      "loss: 0.122282  [38464/50000]\n",
      "loss: 0.165126  [39104/50000]\n",
      "loss: 0.006542  [39744/50000]\n",
      "loss: 0.007123  [40384/50000]\n",
      "loss: 0.024486  [41024/50000]\n",
      "loss: 0.017672  [41664/50000]\n",
      "loss: 0.007404  [42304/50000]\n",
      "loss: 0.006276  [42944/50000]\n",
      "loss: 0.031373  [43584/50000]\n",
      "loss: 0.028474  [44224/50000]\n",
      "loss: 0.035929  [44864/50000]\n",
      "loss: 0.056379  [45504/50000]\n",
      "loss: 0.031694  [46144/50000]\n",
      "loss: 0.028794  [46784/50000]\n",
      "loss: 0.007130  [47424/50000]\n",
      "loss: 0.020464  [48064/50000]\n",
      "loss: 0.028893  [48704/50000]\n",
      "loss: 0.005761  [49344/50000]\n",
      "loss: 0.004790  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.719344 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.035708  [   64/50000]\n",
      "loss: 0.025338  [  704/50000]\n",
      "loss: 0.003534  [ 1344/50000]\n",
      "loss: 0.002840  [ 1984/50000]\n",
      "loss: 0.007697  [ 2624/50000]\n",
      "loss: 0.002033  [ 3264/50000]\n",
      "loss: 0.023583  [ 3904/50000]\n",
      "loss: 0.055923  [ 4544/50000]\n",
      "loss: 0.001450  [ 5184/50000]\n",
      "loss: 0.024619  [ 5824/50000]\n",
      "loss: 0.003883  [ 6464/50000]\n",
      "loss: 0.065292  [ 7104/50000]\n",
      "loss: 0.018300  [ 7744/50000]\n",
      "loss: 0.003295  [ 8384/50000]\n",
      "loss: 0.010575  [ 9024/50000]\n",
      "loss: 0.012888  [ 9664/50000]\n",
      "loss: 0.004505  [10304/50000]\n",
      "loss: 0.035026  [10944/50000]\n",
      "loss: 0.014297  [11584/50000]\n",
      "loss: 0.027531  [12224/50000]\n",
      "loss: 0.027576  [12864/50000]\n",
      "loss: 0.010922  [13504/50000]\n",
      "loss: 0.010093  [14144/50000]\n",
      "loss: 0.003442  [14784/50000]\n",
      "loss: 0.018530  [15424/50000]\n",
      "loss: 0.008733  [16064/50000]\n",
      "loss: 0.004100  [16704/50000]\n",
      "loss: 0.002509  [17344/50000]\n",
      "loss: 0.007280  [17984/50000]\n",
      "loss: 0.004459  [18624/50000]\n",
      "loss: 0.007370  [19264/50000]\n",
      "loss: 0.006907  [19904/50000]\n",
      "loss: 0.030322  [20544/50000]\n",
      "loss: 0.001011  [21184/50000]\n",
      "loss: 0.038578  [21824/50000]\n",
      "loss: 0.191299  [22464/50000]\n",
      "loss: 0.027433  [23104/50000]\n",
      "loss: 0.010770  [23744/50000]\n",
      "loss: 0.006634  [24384/50000]\n",
      "loss: 0.002762  [25024/50000]\n",
      "loss: 0.047783  [25664/50000]\n",
      "loss: 0.029111  [26304/50000]\n",
      "loss: 0.065183  [26944/50000]\n",
      "loss: 0.003856  [27584/50000]\n",
      "loss: 0.049747  [28224/50000]\n",
      "loss: 0.051163  [28864/50000]\n",
      "loss: 0.030979  [29504/50000]\n",
      "loss: 0.156946  [30144/50000]\n",
      "loss: 0.004012  [30784/50000]\n",
      "loss: 0.071906  [31424/50000]\n",
      "loss: 0.043649  [32064/50000]\n",
      "loss: 0.004727  [32704/50000]\n",
      "loss: 0.129815  [33344/50000]\n",
      "loss: 0.034728  [33984/50000]\n",
      "loss: 0.005560  [34624/50000]\n",
      "loss: 0.060246  [35264/50000]\n",
      "loss: 0.006942  [35904/50000]\n",
      "loss: 0.055233  [36544/50000]\n",
      "loss: 0.006487  [37184/50000]\n",
      "loss: 0.079462  [37824/50000]\n",
      "loss: 0.088718  [38464/50000]\n",
      "loss: 0.029667  [39104/50000]\n",
      "loss: 0.159876  [39744/50000]\n",
      "loss: 0.058872  [40384/50000]\n",
      "loss: 0.041916  [41024/50000]\n",
      "loss: 0.081100  [41664/50000]\n",
      "loss: 0.004301  [42304/50000]\n",
      "loss: 0.049612  [42944/50000]\n",
      "loss: 0.077371  [43584/50000]\n",
      "loss: 0.081015  [44224/50000]\n",
      "loss: 0.016000  [44864/50000]\n",
      "loss: 0.027097  [45504/50000]\n",
      "loss: 0.011832  [46144/50000]\n",
      "loss: 0.070725  [46784/50000]\n",
      "loss: 0.118021  [47424/50000]\n",
      "loss: 0.121660  [48064/50000]\n",
      "loss: 0.010579  [48704/50000]\n",
      "loss: 0.004027  [49344/50000]\n",
      "loss: 0.021919  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.745947 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.008924  [   64/50000]\n",
      "loss: 0.005725  [  704/50000]\n",
      "loss: 0.119017  [ 1344/50000]\n",
      "loss: 0.026038  [ 1984/50000]\n",
      "loss: 0.051934  [ 2624/50000]\n",
      "loss: 0.002934  [ 3264/50000]\n",
      "loss: 0.037184  [ 3904/50000]\n",
      "loss: 0.056666  [ 4544/50000]\n",
      "loss: 0.006430  [ 5184/50000]\n",
      "loss: 0.053809  [ 5824/50000]\n",
      "loss: 0.036930  [ 6464/50000]\n",
      "loss: 0.005963  [ 7104/50000]\n",
      "loss: 0.140214  [ 7744/50000]\n",
      "loss: 0.024596  [ 8384/50000]\n",
      "loss: 0.005173  [ 9024/50000]\n",
      "loss: 0.006956  [ 9664/50000]\n",
      "loss: 0.011415  [10304/50000]\n",
      "loss: 0.030242  [10944/50000]\n",
      "loss: 0.005704  [11584/50000]\n",
      "loss: 0.057033  [12224/50000]\n",
      "loss: 0.038159  [12864/50000]\n",
      "loss: 0.012883  [13504/50000]\n",
      "loss: 0.011099  [14144/50000]\n",
      "loss: 0.002210  [14784/50000]\n",
      "loss: 0.066913  [15424/50000]\n",
      "loss: 0.008543  [16064/50000]\n",
      "loss: 0.046036  [16704/50000]\n",
      "loss: 0.041789  [17344/50000]\n",
      "loss: 0.014001  [17984/50000]\n",
      "loss: 0.005013  [18624/50000]\n",
      "loss: 0.023428  [19264/50000]\n",
      "loss: 0.004434  [19904/50000]\n",
      "loss: 0.063460  [20544/50000]\n",
      "loss: 0.014397  [21184/50000]\n",
      "loss: 0.034898  [21824/50000]\n",
      "loss: 0.001129  [22464/50000]\n",
      "loss: 0.039673  [23104/50000]\n",
      "loss: 0.030271  [23744/50000]\n",
      "loss: 0.036135  [24384/50000]\n",
      "loss: 0.001491  [25024/50000]\n",
      "loss: 0.066682  [25664/50000]\n",
      "loss: 0.039737  [26304/50000]\n",
      "loss: 0.027873  [26944/50000]\n",
      "loss: 0.006682  [27584/50000]\n",
      "loss: 0.036027  [28224/50000]\n",
      "loss: 0.001726  [28864/50000]\n",
      "loss: 0.010691  [29504/50000]\n",
      "loss: 0.001230  [30144/50000]\n",
      "loss: 0.074288  [30784/50000]\n",
      "loss: 0.054825  [31424/50000]\n",
      "loss: 0.007267  [32064/50000]\n",
      "loss: 0.011647  [32704/50000]\n",
      "loss: 0.060313  [33344/50000]\n",
      "loss: 0.002208  [33984/50000]\n",
      "loss: 0.059607  [34624/50000]\n",
      "loss: 0.005311  [35264/50000]\n",
      "loss: 0.003641  [35904/50000]\n",
      "loss: 0.015286  [36544/50000]\n",
      "loss: 0.007283  [37184/50000]\n",
      "loss: 0.004607  [37824/50000]\n",
      "loss: 0.021538  [38464/50000]\n",
      "loss: 0.020386  [39104/50000]\n",
      "loss: 0.052474  [39744/50000]\n",
      "loss: 0.023254  [40384/50000]\n",
      "loss: 0.018787  [41024/50000]\n",
      "loss: 0.131844  [41664/50000]\n",
      "loss: 0.009498  [42304/50000]\n",
      "loss: 0.003260  [42944/50000]\n",
      "loss: 0.125099  [43584/50000]\n",
      "loss: 0.010675  [44224/50000]\n",
      "loss: 0.080115  [44864/50000]\n",
      "loss: 0.008109  [45504/50000]\n",
      "loss: 0.088967  [46144/50000]\n",
      "loss: 0.014508  [46784/50000]\n",
      "loss: 0.039237  [47424/50000]\n",
      "loss: 0.033397  [48064/50000]\n",
      "loss: 0.011502  [48704/50000]\n",
      "loss: 0.138003  [49344/50000]\n",
      "loss: 0.098447  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.777855 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▅▆▇▇▇▇██▇██████████</td></tr><tr><td>test_loss</td><td>█▄▃▂▂▂▂▁▂▃▃▂▃▃▄▄▄▃▄▄</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8463</td></tr><tr><td>test_loss</td><td>0.77785</td></tr><tr><td>train_loss</td><td>0.03115</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet_2</strong> at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/8hocx09h' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/8hocx09h</a><br> View project at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250502_151449-8hocx09h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "trainset, testset = get_data()\n",
    "\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "net = resnet_model\n",
    "net.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"ML2_4_2\",\n",
    "    # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=\"resnet_2\",\n",
    ")\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, net, loss_fn, optimizer, device)\n",
    "    test_loop(testloader, net, loss_fn, device)\n",
    "\n",
    "torch.save(net.state_dict(), \"model_weights.pth\")\n",
    "torch.save(optimizer.state_dict(), \"optimizer_settings.pth\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1746188490246,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "udKqzTeu5lKa",
    "outputId": "f69e3dcc-a798-44dd-8533-e186f39b6b4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▅█</td></tr><tr><td>test_loss</td><td>█▃▁</td></tr><tr><td>train_loss</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.7215</td></tr><tr><td>test_loss</td><td>0.79843</td></tr><tr><td>train_loss</td><td>0.87406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet_1</strong> at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/eu0e6xej' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/eu0e6xej</a><br> View project at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250502_120858-eu0e6xej/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qj8eE-wE6_p9"
   },
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D11iRfPn6_qC"
   },
   "outputs": [],
   "source": [
    "vgg_model = vgg13(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJlmN69y6_qE"
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6234716,
     "status": "error",
     "timestamp": 1746210080526,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "uFr4kKif6_qG",
    "outputId": "9d052455-a56c-435b-bc2b-1200741824e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250502_163727-4u7wlwg0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/4u7wlwg0' target=\"_blank\">vgg3</a></strong> to <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/4u7wlwg0' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/4u7wlwg0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.316156  [   64/50000]\n",
      "loss: 2.297116  [  704/50000]\n",
      "loss: 2.308151  [ 1344/50000]\n",
      "loss: 2.511289  [ 1984/50000]\n",
      "loss: 2.296706  [ 2624/50000]\n",
      "loss: 2.300126  [ 3264/50000]\n",
      "loss: 2.301713  [ 3904/50000]\n",
      "loss: 2.309482  [ 4544/50000]\n",
      "loss: 2.302911  [ 5184/50000]\n",
      "loss: 2.296366  [ 5824/50000]\n",
      "loss: 2.282675  [ 6464/50000]\n",
      "loss: 2.256222  [ 7104/50000]\n",
      "loss: 2.183543  [ 7744/50000]\n",
      "loss: 2.275263  [ 8384/50000]\n",
      "loss: 2.279922  [ 9024/50000]\n",
      "loss: 2.157320  [ 9664/50000]\n",
      "loss: 2.099302  [10304/50000]\n",
      "loss: 1.942390  [10944/50000]\n",
      "loss: 1.945312  [11584/50000]\n",
      "loss: 1.874749  [12224/50000]\n",
      "loss: 1.805930  [12864/50000]\n",
      "loss: 1.960619  [13504/50000]\n",
      "loss: 1.871050  [14144/50000]\n",
      "loss: 1.862402  [14784/50000]\n",
      "loss: 1.879248  [15424/50000]\n",
      "loss: 1.891916  [16064/50000]\n",
      "loss: 1.659115  [16704/50000]\n",
      "loss: 1.753145  [17344/50000]\n",
      "loss: 1.919910  [17984/50000]\n",
      "loss: 1.807973  [18624/50000]\n",
      "loss: 1.611064  [19264/50000]\n",
      "loss: 1.756188  [19904/50000]\n",
      "loss: 1.840690  [20544/50000]\n",
      "loss: 1.833753  [21184/50000]\n",
      "loss: 1.891035  [21824/50000]\n",
      "loss: 1.717033  [22464/50000]\n",
      "loss: 1.903964  [23104/50000]\n",
      "loss: 1.798258  [23744/50000]\n",
      "loss: 1.750214  [24384/50000]\n",
      "loss: 1.925884  [25024/50000]\n",
      "loss: 1.594015  [25664/50000]\n",
      "loss: 1.625109  [26304/50000]\n",
      "loss: 1.778760  [26944/50000]\n",
      "loss: 1.519346  [27584/50000]\n",
      "loss: 1.769910  [28224/50000]\n",
      "loss: 1.585178  [28864/50000]\n",
      "loss: 1.697350  [29504/50000]\n",
      "loss: 1.496187  [30144/50000]\n",
      "loss: 1.642351  [30784/50000]\n",
      "loss: 1.833957  [31424/50000]\n",
      "loss: 1.553210  [32064/50000]\n",
      "loss: 1.874417  [32704/50000]\n",
      "loss: 1.557870  [33344/50000]\n",
      "loss: 1.577668  [33984/50000]\n",
      "loss: 1.661381  [34624/50000]\n",
      "loss: 1.650011  [35264/50000]\n",
      "loss: 1.506702  [35904/50000]\n",
      "loss: 1.291913  [36544/50000]\n",
      "loss: 1.619051  [37184/50000]\n",
      "loss: 1.633502  [37824/50000]\n",
      "loss: 1.605244  [38464/50000]\n",
      "loss: 1.427340  [39104/50000]\n",
      "loss: 1.436436  [39744/50000]\n",
      "loss: 1.775676  [40384/50000]\n",
      "loss: 1.851471  [41024/50000]\n",
      "loss: 1.531237  [41664/50000]\n",
      "loss: 1.556425  [42304/50000]\n",
      "loss: 1.674348  [42944/50000]\n",
      "loss: 1.559504  [43584/50000]\n",
      "loss: 1.272056  [44224/50000]\n",
      "loss: 1.534102  [44864/50000]\n",
      "loss: 1.576355  [45504/50000]\n",
      "loss: 1.610036  [46144/50000]\n",
      "loss: 1.503862  [46784/50000]\n",
      "loss: 1.601572  [47424/50000]\n",
      "loss: 1.672221  [48064/50000]\n",
      "loss: 1.610896  [48704/50000]\n",
      "loss: 1.638167  [49344/50000]\n",
      "loss: 1.585843  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 1.526312 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.569304  [   64/50000]\n",
      "loss: 1.437042  [  704/50000]\n",
      "loss: 1.586246  [ 1344/50000]\n",
      "loss: 1.531941  [ 1984/50000]\n",
      "loss: 1.508659  [ 2624/50000]\n",
      "loss: 1.527549  [ 3264/50000]\n",
      "loss: 1.454222  [ 3904/50000]\n",
      "loss: 1.476376  [ 4544/50000]\n",
      "loss: 1.383039  [ 5184/50000]\n",
      "loss: 1.403355  [ 5824/50000]\n",
      "loss: 1.465560  [ 6464/50000]\n",
      "loss: 1.444916  [ 7104/50000]\n",
      "loss: 1.342662  [ 7744/50000]\n",
      "loss: 1.297145  [ 8384/50000]\n",
      "loss: 1.373748  [ 9024/50000]\n",
      "loss: 1.622794  [ 9664/50000]\n",
      "loss: 1.374518  [10304/50000]\n",
      "loss: 1.452925  [10944/50000]\n",
      "loss: 1.411436  [11584/50000]\n",
      "loss: 1.457767  [12224/50000]\n",
      "loss: 1.310012  [12864/50000]\n",
      "loss: 1.439406  [13504/50000]\n",
      "loss: 1.460795  [14144/50000]\n",
      "loss: 1.546516  [14784/50000]\n",
      "loss: 1.424478  [15424/50000]\n",
      "loss: 1.219192  [16064/50000]\n",
      "loss: 1.320461  [16704/50000]\n",
      "loss: 1.531073  [17344/50000]\n",
      "loss: 1.321027  [17984/50000]\n",
      "loss: 1.496313  [18624/50000]\n",
      "loss: 1.257527  [19264/50000]\n",
      "loss: 1.378681  [19904/50000]\n",
      "loss: 1.180448  [20544/50000]\n",
      "loss: 1.265080  [21184/50000]\n",
      "loss: 1.490668  [21824/50000]\n",
      "loss: 1.287967  [22464/50000]\n",
      "loss: 1.336625  [23104/50000]\n",
      "loss: 1.361052  [23744/50000]\n",
      "loss: 1.182226  [24384/50000]\n",
      "loss: 1.239469  [25024/50000]\n",
      "loss: 1.497674  [25664/50000]\n",
      "loss: 1.354291  [26304/50000]\n",
      "loss: 1.314194  [26944/50000]\n",
      "loss: 1.050509  [27584/50000]\n",
      "loss: 1.467057  [28224/50000]\n",
      "loss: 1.490740  [28864/50000]\n",
      "loss: 1.430043  [29504/50000]\n",
      "loss: 1.070509  [30144/50000]\n",
      "loss: 1.437996  [30784/50000]\n",
      "loss: 1.467721  [31424/50000]\n",
      "loss: 1.326308  [32064/50000]\n",
      "loss: 1.495812  [32704/50000]\n",
      "loss: 1.197868  [33344/50000]\n",
      "loss: 1.203577  [33984/50000]\n",
      "loss: 1.268386  [34624/50000]\n",
      "loss: 1.379404  [35264/50000]\n",
      "loss: 1.055821  [35904/50000]\n",
      "loss: 1.184640  [36544/50000]\n",
      "loss: 1.105842  [37184/50000]\n",
      "loss: 1.319088  [37824/50000]\n",
      "loss: 1.337075  [38464/50000]\n",
      "loss: 1.207186  [39104/50000]\n",
      "loss: 1.292785  [39744/50000]\n",
      "loss: 1.171946  [40384/50000]\n",
      "loss: 1.313036  [41024/50000]\n",
      "loss: 1.190851  [41664/50000]\n",
      "loss: 1.072790  [42304/50000]\n",
      "loss: 1.327254  [42944/50000]\n",
      "loss: 1.097050  [43584/50000]\n",
      "loss: 1.067029  [44224/50000]\n",
      "loss: 1.244136  [44864/50000]\n",
      "loss: 1.087206  [45504/50000]\n",
      "loss: 1.425422  [46144/50000]\n",
      "loss: 1.092404  [46784/50000]\n",
      "loss: 1.392969  [47424/50000]\n",
      "loss: 1.358615  [48064/50000]\n",
      "loss: 1.082965  [48704/50000]\n",
      "loss: 1.248719  [49344/50000]\n",
      "loss: 1.222252  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.6%, Avg loss: 1.418833 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.218909  [   64/50000]\n",
      "loss: 1.269055  [  704/50000]\n",
      "loss: 0.957649  [ 1344/50000]\n",
      "loss: 1.218999  [ 1984/50000]\n",
      "loss: 1.217512  [ 2624/50000]\n",
      "loss: 1.061956  [ 3264/50000]\n",
      "loss: 1.312553  [ 3904/50000]\n",
      "loss: 1.176961  [ 4544/50000]\n",
      "loss: 1.380884  [ 5184/50000]\n",
      "loss: 1.251512  [ 5824/50000]\n",
      "loss: 1.235650  [ 6464/50000]\n",
      "loss: 1.045274  [ 7104/50000]\n",
      "loss: 1.258627  [ 7744/50000]\n",
      "loss: 1.345190  [ 8384/50000]\n",
      "loss: 1.167010  [ 9024/50000]\n",
      "loss: 1.254992  [ 9664/50000]\n",
      "loss: 0.975613  [10304/50000]\n",
      "loss: 1.138950  [10944/50000]\n",
      "loss: 1.021111  [11584/50000]\n",
      "loss: 1.309441  [12224/50000]\n",
      "loss: 1.024063  [12864/50000]\n",
      "loss: 1.145252  [13504/50000]\n",
      "loss: 1.243327  [14144/50000]\n",
      "loss: 1.059487  [14784/50000]\n",
      "loss: 1.250999  [15424/50000]\n",
      "loss: 1.089606  [16064/50000]\n",
      "loss: 1.152466  [16704/50000]\n",
      "loss: 0.959440  [17344/50000]\n",
      "loss: 1.098580  [17984/50000]\n",
      "loss: 1.132814  [18624/50000]\n",
      "loss: 1.060473  [19264/50000]\n",
      "loss: 0.892467  [19904/50000]\n",
      "loss: 1.192749  [20544/50000]\n",
      "loss: 0.966723  [21184/50000]\n",
      "loss: 1.134842  [21824/50000]\n",
      "loss: 1.068847  [22464/50000]\n",
      "loss: 1.122554  [23104/50000]\n",
      "loss: 1.059460  [23744/50000]\n",
      "loss: 1.227395  [24384/50000]\n",
      "loss: 1.255492  [25024/50000]\n",
      "loss: 1.207663  [25664/50000]\n",
      "loss: 1.012555  [26304/50000]\n",
      "loss: 0.887648  [26944/50000]\n",
      "loss: 0.920335  [27584/50000]\n",
      "loss: 1.062247  [28224/50000]\n",
      "loss: 1.104104  [28864/50000]\n",
      "loss: 1.032642  [29504/50000]\n",
      "loss: 1.145202  [30144/50000]\n",
      "loss: 1.099856  [30784/50000]\n",
      "loss: 0.853868  [31424/50000]\n",
      "loss: 1.082275  [32064/50000]\n",
      "loss: 0.973280  [32704/50000]\n",
      "loss: 1.055253  [33344/50000]\n",
      "loss: 0.960954  [33984/50000]\n",
      "loss: 1.247943  [34624/50000]\n",
      "loss: 0.832047  [35264/50000]\n",
      "loss: 1.064871  [35904/50000]\n",
      "loss: 1.002809  [36544/50000]\n",
      "loss: 0.972643  [37184/50000]\n",
      "loss: 0.964176  [37824/50000]\n",
      "loss: 1.143472  [38464/50000]\n",
      "loss: 1.101469  [39104/50000]\n",
      "loss: 1.050897  [39744/50000]\n",
      "loss: 1.065553  [40384/50000]\n",
      "loss: 0.900005  [41024/50000]\n",
      "loss: 0.974918  [41664/50000]\n",
      "loss: 0.811060  [42304/50000]\n",
      "loss: 1.153275  [42944/50000]\n",
      "loss: 0.921576  [43584/50000]\n",
      "loss: 1.386996  [44224/50000]\n",
      "loss: 1.128426  [44864/50000]\n",
      "loss: 0.853050  [45504/50000]\n",
      "loss: 1.120737  [46144/50000]\n",
      "loss: 1.066129  [46784/50000]\n",
      "loss: 0.994069  [47424/50000]\n",
      "loss: 1.002074  [48064/50000]\n",
      "loss: 1.059193  [48704/50000]\n",
      "loss: 1.123333  [49344/50000]\n",
      "loss: 1.000620  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.952138 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.958629  [   64/50000]\n",
      "loss: 0.803928  [  704/50000]\n",
      "loss: 0.688030  [ 1344/50000]\n",
      "loss: 0.793861  [ 1984/50000]\n",
      "loss: 0.886622  [ 2624/50000]\n",
      "loss: 0.861539  [ 3264/50000]\n",
      "loss: 0.860845  [ 3904/50000]\n",
      "loss: 0.784370  [ 4544/50000]\n",
      "loss: 0.888978  [ 5184/50000]\n",
      "loss: 0.937407  [ 5824/50000]\n",
      "loss: 0.838977  [ 6464/50000]\n",
      "loss: 1.066238  [ 7104/50000]\n",
      "loss: 0.729539  [ 7744/50000]\n",
      "loss: 1.032031  [ 8384/50000]\n",
      "loss: 1.144265  [ 9024/50000]\n",
      "loss: 0.857341  [ 9664/50000]\n",
      "loss: 0.950754  [10304/50000]\n",
      "loss: 0.851419  [10944/50000]\n",
      "loss: 0.819191  [11584/50000]\n",
      "loss: 0.881460  [12224/50000]\n",
      "loss: 0.747762  [12864/50000]\n",
      "loss: 0.782483  [13504/50000]\n",
      "loss: 1.065513  [14144/50000]\n",
      "loss: 0.992747  [14784/50000]\n",
      "loss: 0.813440  [15424/50000]\n",
      "loss: 1.111983  [16064/50000]\n",
      "loss: 0.744215  [16704/50000]\n",
      "loss: 0.937593  [17344/50000]\n",
      "loss: 0.971510  [17984/50000]\n",
      "loss: 0.862978  [18624/50000]\n",
      "loss: 0.954188  [19264/50000]\n",
      "loss: 0.967846  [19904/50000]\n",
      "loss: 0.848619  [20544/50000]\n",
      "loss: 1.096776  [21184/50000]\n",
      "loss: 0.720621  [21824/50000]\n",
      "loss: 0.849814  [22464/50000]\n",
      "loss: 0.696254  [23104/50000]\n",
      "loss: 0.843545  [23744/50000]\n",
      "loss: 0.844108  [24384/50000]\n",
      "loss: 0.874994  [25024/50000]\n",
      "loss: 0.976805  [25664/50000]\n",
      "loss: 0.957936  [26304/50000]\n",
      "loss: 0.616619  [26944/50000]\n",
      "loss: 0.712271  [27584/50000]\n",
      "loss: 1.034477  [28224/50000]\n",
      "loss: 0.866227  [28864/50000]\n",
      "loss: 0.757325  [29504/50000]\n",
      "loss: 0.694110  [30144/50000]\n",
      "loss: 0.974262  [30784/50000]\n",
      "loss: 0.772339  [31424/50000]\n",
      "loss: 1.039276  [32064/50000]\n",
      "loss: 0.961208  [32704/50000]\n",
      "loss: 1.049582  [33344/50000]\n",
      "loss: 1.013596  [33984/50000]\n",
      "loss: 0.821435  [34624/50000]\n",
      "loss: 0.971855  [35264/50000]\n",
      "loss: 0.876299  [35904/50000]\n",
      "loss: 1.009157  [36544/50000]\n",
      "loss: 0.811282  [37184/50000]\n",
      "loss: 0.849287  [37824/50000]\n",
      "loss: 0.827710  [38464/50000]\n",
      "loss: 0.958747  [39104/50000]\n",
      "loss: 1.006641  [39744/50000]\n",
      "loss: 0.944855  [40384/50000]\n",
      "loss: 1.002633  [41024/50000]\n",
      "loss: 0.843805  [41664/50000]\n",
      "loss: 0.860635  [42304/50000]\n",
      "loss: 0.912943  [42944/50000]\n",
      "loss: 1.041723  [43584/50000]\n",
      "loss: 0.787379  [44224/50000]\n",
      "loss: 1.030623  [44864/50000]\n",
      "loss: 0.835627  [45504/50000]\n",
      "loss: 0.914267  [46144/50000]\n",
      "loss: 0.853867  [46784/50000]\n",
      "loss: 0.787092  [47424/50000]\n",
      "loss: 1.081849  [48064/50000]\n",
      "loss: 0.962399  [48704/50000]\n",
      "loss: 0.989168  [49344/50000]\n",
      "loss: 0.691373  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.923582 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.852883  [   64/50000]\n",
      "loss: 0.986664  [  704/50000]\n",
      "loss: 0.761258  [ 1344/50000]\n",
      "loss: 0.738120  [ 1984/50000]\n",
      "loss: 0.588634  [ 2624/50000]\n",
      "loss: 0.653361  [ 3264/50000]\n",
      "loss: 0.766731  [ 3904/50000]\n",
      "loss: 0.936157  [ 4544/50000]\n",
      "loss: 0.728803  [ 5184/50000]\n",
      "loss: 0.903424  [ 5824/50000]\n",
      "loss: 0.705887  [ 6464/50000]\n",
      "loss: 0.852879  [ 7104/50000]\n",
      "loss: 0.675434  [ 7744/50000]\n",
      "loss: 0.903282  [ 8384/50000]\n",
      "loss: 0.613037  [ 9024/50000]\n",
      "loss: 0.802063  [ 9664/50000]\n",
      "loss: 0.842998  [10304/50000]\n",
      "loss: 0.876943  [10944/50000]\n",
      "loss: 0.786986  [11584/50000]\n",
      "loss: 0.574865  [12224/50000]\n",
      "loss: 0.828558  [12864/50000]\n",
      "loss: 0.776980  [13504/50000]\n",
      "loss: 0.780602  [14144/50000]\n",
      "loss: 0.624461  [14784/50000]\n",
      "loss: 0.767006  [15424/50000]\n",
      "loss: 0.853966  [16064/50000]\n",
      "loss: 0.761391  [16704/50000]\n",
      "loss: 0.867339  [17344/50000]\n",
      "loss: 0.732494  [17984/50000]\n",
      "loss: 0.792408  [18624/50000]\n",
      "loss: 0.566167  [19264/50000]\n",
      "loss: 0.744339  [19904/50000]\n",
      "loss: 0.797725  [20544/50000]\n",
      "loss: 0.769474  [21184/50000]\n",
      "loss: 0.810748  [21824/50000]\n",
      "loss: 0.700736  [22464/50000]\n",
      "loss: 0.704301  [23104/50000]\n",
      "loss: 0.565556  [23744/50000]\n",
      "loss: 0.795535  [24384/50000]\n",
      "loss: 0.878582  [25024/50000]\n",
      "loss: 0.785699  [25664/50000]\n",
      "loss: 0.529704  [26304/50000]\n",
      "loss: 0.828772  [26944/50000]\n",
      "loss: 0.527021  [27584/50000]\n",
      "loss: 0.421440  [28224/50000]\n",
      "loss: 0.902909  [28864/50000]\n",
      "loss: 0.967787  [29504/50000]\n",
      "loss: 0.858147  [30144/50000]\n",
      "loss: 0.988044  [30784/50000]\n",
      "loss: 0.559975  [31424/50000]\n",
      "loss: 0.891233  [32064/50000]\n",
      "loss: 0.657263  [32704/50000]\n",
      "loss: 0.777008  [33344/50000]\n",
      "loss: 0.756502  [33984/50000]\n",
      "loss: 0.858549  [34624/50000]\n",
      "loss: 0.640095  [35264/50000]\n",
      "loss: 1.006727  [35904/50000]\n",
      "loss: 0.940731  [36544/50000]\n",
      "loss: 0.855785  [37184/50000]\n",
      "loss: 0.590426  [37824/50000]\n",
      "loss: 0.801854  [38464/50000]\n",
      "loss: 0.908447  [39104/50000]\n",
      "loss: 0.806365  [39744/50000]\n",
      "loss: 0.682170  [40384/50000]\n",
      "loss: 0.726577  [41024/50000]\n",
      "loss: 0.649471  [41664/50000]\n",
      "loss: 0.662703  [42304/50000]\n",
      "loss: 0.677429  [42944/50000]\n",
      "loss: 0.914986  [43584/50000]\n",
      "loss: 0.704974  [44224/50000]\n",
      "loss: 0.682923  [44864/50000]\n",
      "loss: 0.698459  [45504/50000]\n",
      "loss: 0.904541  [46144/50000]\n",
      "loss: 0.738234  [46784/50000]\n",
      "loss: 0.775584  [47424/50000]\n",
      "loss: 0.763403  [48064/50000]\n",
      "loss: 0.650162  [48704/50000]\n",
      "loss: 0.782802  [49344/50000]\n",
      "loss: 0.723276  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.835809 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.701646  [   64/50000]\n",
      "loss: 0.545632  [  704/50000]\n",
      "loss: 0.400263  [ 1344/50000]\n",
      "loss: 0.554767  [ 1984/50000]\n",
      "loss: 0.462489  [ 2624/50000]\n",
      "loss: 0.474097  [ 3264/50000]\n",
      "loss: 0.697134  [ 3904/50000]\n",
      "loss: 0.832514  [ 4544/50000]\n",
      "loss: 0.538858  [ 5184/50000]\n",
      "loss: 0.521940  [ 5824/50000]\n",
      "loss: 0.722467  [ 6464/50000]\n",
      "loss: 0.496139  [ 7104/50000]\n",
      "loss: 0.741826  [ 7744/50000]\n",
      "loss: 0.723525  [ 8384/50000]\n",
      "loss: 0.698865  [ 9024/50000]\n",
      "loss: 0.520286  [ 9664/50000]\n",
      "loss: 0.944298  [10304/50000]\n",
      "loss: 0.759924  [10944/50000]\n",
      "loss: 0.605019  [11584/50000]\n",
      "loss: 0.511150  [12224/50000]\n",
      "loss: 0.725527  [12864/50000]\n",
      "loss: 0.953090  [13504/50000]\n",
      "loss: 0.651746  [14144/50000]\n",
      "loss: 0.515577  [14784/50000]\n",
      "loss: 0.756152  [15424/50000]\n",
      "loss: 0.468635  [16064/50000]\n",
      "loss: 0.704996  [16704/50000]\n",
      "loss: 0.564222  [17344/50000]\n",
      "loss: 0.468062  [17984/50000]\n",
      "loss: 0.702805  [18624/50000]\n",
      "loss: 0.637957  [19264/50000]\n",
      "loss: 0.486264  [19904/50000]\n",
      "loss: 0.589797  [20544/50000]\n",
      "loss: 0.765526  [21184/50000]\n",
      "loss: 0.472572  [21824/50000]\n",
      "loss: 0.533620  [22464/50000]\n",
      "loss: 0.712668  [23104/50000]\n",
      "loss: 0.485362  [23744/50000]\n",
      "loss: 0.541827  [24384/50000]\n",
      "loss: 0.534906  [25024/50000]\n",
      "loss: 0.710042  [25664/50000]\n",
      "loss: 0.489742  [26304/50000]\n",
      "loss: 0.684502  [26944/50000]\n",
      "loss: 0.513756  [27584/50000]\n",
      "loss: 0.615530  [28224/50000]\n",
      "loss: 0.594396  [28864/50000]\n",
      "loss: 0.710649  [29504/50000]\n",
      "loss: 0.526908  [30144/50000]\n",
      "loss: 0.613795  [30784/50000]\n",
      "loss: 0.614529  [31424/50000]\n",
      "loss: 1.093429  [32064/50000]\n",
      "loss: 0.821399  [32704/50000]\n",
      "loss: 0.525412  [33344/50000]\n",
      "loss: 0.440657  [33984/50000]\n",
      "loss: 0.645597  [34624/50000]\n",
      "loss: 0.648605  [35264/50000]\n",
      "loss: 0.627473  [35904/50000]\n",
      "loss: 0.679789  [36544/50000]\n",
      "loss: 0.743389  [37184/50000]\n",
      "loss: 0.424645  [37824/50000]\n",
      "loss: 0.584023  [38464/50000]\n",
      "loss: 0.805846  [39104/50000]\n",
      "loss: 0.791219  [39744/50000]\n",
      "loss: 0.648324  [40384/50000]\n",
      "loss: 0.621069  [41024/50000]\n",
      "loss: 0.685242  [41664/50000]\n",
      "loss: 0.727052  [42304/50000]\n",
      "loss: 0.696190  [42944/50000]\n",
      "loss: 0.572658  [43584/50000]\n",
      "loss: 0.829715  [44224/50000]\n",
      "loss: 0.518871  [44864/50000]\n",
      "loss: 0.528254  [45504/50000]\n",
      "loss: 0.553049  [46144/50000]\n",
      "loss: 0.598829  [46784/50000]\n",
      "loss: 0.658271  [47424/50000]\n",
      "loss: 0.602735  [48064/50000]\n",
      "loss: 0.853932  [48704/50000]\n",
      "loss: 0.674408  [49344/50000]\n",
      "loss: 0.667202  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.812443 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.386121  [   64/50000]\n",
      "loss: 0.534666  [  704/50000]\n",
      "loss: 0.589599  [ 1344/50000]\n",
      "loss: 0.385814  [ 1984/50000]\n",
      "loss: 0.260054  [ 2624/50000]\n",
      "loss: 0.496258  [ 3264/50000]\n",
      "loss: 0.409288  [ 3904/50000]\n",
      "loss: 0.643983  [ 4544/50000]\n",
      "loss: 0.443191  [ 5184/50000]\n",
      "loss: 0.514021  [ 5824/50000]\n",
      "loss: 0.334180  [ 6464/50000]\n",
      "loss: 0.436955  [ 7104/50000]\n",
      "loss: 0.328054  [ 7744/50000]\n",
      "loss: 0.384300  [ 8384/50000]\n",
      "loss: 0.262727  [ 9024/50000]\n",
      "loss: 0.286281  [ 9664/50000]\n",
      "loss: 0.468857  [10304/50000]\n",
      "loss: 0.475753  [10944/50000]\n",
      "loss: 0.519152  [11584/50000]\n",
      "loss: 0.555302  [12224/50000]\n",
      "loss: 0.503753  [12864/50000]\n",
      "loss: 0.507608  [13504/50000]\n",
      "loss: 0.383498  [14144/50000]\n",
      "loss: 0.869551  [14784/50000]\n",
      "loss: 0.489245  [15424/50000]\n",
      "loss: 0.505179  [16064/50000]\n",
      "loss: 0.282346  [16704/50000]\n",
      "loss: 0.645052  [17344/50000]\n",
      "loss: 0.624008  [17984/50000]\n",
      "loss: 0.450515  [18624/50000]\n",
      "loss: 0.398550  [19264/50000]\n",
      "loss: 0.522570  [19904/50000]\n",
      "loss: 0.381106  [20544/50000]\n",
      "loss: 0.484573  [21184/50000]\n",
      "loss: 0.477098  [21824/50000]\n",
      "loss: 0.484511  [22464/50000]\n",
      "loss: 0.669213  [23104/50000]\n",
      "loss: 0.700000  [23744/50000]\n",
      "loss: 0.629933  [24384/50000]\n",
      "loss: 0.434992  [25024/50000]\n",
      "loss: 0.455847  [25664/50000]\n",
      "loss: 0.421288  [26304/50000]\n",
      "loss: 0.585220  [26944/50000]\n",
      "loss: 0.354355  [27584/50000]\n",
      "loss: 0.384473  [28224/50000]\n",
      "loss: 0.482036  [28864/50000]\n",
      "loss: 0.466583  [29504/50000]\n",
      "loss: 0.537388  [30144/50000]\n",
      "loss: 0.552871  [30784/50000]\n",
      "loss: 0.397947  [31424/50000]\n",
      "loss: 0.649022  [32064/50000]\n",
      "loss: 0.559631  [32704/50000]\n",
      "loss: 0.451087  [33344/50000]\n",
      "loss: 0.754164  [33984/50000]\n",
      "loss: 0.441007  [34624/50000]\n",
      "loss: 0.557207  [35264/50000]\n",
      "loss: 0.368177  [35904/50000]\n",
      "loss: 0.645796  [36544/50000]\n",
      "loss: 0.531938  [37184/50000]\n",
      "loss: 0.450121  [37824/50000]\n",
      "loss: 0.469346  [38464/50000]\n",
      "loss: 0.375391  [39104/50000]\n",
      "loss: 0.479116  [39744/50000]\n",
      "loss: 0.540131  [40384/50000]\n",
      "loss: 0.521874  [41024/50000]\n",
      "loss: 0.639530  [41664/50000]\n",
      "loss: 0.708146  [42304/50000]\n",
      "loss: 0.212711  [42944/50000]\n",
      "loss: 0.546301  [43584/50000]\n",
      "loss: 0.715245  [44224/50000]\n",
      "loss: 0.651289  [44864/50000]\n",
      "loss: 0.438023  [45504/50000]\n",
      "loss: 0.540600  [46144/50000]\n",
      "loss: 0.531578  [46784/50000]\n",
      "loss: 0.498117  [47424/50000]\n",
      "loss: 0.462100  [48064/50000]\n",
      "loss: 0.469703  [48704/50000]\n",
      "loss: 0.490773  [49344/50000]\n",
      "loss: 0.528027  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.812755 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.548104  [   64/50000]\n",
      "loss: 0.445515  [  704/50000]\n",
      "loss: 0.363155  [ 1344/50000]\n",
      "loss: 0.379915  [ 1984/50000]\n",
      "loss: 0.302363  [ 2624/50000]\n",
      "loss: 0.349962  [ 3264/50000]\n",
      "loss: 0.323124  [ 3904/50000]\n",
      "loss: 0.494261  [ 4544/50000]\n",
      "loss: 0.251264  [ 5184/50000]\n",
      "loss: 0.366155  [ 5824/50000]\n",
      "loss: 0.473655  [ 6464/50000]\n",
      "loss: 0.348657  [ 7104/50000]\n",
      "loss: 0.445593  [ 7744/50000]\n",
      "loss: 0.346481  [ 8384/50000]\n",
      "loss: 0.332003  [ 9024/50000]\n",
      "loss: 0.447167  [ 9664/50000]\n",
      "loss: 0.345164  [10304/50000]\n",
      "loss: 0.424429  [10944/50000]\n",
      "loss: 0.387988  [11584/50000]\n",
      "loss: 0.452873  [12224/50000]\n",
      "loss: 0.404845  [12864/50000]\n",
      "loss: 0.380330  [13504/50000]\n",
      "loss: 0.748579  [14144/50000]\n",
      "loss: 0.300273  [14784/50000]\n",
      "loss: 0.294437  [15424/50000]\n",
      "loss: 0.357746  [16064/50000]\n",
      "loss: 0.380175  [16704/50000]\n",
      "loss: 0.468832  [17344/50000]\n",
      "loss: 0.250514  [17984/50000]\n",
      "loss: 0.458602  [18624/50000]\n",
      "loss: 0.276906  [19264/50000]\n",
      "loss: 0.550296  [19904/50000]\n",
      "loss: 0.706969  [20544/50000]\n",
      "loss: 0.451395  [21184/50000]\n",
      "loss: 0.298777  [21824/50000]\n",
      "loss: 0.510073  [22464/50000]\n",
      "loss: 0.504338  [23104/50000]\n",
      "loss: 0.434653  [23744/50000]\n",
      "loss: 0.416625  [24384/50000]\n",
      "loss: 0.299200  [25024/50000]\n",
      "loss: 0.399572  [25664/50000]\n",
      "loss: 0.424436  [26304/50000]\n",
      "loss: 0.532253  [26944/50000]\n",
      "loss: 0.496180  [27584/50000]\n",
      "loss: 0.355410  [28224/50000]\n",
      "loss: 0.369167  [28864/50000]\n",
      "loss: 0.302358  [29504/50000]\n",
      "loss: 0.715727  [30144/50000]\n",
      "loss: 0.384025  [30784/50000]\n",
      "loss: 0.726362  [31424/50000]\n",
      "loss: 0.381560  [32064/50000]\n",
      "loss: 0.275629  [32704/50000]\n",
      "loss: 0.242097  [33344/50000]\n",
      "loss: 0.543412  [33984/50000]\n",
      "loss: 0.466791  [34624/50000]\n",
      "loss: 0.369624  [35264/50000]\n",
      "loss: 0.506491  [35904/50000]\n",
      "loss: 0.631254  [36544/50000]\n",
      "loss: 0.782815  [37184/50000]\n",
      "loss: 0.380325  [37824/50000]\n",
      "loss: 0.712219  [38464/50000]\n",
      "loss: 0.482244  [39104/50000]\n",
      "loss: 0.265412  [39744/50000]\n",
      "loss: 0.369335  [40384/50000]\n",
      "loss: 0.393984  [41024/50000]\n",
      "loss: 0.326784  [41664/50000]\n",
      "loss: 0.327695  [42304/50000]\n",
      "loss: 0.566706  [42944/50000]\n",
      "loss: 0.371119  [43584/50000]\n",
      "loss: 0.344241  [44224/50000]\n",
      "loss: 0.595256  [44864/50000]\n",
      "loss: 0.360459  [45504/50000]\n",
      "loss: 0.381252  [46144/50000]\n",
      "loss: 0.397077  [46784/50000]\n",
      "loss: 0.484383  [47424/50000]\n",
      "loss: 0.335204  [48064/50000]\n",
      "loss: 0.597232  [48704/50000]\n",
      "loss: 0.328770  [49344/50000]\n",
      "loss: 0.472153  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.834001 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.228583  [   64/50000]\n",
      "loss: 0.188830  [  704/50000]\n",
      "loss: 0.367498  [ 1344/50000]\n",
      "loss: 0.143251  [ 1984/50000]\n",
      "loss: 0.300939  [ 2624/50000]\n",
      "loss: 0.345868  [ 3264/50000]\n",
      "loss: 0.352539  [ 3904/50000]\n",
      "loss: 0.339674  [ 4544/50000]\n",
      "loss: 0.473048  [ 5184/50000]\n",
      "loss: 0.406026  [ 5824/50000]\n",
      "loss: 0.317719  [ 6464/50000]\n",
      "loss: 0.223678  [ 7104/50000]\n",
      "loss: 0.220570  [ 7744/50000]\n",
      "loss: 0.293921  [ 8384/50000]\n",
      "loss: 0.232161  [ 9024/50000]\n",
      "loss: 0.371746  [ 9664/50000]\n",
      "loss: 0.540834  [10304/50000]\n",
      "loss: 0.285860  [10944/50000]\n",
      "loss: 0.262288  [11584/50000]\n",
      "loss: 0.276638  [12224/50000]\n",
      "loss: 0.315590  [12864/50000]\n",
      "loss: 0.296784  [13504/50000]\n",
      "loss: 0.604824  [14144/50000]\n",
      "loss: 0.369559  [14784/50000]\n",
      "loss: 0.272052  [15424/50000]\n",
      "loss: 0.292304  [16064/50000]\n",
      "loss: 0.578683  [16704/50000]\n",
      "loss: 0.290718  [17344/50000]\n",
      "loss: 0.285896  [17984/50000]\n",
      "loss: 0.439699  [18624/50000]\n",
      "loss: 0.160410  [19264/50000]\n",
      "loss: 0.280682  [19904/50000]\n",
      "loss: 0.316849  [20544/50000]\n",
      "loss: 0.625400  [21184/50000]\n",
      "loss: 0.420799  [21824/50000]\n",
      "loss: 0.183797  [22464/50000]\n",
      "loss: 0.355278  [23104/50000]\n",
      "loss: 0.178174  [23744/50000]\n",
      "loss: 0.438913  [24384/50000]\n",
      "loss: 0.300700  [25024/50000]\n",
      "loss: 0.381267  [25664/50000]\n",
      "loss: 0.315198  [26304/50000]\n",
      "loss: 0.276720  [26944/50000]\n",
      "loss: 0.374625  [27584/50000]\n",
      "loss: 0.411681  [28224/50000]\n",
      "loss: 0.291693  [28864/50000]\n",
      "loss: 0.528326  [29504/50000]\n",
      "loss: 0.376249  [30144/50000]\n",
      "loss: 0.327142  [30784/50000]\n",
      "loss: 0.360919  [31424/50000]\n",
      "loss: 0.222739  [32064/50000]\n",
      "loss: 0.398902  [32704/50000]\n",
      "loss: 0.355609  [33344/50000]\n",
      "loss: 0.344174  [33984/50000]\n",
      "loss: 0.488554  [34624/50000]\n",
      "loss: 0.429159  [35264/50000]\n",
      "loss: 0.248668  [35904/50000]\n",
      "loss: 0.172935  [36544/50000]\n",
      "loss: 0.238068  [37184/50000]\n",
      "loss: 0.494279  [37824/50000]\n",
      "loss: 0.413881  [38464/50000]\n",
      "loss: 0.348495  [39104/50000]\n",
      "loss: 0.368929  [39744/50000]\n",
      "loss: 0.410939  [40384/50000]\n",
      "loss: 0.332590  [41024/50000]\n",
      "loss: 0.428766  [41664/50000]\n",
      "loss: 0.402940  [42304/50000]\n",
      "loss: 0.376173  [42944/50000]\n",
      "loss: 0.350100  [43584/50000]\n",
      "loss: 0.479519  [44224/50000]\n",
      "loss: 0.389839  [44864/50000]\n",
      "loss: 0.322029  [45504/50000]\n",
      "loss: 0.255351  [46144/50000]\n",
      "loss: 0.370050  [46784/50000]\n",
      "loss: 0.308345  [47424/50000]\n",
      "loss: 0.225188  [48064/50000]\n",
      "loss: 0.464748  [48704/50000]\n",
      "loss: 0.283400  [49344/50000]\n",
      "loss: 0.419361  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.902549 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.234890  [   64/50000]\n",
      "loss: 0.239403  [  704/50000]\n",
      "loss: 0.191881  [ 1344/50000]\n",
      "loss: 0.333116  [ 1984/50000]\n",
      "loss: 0.296671  [ 2624/50000]\n",
      "loss: 0.233955  [ 3264/50000]\n",
      "loss: 0.353971  [ 3904/50000]\n",
      "loss: 0.248619  [ 4544/50000]\n",
      "loss: 0.283046  [ 5184/50000]\n",
      "loss: 0.376813  [ 5824/50000]\n",
      "loss: 0.380816  [ 6464/50000]\n",
      "loss: 0.381538  [ 7104/50000]\n",
      "loss: 0.504375  [ 7744/50000]\n",
      "loss: 0.264443  [ 8384/50000]\n",
      "loss: 0.295871  [ 9024/50000]\n",
      "loss: 0.419017  [ 9664/50000]\n",
      "loss: 0.495509  [10304/50000]\n",
      "loss: 0.329373  [10944/50000]\n",
      "loss: 0.355672  [11584/50000]\n",
      "loss: 0.191262  [12224/50000]\n",
      "loss: 0.158072  [12864/50000]\n",
      "loss: 0.180587  [13504/50000]\n",
      "loss: 0.388032  [14144/50000]\n",
      "loss: 0.177672  [14784/50000]\n",
      "loss: 0.314115  [15424/50000]\n",
      "loss: 0.404061  [16064/50000]\n",
      "loss: 0.365177  [16704/50000]\n",
      "loss: 0.312857  [17344/50000]\n",
      "loss: 0.288493  [17984/50000]\n",
      "loss: 0.139206  [18624/50000]\n",
      "loss: 0.356487  [19264/50000]\n",
      "loss: 0.195269  [19904/50000]\n",
      "loss: 0.557139  [20544/50000]\n",
      "loss: 0.251475  [21184/50000]\n",
      "loss: 0.186286  [21824/50000]\n",
      "loss: 0.242298  [22464/50000]\n",
      "loss: 0.327217  [23104/50000]\n",
      "loss: 0.436292  [23744/50000]\n",
      "loss: 0.323323  [24384/50000]\n",
      "loss: 0.324949  [25024/50000]\n",
      "loss: 0.310924  [25664/50000]\n",
      "loss: 0.092615  [26304/50000]\n",
      "loss: 0.572244  [26944/50000]\n",
      "loss: 0.234378  [27584/50000]\n",
      "loss: 0.323919  [28224/50000]\n",
      "loss: 0.431197  [28864/50000]\n",
      "loss: 0.305860  [29504/50000]\n",
      "loss: 0.205656  [30144/50000]\n",
      "loss: 0.201566  [30784/50000]\n",
      "loss: 0.314628  [31424/50000]\n",
      "loss: 0.313495  [32064/50000]\n",
      "loss: 0.394391  [32704/50000]\n",
      "loss: 0.335879  [33344/50000]\n",
      "loss: 0.282334  [33984/50000]\n",
      "loss: 0.162503  [34624/50000]\n",
      "loss: 0.337463  [35264/50000]\n",
      "loss: 0.221668  [35904/50000]\n",
      "loss: 0.277011  [36544/50000]\n",
      "loss: 0.448973  [37184/50000]\n",
      "loss: 0.352716  [37824/50000]\n",
      "loss: 0.733935  [38464/50000]\n",
      "loss: 0.361883  [39104/50000]\n",
      "loss: 0.221593  [39744/50000]\n",
      "loss: 0.299960  [40384/50000]\n",
      "loss: 0.213668  [41024/50000]\n",
      "loss: 0.170811  [41664/50000]\n",
      "loss: 0.296948  [42304/50000]\n",
      "loss: 0.120940  [42944/50000]\n",
      "loss: 0.471747  [43584/50000]\n",
      "loss: 0.246546  [44224/50000]\n",
      "loss: 0.379450  [44864/50000]\n",
      "loss: 0.353922  [45504/50000]\n",
      "loss: 0.590920  [46144/50000]\n",
      "loss: 0.587540  [46784/50000]\n",
      "loss: 0.122050  [47424/50000]\n",
      "loss: 0.154978  [48064/50000]\n",
      "loss: 0.242273  [48704/50000]\n",
      "loss: 0.277368  [49344/50000]\n",
      "loss: 0.601219  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.903878 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.278861  [   64/50000]\n",
      "loss: 0.161260  [  704/50000]\n",
      "loss: 0.067939  [ 1344/50000]\n",
      "loss: 0.325595  [ 1984/50000]\n",
      "loss: 0.256918  [ 2624/50000]\n",
      "loss: 0.410273  [ 3264/50000]\n",
      "loss: 0.174942  [ 3904/50000]\n",
      "loss: 0.707338  [ 4544/50000]\n",
      "loss: 0.201481  [ 5184/50000]\n",
      "loss: 0.187683  [ 5824/50000]\n",
      "loss: 0.220965  [ 6464/50000]\n",
      "loss: 0.424827  [ 7104/50000]\n",
      "loss: 0.253919  [ 7744/50000]\n",
      "loss: 0.143073  [ 8384/50000]\n",
      "loss: 0.229072  [ 9024/50000]\n",
      "loss: 0.286475  [ 9664/50000]\n",
      "loss: 0.170584  [10304/50000]\n",
      "loss: 0.243703  [10944/50000]\n",
      "loss: 0.277418  [11584/50000]\n",
      "loss: 0.355902  [12224/50000]\n",
      "loss: 0.198484  [12864/50000]\n",
      "loss: 0.305010  [13504/50000]\n",
      "loss: 0.242688  [14144/50000]\n",
      "loss: 0.271995  [14784/50000]\n",
      "loss: 0.277156  [15424/50000]\n",
      "loss: 0.204215  [16064/50000]\n",
      "loss: 0.319384  [16704/50000]\n",
      "loss: 0.247184  [17344/50000]\n",
      "loss: 0.189999  [17984/50000]\n",
      "loss: 0.212767  [18624/50000]\n",
      "loss: 0.258621  [19264/50000]\n",
      "loss: 0.295662  [19904/50000]\n",
      "loss: 0.188836  [20544/50000]\n",
      "loss: 0.196890  [21184/50000]\n",
      "loss: 0.216518  [21824/50000]\n",
      "loss: 0.101260  [22464/50000]\n",
      "loss: 0.247222  [23104/50000]\n",
      "loss: 0.176548  [23744/50000]\n",
      "loss: 0.153078  [24384/50000]\n",
      "loss: 0.168547  [25024/50000]\n",
      "loss: 0.281686  [25664/50000]\n",
      "loss: 0.290741  [26304/50000]\n",
      "loss: 0.166980  [26944/50000]\n",
      "loss: 0.210911  [27584/50000]\n",
      "loss: 0.129535  [28224/50000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6b5953c58c21>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-bd0f3ac1fafd>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "trainset, testset = get_data()\n",
    "\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "net = vgg_model\n",
    "net.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"ML2_4_2\",\n",
    "    # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=\"vgg13\",\n",
    ")\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, net, loss_fn, optimizer, device)\n",
    "    test_loop(testloader, net, loss_fn, device)\n",
    "\n",
    "torch.save(net.state_dict(), \"model_weights.pth\")\n",
    "torch.save(optimizer.state_dict(), \"optimizer_settings.pth\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "executionInfo": {
     "elapsed": 1401,
     "status": "ok",
     "timestamp": 1746210086906,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "QVM6BhXk1gKu",
    "outputId": "8ec0cb2d-aeaa-42d2-b46a-403d9b07de59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▂▆▇▇█████</td></tr><tr><td>test_loss</td><td>█▇▂▂▁▁▁▁▂▂</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.7367</td></tr><tr><td>test_loss</td><td>0.90388</td></tr><tr><td>train_loss</td><td>0.30197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vgg3</strong> at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/4u7wlwg0' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/4u7wlwg0</a><br> View project at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250502_163727-4u7wlwg0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EzNruZQ1Pva"
   },
   "source": [
    "### MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bnCDaOh6_qI"
   },
   "outputs": [],
   "source": [
    "mobnet_model = mobilenet_v3_small(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfsNeTzQ2Tse"
   },
   "outputs": [],
   "source": [
    "def get_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform\n",
    "    )\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2286104,
     "status": "ok",
     "timestamp": 1746212395296,
     "user": {
      "displayName": "Шадаев Фёдор",
      "userId": "14152552676221368510"
     },
     "user_tz": -180
    },
    "id": "TjjyQ6nQ3vLR",
    "outputId": "68a1d196-d821-45a5-d7f5-265809ae0298"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250502_182151-7cls1xza</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/7cls1xza' target=\"_blank\">mobnet1</a></strong> to <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/7cls1xza' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/7cls1xza</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.304287  [   64/50000]\n",
      "loss: 2.096444  [  704/50000]\n",
      "loss: 1.980592  [ 1344/50000]\n",
      "loss: 1.839184  [ 1984/50000]\n",
      "loss: 1.913953  [ 2624/50000]\n",
      "loss: 1.772933  [ 3264/50000]\n",
      "loss: 1.634785  [ 3904/50000]\n",
      "loss: 1.796628  [ 4544/50000]\n",
      "loss: 1.656427  [ 5184/50000]\n",
      "loss: 1.496631  [ 5824/50000]\n",
      "loss: 1.472347  [ 6464/50000]\n",
      "loss: 1.685889  [ 7104/50000]\n",
      "loss: 1.486093  [ 7744/50000]\n",
      "loss: 1.692029  [ 8384/50000]\n",
      "loss: 1.411882  [ 9024/50000]\n",
      "loss: 1.498034  [ 9664/50000]\n",
      "loss: 1.883375  [10304/50000]\n",
      "loss: 1.501496  [10944/50000]\n",
      "loss: 1.557839  [11584/50000]\n",
      "loss: 1.794960  [12224/50000]\n",
      "loss: 1.390737  [12864/50000]\n",
      "loss: 1.143298  [13504/50000]\n",
      "loss: 1.280218  [14144/50000]\n",
      "loss: 1.509063  [14784/50000]\n",
      "loss: 1.343849  [15424/50000]\n",
      "loss: 1.446296  [16064/50000]\n",
      "loss: 1.443453  [16704/50000]\n",
      "loss: 1.482042  [17344/50000]\n",
      "loss: 1.216291  [17984/50000]\n",
      "loss: 1.434901  [18624/50000]\n",
      "loss: 1.585588  [19264/50000]\n",
      "loss: 1.354360  [19904/50000]\n",
      "loss: 1.437130  [20544/50000]\n",
      "loss: 1.191907  [21184/50000]\n",
      "loss: 1.243079  [21824/50000]\n",
      "loss: 1.273334  [22464/50000]\n",
      "loss: 1.240430  [23104/50000]\n",
      "loss: 1.141815  [23744/50000]\n",
      "loss: 1.256500  [24384/50000]\n",
      "loss: 1.323754  [25024/50000]\n",
      "loss: 1.114632  [25664/50000]\n",
      "loss: 1.268673  [26304/50000]\n",
      "loss: 1.227801  [26944/50000]\n",
      "loss: 1.380193  [27584/50000]\n",
      "loss: 1.222295  [28224/50000]\n",
      "loss: 0.794736  [28864/50000]\n",
      "loss: 1.390266  [29504/50000]\n",
      "loss: 1.210335  [30144/50000]\n",
      "loss: 1.049382  [30784/50000]\n",
      "loss: 1.354377  [31424/50000]\n",
      "loss: 1.164693  [32064/50000]\n",
      "loss: 1.258224  [32704/50000]\n",
      "loss: 1.129860  [33344/50000]\n",
      "loss: 1.159652  [33984/50000]\n",
      "loss: 1.061203  [34624/50000]\n",
      "loss: 1.216232  [35264/50000]\n",
      "loss: 1.008166  [35904/50000]\n",
      "loss: 0.926340  [36544/50000]\n",
      "loss: 0.773189  [37184/50000]\n",
      "loss: 1.349092  [37824/50000]\n",
      "loss: 1.107967  [38464/50000]\n",
      "loss: 1.191984  [39104/50000]\n",
      "loss: 1.112985  [39744/50000]\n",
      "loss: 1.042590  [40384/50000]\n",
      "loss: 1.046541  [41024/50000]\n",
      "loss: 1.316830  [41664/50000]\n",
      "loss: 0.876803  [42304/50000]\n",
      "loss: 0.982848  [42944/50000]\n",
      "loss: 1.117069  [43584/50000]\n",
      "loss: 0.821802  [44224/50000]\n",
      "loss: 0.847555  [44864/50000]\n",
      "loss: 0.831274  [45504/50000]\n",
      "loss: 1.103727  [46144/50000]\n",
      "loss: 1.079113  [46784/50000]\n",
      "loss: 1.191621  [47424/50000]\n",
      "loss: 1.033688  [48064/50000]\n",
      "loss: 1.038389  [48704/50000]\n",
      "loss: 0.818865  [49344/50000]\n",
      "loss: 0.926411  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 1.530095 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.961200  [   64/50000]\n",
      "loss: 1.255589  [  704/50000]\n",
      "loss: 0.953686  [ 1344/50000]\n",
      "loss: 0.972921  [ 1984/50000]\n",
      "loss: 0.811609  [ 2624/50000]\n",
      "loss: 1.081132  [ 3264/50000]\n",
      "loss: 0.792435  [ 3904/50000]\n",
      "loss: 1.003236  [ 4544/50000]\n",
      "loss: 0.875766  [ 5184/50000]\n",
      "loss: 0.952044  [ 5824/50000]\n",
      "loss: 0.767942  [ 6464/50000]\n",
      "loss: 0.683181  [ 7104/50000]\n",
      "loss: 1.105047  [ 7744/50000]\n",
      "loss: 1.115565  [ 8384/50000]\n",
      "loss: 0.743479  [ 9024/50000]\n",
      "loss: 0.977400  [ 9664/50000]\n",
      "loss: 1.182329  [10304/50000]\n",
      "loss: 0.920568  [10944/50000]\n",
      "loss: 0.861189  [11584/50000]\n",
      "loss: 0.986553  [12224/50000]\n",
      "loss: 0.978413  [12864/50000]\n",
      "loss: 0.767141  [13504/50000]\n",
      "loss: 0.875463  [14144/50000]\n",
      "loss: 0.946702  [14784/50000]\n",
      "loss: 0.865366  [15424/50000]\n",
      "loss: 1.248214  [16064/50000]\n",
      "loss: 0.989702  [16704/50000]\n",
      "loss: 0.859865  [17344/50000]\n",
      "loss: 1.300509  [17984/50000]\n",
      "loss: 0.813188  [18624/50000]\n",
      "loss: 0.825514  [19264/50000]\n",
      "loss: 1.055756  [19904/50000]\n",
      "loss: 0.879210  [20544/50000]\n",
      "loss: 0.722718  [21184/50000]\n",
      "loss: 1.019994  [21824/50000]\n",
      "loss: 0.732418  [22464/50000]\n",
      "loss: 1.157777  [23104/50000]\n",
      "loss: 0.848093  [23744/50000]\n",
      "loss: 0.853122  [24384/50000]\n",
      "loss: 0.877635  [25024/50000]\n",
      "loss: 0.707530  [25664/50000]\n",
      "loss: 1.003991  [26304/50000]\n",
      "loss: 0.887011  [26944/50000]\n",
      "loss: 1.067499  [27584/50000]\n",
      "loss: 0.843661  [28224/50000]\n",
      "loss: 0.974834  [28864/50000]\n",
      "loss: 0.838659  [29504/50000]\n",
      "loss: 0.616886  [30144/50000]\n",
      "loss: 0.726536  [30784/50000]\n",
      "loss: 0.748164  [31424/50000]\n",
      "loss: 0.995798  [32064/50000]\n",
      "loss: 0.703307  [32704/50000]\n",
      "loss: 0.799870  [33344/50000]\n",
      "loss: 0.556149  [33984/50000]\n",
      "loss: 0.907638  [34624/50000]\n",
      "loss: 0.651027  [35264/50000]\n",
      "loss: 0.900553  [35904/50000]\n",
      "loss: 0.743859  [36544/50000]\n",
      "loss: 0.622164  [37184/50000]\n",
      "loss: 0.651002  [37824/50000]\n",
      "loss: 0.667739  [38464/50000]\n",
      "loss: 0.726243  [39104/50000]\n",
      "loss: 0.741584  [39744/50000]\n",
      "loss: 0.895035  [40384/50000]\n",
      "loss: 0.754611  [41024/50000]\n",
      "loss: 0.799958  [41664/50000]\n",
      "loss: 0.812342  [42304/50000]\n",
      "loss: 0.826856  [42944/50000]\n",
      "loss: 0.656684  [43584/50000]\n",
      "loss: 0.783346  [44224/50000]\n",
      "loss: 0.944151  [44864/50000]\n",
      "loss: 0.704638  [45504/50000]\n",
      "loss: 0.950014  [46144/50000]\n",
      "loss: 0.565354  [46784/50000]\n",
      "loss: 0.796628  [47424/50000]\n",
      "loss: 0.671025  [48064/50000]\n",
      "loss: 0.948783  [48704/50000]\n",
      "loss: 0.706041  [49344/50000]\n",
      "loss: 0.495237  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.934591 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.666323  [   64/50000]\n",
      "loss: 0.850882  [  704/50000]\n",
      "loss: 0.657255  [ 1344/50000]\n",
      "loss: 0.844961  [ 1984/50000]\n",
      "loss: 0.626287  [ 2624/50000]\n",
      "loss: 0.497740  [ 3264/50000]\n",
      "loss: 0.507670  [ 3904/50000]\n",
      "loss: 0.820265  [ 4544/50000]\n",
      "loss: 0.736965  [ 5184/50000]\n",
      "loss: 1.042625  [ 5824/50000]\n",
      "loss: 0.574945  [ 6464/50000]\n",
      "loss: 0.679917  [ 7104/50000]\n",
      "loss: 0.652211  [ 7744/50000]\n",
      "loss: 0.473870  [ 8384/50000]\n",
      "loss: 0.842928  [ 9024/50000]\n",
      "loss: 1.027258  [ 9664/50000]\n",
      "loss: 0.539457  [10304/50000]\n",
      "loss: 0.462168  [10944/50000]\n",
      "loss: 0.409516  [11584/50000]\n",
      "loss: 0.748069  [12224/50000]\n",
      "loss: 0.619482  [12864/50000]\n",
      "loss: 0.473483  [13504/50000]\n",
      "loss: 0.775016  [14144/50000]\n",
      "loss: 0.922461  [14784/50000]\n",
      "loss: 0.599184  [15424/50000]\n",
      "loss: 0.552911  [16064/50000]\n",
      "loss: 0.435609  [16704/50000]\n",
      "loss: 0.604485  [17344/50000]\n",
      "loss: 0.840559  [17984/50000]\n",
      "loss: 0.525811  [18624/50000]\n",
      "loss: 0.621481  [19264/50000]\n",
      "loss: 0.790919  [19904/50000]\n",
      "loss: 0.801984  [20544/50000]\n",
      "loss: 0.795213  [21184/50000]\n",
      "loss: 0.634124  [21824/50000]\n",
      "loss: 0.751569  [22464/50000]\n",
      "loss: 0.786074  [23104/50000]\n",
      "loss: 0.754225  [23744/50000]\n",
      "loss: 0.674545  [24384/50000]\n",
      "loss: 0.823151  [25024/50000]\n",
      "loss: 0.785107  [25664/50000]\n",
      "loss: 0.652797  [26304/50000]\n",
      "loss: 0.391139  [26944/50000]\n",
      "loss: 0.720038  [27584/50000]\n",
      "loss: 0.481603  [28224/50000]\n",
      "loss: 0.762154  [28864/50000]\n",
      "loss: 0.575166  [29504/50000]\n",
      "loss: 0.744069  [30144/50000]\n",
      "loss: 0.746397  [30784/50000]\n",
      "loss: 0.649544  [31424/50000]\n",
      "loss: 0.542614  [32064/50000]\n",
      "loss: 0.692706  [32704/50000]\n",
      "loss: 0.678991  [33344/50000]\n",
      "loss: 0.584766  [33984/50000]\n",
      "loss: 0.469787  [34624/50000]\n",
      "loss: 0.692791  [35264/50000]\n",
      "loss: 0.617707  [35904/50000]\n",
      "loss: 0.803187  [36544/50000]\n",
      "loss: 0.876557  [37184/50000]\n",
      "loss: 0.770456  [37824/50000]\n",
      "loss: 0.499080  [38464/50000]\n",
      "loss: 0.600530  [39104/50000]\n",
      "loss: 0.589170  [39744/50000]\n",
      "loss: 0.942539  [40384/50000]\n",
      "loss: 0.613509  [41024/50000]\n",
      "loss: 0.772442  [41664/50000]\n",
      "loss: 0.566573  [42304/50000]\n",
      "loss: 0.598598  [42944/50000]\n",
      "loss: 0.661373  [43584/50000]\n",
      "loss: 0.807613  [44224/50000]\n",
      "loss: 0.571490  [44864/50000]\n",
      "loss: 0.762539  [45504/50000]\n",
      "loss: 0.532143  [46144/50000]\n",
      "loss: 0.591469  [46784/50000]\n",
      "loss: 0.615029  [47424/50000]\n",
      "loss: 0.463613  [48064/50000]\n",
      "loss: 0.611649  [48704/50000]\n",
      "loss: 0.646246  [49344/50000]\n",
      "loss: 0.601667  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.769056 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.595951  [   64/50000]\n",
      "loss: 0.736277  [  704/50000]\n",
      "loss: 0.536766  [ 1344/50000]\n",
      "loss: 0.459071  [ 1984/50000]\n",
      "loss: 0.573198  [ 2624/50000]\n",
      "loss: 0.366953  [ 3264/50000]\n",
      "loss: 0.612329  [ 3904/50000]\n",
      "loss: 0.488188  [ 4544/50000]\n",
      "loss: 0.693743  [ 5184/50000]\n",
      "loss: 0.425119  [ 5824/50000]\n",
      "loss: 0.406329  [ 6464/50000]\n",
      "loss: 0.522725  [ 7104/50000]\n",
      "loss: 0.643476  [ 7744/50000]\n",
      "loss: 0.536266  [ 8384/50000]\n",
      "loss: 0.511459  [ 9024/50000]\n",
      "loss: 0.518579  [ 9664/50000]\n",
      "loss: 0.544314  [10304/50000]\n",
      "loss: 0.446077  [10944/50000]\n",
      "loss: 0.462937  [11584/50000]\n",
      "loss: 0.571380  [12224/50000]\n",
      "loss: 0.704866  [12864/50000]\n",
      "loss: 0.545606  [13504/50000]\n",
      "loss: 0.619304  [14144/50000]\n",
      "loss: 0.324998  [14784/50000]\n",
      "loss: 0.532652  [15424/50000]\n",
      "loss: 0.649137  [16064/50000]\n",
      "loss: 0.389107  [16704/50000]\n",
      "loss: 0.497881  [17344/50000]\n",
      "loss: 0.717194  [17984/50000]\n",
      "loss: 0.572564  [18624/50000]\n",
      "loss: 0.414103  [19264/50000]\n",
      "loss: 0.635627  [19904/50000]\n",
      "loss: 0.561931  [20544/50000]\n",
      "loss: 0.563824  [21184/50000]\n",
      "loss: 0.550772  [21824/50000]\n",
      "loss: 0.618668  [22464/50000]\n",
      "loss: 0.676219  [23104/50000]\n",
      "loss: 0.562286  [23744/50000]\n",
      "loss: 0.542423  [24384/50000]\n",
      "loss: 0.445625  [25024/50000]\n",
      "loss: 0.660607  [25664/50000]\n",
      "loss: 0.689281  [26304/50000]\n",
      "loss: 0.548889  [26944/50000]\n",
      "loss: 0.742336  [27584/50000]\n",
      "loss: 0.436045  [28224/50000]\n",
      "loss: 0.366433  [28864/50000]\n",
      "loss: 0.579979  [29504/50000]\n",
      "loss: 0.840169  [30144/50000]\n",
      "loss: 0.428721  [30784/50000]\n",
      "loss: 0.567070  [31424/50000]\n",
      "loss: 0.545691  [32064/50000]\n",
      "loss: 0.556125  [32704/50000]\n",
      "loss: 0.673411  [33344/50000]\n",
      "loss: 0.317999  [33984/50000]\n",
      "loss: 0.634750  [34624/50000]\n",
      "loss: 0.718872  [35264/50000]\n",
      "loss: 0.579181  [35904/50000]\n",
      "loss: 0.579409  [36544/50000]\n",
      "loss: 0.598286  [37184/50000]\n",
      "loss: 0.597135  [37824/50000]\n",
      "loss: 0.573463  [38464/50000]\n",
      "loss: 0.711440  [39104/50000]\n",
      "loss: 0.642998  [39744/50000]\n",
      "loss: 0.478807  [40384/50000]\n",
      "loss: 0.570836  [41024/50000]\n",
      "loss: 0.742603  [41664/50000]\n",
      "loss: 0.440920  [42304/50000]\n",
      "loss: 0.474324  [42944/50000]\n",
      "loss: 0.545191  [43584/50000]\n",
      "loss: 0.612543  [44224/50000]\n",
      "loss: 0.554988  [44864/50000]\n",
      "loss: 0.396586  [45504/50000]\n",
      "loss: 0.642107  [46144/50000]\n",
      "loss: 0.457868  [46784/50000]\n",
      "loss: 0.547417  [47424/50000]\n",
      "loss: 0.534082  [48064/50000]\n",
      "loss: 0.459032  [48704/50000]\n",
      "loss: 0.624979  [49344/50000]\n",
      "loss: 0.466740  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.676587 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.398198  [   64/50000]\n",
      "loss: 0.337541  [  704/50000]\n",
      "loss: 0.432263  [ 1344/50000]\n",
      "loss: 0.391685  [ 1984/50000]\n",
      "loss: 0.627876  [ 2624/50000]\n",
      "loss: 0.327258  [ 3264/50000]\n",
      "loss: 0.364796  [ 3904/50000]\n",
      "loss: 0.565682  [ 4544/50000]\n",
      "loss: 0.866394  [ 5184/50000]\n",
      "loss: 0.280343  [ 5824/50000]\n",
      "loss: 0.604860  [ 6464/50000]\n",
      "loss: 0.536683  [ 7104/50000]\n",
      "loss: 0.515876  [ 7744/50000]\n",
      "loss: 0.336945  [ 8384/50000]\n",
      "loss: 0.549421  [ 9024/50000]\n",
      "loss: 0.429140  [ 9664/50000]\n",
      "loss: 0.516361  [10304/50000]\n",
      "loss: 0.616547  [10944/50000]\n",
      "loss: 0.599362  [11584/50000]\n",
      "loss: 0.592812  [12224/50000]\n",
      "loss: 0.668276  [12864/50000]\n",
      "loss: 0.416431  [13504/50000]\n",
      "loss: 0.511017  [14144/50000]\n",
      "loss: 0.412969  [14784/50000]\n",
      "loss: 0.529508  [15424/50000]\n",
      "loss: 0.556220  [16064/50000]\n",
      "loss: 0.736230  [16704/50000]\n",
      "loss: 0.403239  [17344/50000]\n",
      "loss: 0.543202  [17984/50000]\n",
      "loss: 0.565442  [18624/50000]\n",
      "loss: 0.377933  [19264/50000]\n",
      "loss: 0.456040  [19904/50000]\n",
      "loss: 0.571675  [20544/50000]\n",
      "loss: 0.379726  [21184/50000]\n",
      "loss: 0.459923  [21824/50000]\n",
      "loss: 0.312950  [22464/50000]\n",
      "loss: 0.432444  [23104/50000]\n",
      "loss: 0.314706  [23744/50000]\n",
      "loss: 0.471834  [24384/50000]\n",
      "loss: 0.640016  [25024/50000]\n",
      "loss: 0.524879  [25664/50000]\n",
      "loss: 0.502158  [26304/50000]\n",
      "loss: 0.221652  [26944/50000]\n",
      "loss: 0.585143  [27584/50000]\n",
      "loss: 0.615949  [28224/50000]\n",
      "loss: 0.290621  [28864/50000]\n",
      "loss: 0.324323  [29504/50000]\n",
      "loss: 0.591293  [30144/50000]\n",
      "loss: 0.489254  [30784/50000]\n",
      "loss: 0.301581  [31424/50000]\n",
      "loss: 0.321268  [32064/50000]\n",
      "loss: 0.574830  [32704/50000]\n",
      "loss: 0.377526  [33344/50000]\n",
      "loss: 0.556121  [33984/50000]\n",
      "loss: 0.471168  [34624/50000]\n",
      "loss: 0.495365  [35264/50000]\n",
      "loss: 0.517822  [35904/50000]\n",
      "loss: 0.528056  [36544/50000]\n",
      "loss: 0.514967  [37184/50000]\n",
      "loss: 0.517355  [37824/50000]\n",
      "loss: 0.408783  [38464/50000]\n",
      "loss: 0.477220  [39104/50000]\n",
      "loss: 0.618805  [39744/50000]\n",
      "loss: 0.513279  [40384/50000]\n",
      "loss: 0.242358  [41024/50000]\n",
      "loss: 0.388644  [41664/50000]\n",
      "loss: 0.364335  [42304/50000]\n",
      "loss: 0.356562  [42944/50000]\n",
      "loss: 0.321319  [43584/50000]\n",
      "loss: 0.510927  [44224/50000]\n",
      "loss: 0.600945  [44864/50000]\n",
      "loss: 0.614430  [45504/50000]\n",
      "loss: 0.595727  [46144/50000]\n",
      "loss: 0.443065  [46784/50000]\n",
      "loss: 0.261822  [47424/50000]\n",
      "loss: 0.605347  [48064/50000]\n",
      "loss: 0.382179  [48704/50000]\n",
      "loss: 0.437620  [49344/50000]\n",
      "loss: 0.415719  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.632738 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.497899  [   64/50000]\n",
      "loss: 0.508906  [  704/50000]\n",
      "loss: 0.464050  [ 1344/50000]\n",
      "loss: 0.400957  [ 1984/50000]\n",
      "loss: 0.551182  [ 2624/50000]\n",
      "loss: 0.517074  [ 3264/50000]\n",
      "loss: 0.604448  [ 3904/50000]\n",
      "loss: 0.309247  [ 4544/50000]\n",
      "loss: 0.274129  [ 5184/50000]\n",
      "loss: 0.390112  [ 5824/50000]\n",
      "loss: 0.457078  [ 6464/50000]\n",
      "loss: 0.339352  [ 7104/50000]\n",
      "loss: 0.522366  [ 7744/50000]\n",
      "loss: 0.318740  [ 8384/50000]\n",
      "loss: 0.318917  [ 9024/50000]\n",
      "loss: 0.295041  [ 9664/50000]\n",
      "loss: 0.455050  [10304/50000]\n",
      "loss: 0.756102  [10944/50000]\n",
      "loss: 0.412163  [11584/50000]\n",
      "loss: 0.477058  [12224/50000]\n",
      "loss: 0.255782  [12864/50000]\n",
      "loss: 0.380402  [13504/50000]\n",
      "loss: 0.367836  [14144/50000]\n",
      "loss: 0.400497  [14784/50000]\n",
      "loss: 0.540680  [15424/50000]\n",
      "loss: 0.292511  [16064/50000]\n",
      "loss: 0.351527  [16704/50000]\n",
      "loss: 0.535710  [17344/50000]\n",
      "loss: 0.297576  [17984/50000]\n",
      "loss: 0.688321  [18624/50000]\n",
      "loss: 0.536871  [19264/50000]\n",
      "loss: 0.380134  [19904/50000]\n",
      "loss: 0.504514  [20544/50000]\n",
      "loss: 0.342641  [21184/50000]\n",
      "loss: 0.339545  [21824/50000]\n",
      "loss: 0.342619  [22464/50000]\n",
      "loss: 0.477930  [23104/50000]\n",
      "loss: 0.340101  [23744/50000]\n",
      "loss: 0.355639  [24384/50000]\n",
      "loss: 0.492450  [25024/50000]\n",
      "loss: 0.627471  [25664/50000]\n",
      "loss: 0.376841  [26304/50000]\n",
      "loss: 0.334808  [26944/50000]\n",
      "loss: 0.578667  [27584/50000]\n",
      "loss: 0.400376  [28224/50000]\n",
      "loss: 0.340223  [28864/50000]\n",
      "loss: 0.387887  [29504/50000]\n",
      "loss: 0.365703  [30144/50000]\n",
      "loss: 0.431375  [30784/50000]\n",
      "loss: 0.369462  [31424/50000]\n",
      "loss: 0.291775  [32064/50000]\n",
      "loss: 0.468567  [32704/50000]\n",
      "loss: 0.459062  [33344/50000]\n",
      "loss: 0.297643  [33984/50000]\n",
      "loss: 0.324916  [34624/50000]\n",
      "loss: 0.519891  [35264/50000]\n",
      "loss: 0.456755  [35904/50000]\n",
      "loss: 0.582878  [36544/50000]\n",
      "loss: 0.485641  [37184/50000]\n",
      "loss: 0.473693  [37824/50000]\n",
      "loss: 0.370292  [38464/50000]\n",
      "loss: 0.390957  [39104/50000]\n",
      "loss: 0.334322  [39744/50000]\n",
      "loss: 0.400520  [40384/50000]\n",
      "loss: 0.635805  [41024/50000]\n",
      "loss: 0.286634  [41664/50000]\n",
      "loss: 0.433794  [42304/50000]\n",
      "loss: 0.293198  [42944/50000]\n",
      "loss: 0.711899  [43584/50000]\n",
      "loss: 0.426940  [44224/50000]\n",
      "loss: 0.589250  [44864/50000]\n",
      "loss: 0.478708  [45504/50000]\n",
      "loss: 0.752017  [46144/50000]\n",
      "loss: 0.378857  [46784/50000]\n",
      "loss: 0.435483  [47424/50000]\n",
      "loss: 0.478362  [48064/50000]\n",
      "loss: 0.350353  [48704/50000]\n",
      "loss: 0.567855  [49344/50000]\n",
      "loss: 0.510879  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.602761 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.349206  [   64/50000]\n",
      "loss: 0.426636  [  704/50000]\n",
      "loss: 0.368736  [ 1344/50000]\n",
      "loss: 0.341316  [ 1984/50000]\n",
      "loss: 0.319011  [ 2624/50000]\n",
      "loss: 0.297760  [ 3264/50000]\n",
      "loss: 0.381964  [ 3904/50000]\n",
      "loss: 0.239883  [ 4544/50000]\n",
      "loss: 0.309853  [ 5184/50000]\n",
      "loss: 0.263726  [ 5824/50000]\n",
      "loss: 0.459001  [ 6464/50000]\n",
      "loss: 0.266867  [ 7104/50000]\n",
      "loss: 0.347746  [ 7744/50000]\n",
      "loss: 0.200742  [ 8384/50000]\n",
      "loss: 0.235991  [ 9024/50000]\n",
      "loss: 0.302851  [ 9664/50000]\n",
      "loss: 0.387200  [10304/50000]\n",
      "loss: 0.319261  [10944/50000]\n",
      "loss: 0.177306  [11584/50000]\n",
      "loss: 0.367513  [12224/50000]\n",
      "loss: 0.369641  [12864/50000]\n",
      "loss: 0.430678  [13504/50000]\n",
      "loss: 0.303436  [14144/50000]\n",
      "loss: 0.309709  [14784/50000]\n",
      "loss: 0.350085  [15424/50000]\n",
      "loss: 0.287243  [16064/50000]\n",
      "loss: 0.241077  [16704/50000]\n",
      "loss: 0.180982  [17344/50000]\n",
      "loss: 0.419766  [17984/50000]\n",
      "loss: 0.325938  [18624/50000]\n",
      "loss: 0.347786  [19264/50000]\n",
      "loss: 0.494880  [19904/50000]\n",
      "loss: 0.422148  [20544/50000]\n",
      "loss: 0.268998  [21184/50000]\n",
      "loss: 0.279941  [21824/50000]\n",
      "loss: 0.238028  [22464/50000]\n",
      "loss: 0.179605  [23104/50000]\n",
      "loss: 0.384005  [23744/50000]\n",
      "loss: 0.386801  [24384/50000]\n",
      "loss: 0.311450  [25024/50000]\n",
      "loss: 0.423093  [25664/50000]\n",
      "loss: 0.306065  [26304/50000]\n",
      "loss: 0.327302  [26944/50000]\n",
      "loss: 0.214631  [27584/50000]\n",
      "loss: 0.371979  [28224/50000]\n",
      "loss: 0.339897  [28864/50000]\n",
      "loss: 0.337318  [29504/50000]\n",
      "loss: 0.364324  [30144/50000]\n",
      "loss: 0.526510  [30784/50000]\n",
      "loss: 0.330330  [31424/50000]\n",
      "loss: 0.341228  [32064/50000]\n",
      "loss: 0.371638  [32704/50000]\n",
      "loss: 0.305429  [33344/50000]\n",
      "loss: 0.401489  [33984/50000]\n",
      "loss: 0.449339  [34624/50000]\n",
      "loss: 0.238558  [35264/50000]\n",
      "loss: 0.221752  [35904/50000]\n",
      "loss: 0.315092  [36544/50000]\n",
      "loss: 0.527154  [37184/50000]\n",
      "loss: 0.289990  [37824/50000]\n",
      "loss: 0.381682  [38464/50000]\n",
      "loss: 0.352590  [39104/50000]\n",
      "loss: 0.384267  [39744/50000]\n",
      "loss: 0.477021  [40384/50000]\n",
      "loss: 0.285217  [41024/50000]\n",
      "loss: 0.261847  [41664/50000]\n",
      "loss: 0.359824  [42304/50000]\n",
      "loss: 0.414397  [42944/50000]\n",
      "loss: 0.323620  [43584/50000]\n",
      "loss: 0.341167  [44224/50000]\n",
      "loss: 0.561984  [44864/50000]\n",
      "loss: 0.334459  [45504/50000]\n",
      "loss: 0.278271  [46144/50000]\n",
      "loss: 0.258511  [46784/50000]\n",
      "loss: 0.390485  [47424/50000]\n",
      "loss: 0.333855  [48064/50000]\n",
      "loss: 0.414526  [48704/50000]\n",
      "loss: 0.283773  [49344/50000]\n",
      "loss: 0.477182  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.559460 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.300458  [   64/50000]\n",
      "loss: 0.296896  [  704/50000]\n",
      "loss: 0.200634  [ 1344/50000]\n",
      "loss: 0.277641  [ 1984/50000]\n",
      "loss: 0.232802  [ 2624/50000]\n",
      "loss: 0.301972  [ 3264/50000]\n",
      "loss: 0.297938  [ 3904/50000]\n",
      "loss: 0.224485  [ 4544/50000]\n",
      "loss: 0.558306  [ 5184/50000]\n",
      "loss: 0.327877  [ 5824/50000]\n",
      "loss: 0.205584  [ 6464/50000]\n",
      "loss: 0.368445  [ 7104/50000]\n",
      "loss: 0.447271  [ 7744/50000]\n",
      "loss: 0.307625  [ 8384/50000]\n",
      "loss: 0.292302  [ 9024/50000]\n",
      "loss: 0.302059  [ 9664/50000]\n",
      "loss: 0.248602  [10304/50000]\n",
      "loss: 0.135412  [10944/50000]\n",
      "loss: 0.282744  [11584/50000]\n",
      "loss: 0.180356  [12224/50000]\n",
      "loss: 0.190209  [12864/50000]\n",
      "loss: 0.318441  [13504/50000]\n",
      "loss: 0.270079  [14144/50000]\n",
      "loss: 0.176546  [14784/50000]\n",
      "loss: 0.477889  [15424/50000]\n",
      "loss: 0.541853  [16064/50000]\n",
      "loss: 0.460940  [16704/50000]\n",
      "loss: 0.303924  [17344/50000]\n",
      "loss: 0.246263  [17984/50000]\n",
      "loss: 0.292397  [18624/50000]\n",
      "loss: 0.266537  [19264/50000]\n",
      "loss: 0.326884  [19904/50000]\n",
      "loss: 0.316477  [20544/50000]\n",
      "loss: 0.433753  [21184/50000]\n",
      "loss: 0.322430  [21824/50000]\n",
      "loss: 0.280952  [22464/50000]\n",
      "loss: 0.234472  [23104/50000]\n",
      "loss: 0.126294  [23744/50000]\n",
      "loss: 0.181152  [24384/50000]\n",
      "loss: 0.393730  [25024/50000]\n",
      "loss: 0.414361  [25664/50000]\n",
      "loss: 0.254296  [26304/50000]\n",
      "loss: 0.315136  [26944/50000]\n",
      "loss: 0.082294  [27584/50000]\n",
      "loss: 0.514245  [28224/50000]\n",
      "loss: 0.276624  [28864/50000]\n",
      "loss: 0.218916  [29504/50000]\n",
      "loss: 0.308198  [30144/50000]\n",
      "loss: 0.335440  [30784/50000]\n",
      "loss: 0.199248  [31424/50000]\n",
      "loss: 0.293604  [32064/50000]\n",
      "loss: 0.230150  [32704/50000]\n",
      "loss: 0.240410  [33344/50000]\n",
      "loss: 0.309275  [33984/50000]\n",
      "loss: 0.270161  [34624/50000]\n",
      "loss: 0.377006  [35264/50000]\n",
      "loss: 0.455800  [35904/50000]\n",
      "loss: 0.520705  [36544/50000]\n",
      "loss: 0.243726  [37184/50000]\n",
      "loss: 0.192827  [37824/50000]\n",
      "loss: 0.339224  [38464/50000]\n",
      "loss: 0.465924  [39104/50000]\n",
      "loss: 0.331086  [39744/50000]\n",
      "loss: 0.217202  [40384/50000]\n",
      "loss: 0.189817  [41024/50000]\n",
      "loss: 0.294085  [41664/50000]\n",
      "loss: 0.298888  [42304/50000]\n",
      "loss: 0.382170  [42944/50000]\n",
      "loss: 0.302714  [43584/50000]\n",
      "loss: 0.335964  [44224/50000]\n",
      "loss: 0.311487  [44864/50000]\n",
      "loss: 0.368434  [45504/50000]\n",
      "loss: 0.174109  [46144/50000]\n",
      "loss: 0.266252  [46784/50000]\n",
      "loss: 0.265596  [47424/50000]\n",
      "loss: 0.532811  [48064/50000]\n",
      "loss: 0.359932  [48704/50000]\n",
      "loss: 0.519309  [49344/50000]\n",
      "loss: 0.277702  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.549415 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.165984  [   64/50000]\n",
      "loss: 0.376806  [  704/50000]\n",
      "loss: 0.176964  [ 1344/50000]\n",
      "loss: 0.228293  [ 1984/50000]\n",
      "loss: 0.224923  [ 2624/50000]\n",
      "loss: 0.552244  [ 3264/50000]\n",
      "loss: 0.487645  [ 3904/50000]\n",
      "loss: 0.254524  [ 4544/50000]\n",
      "loss: 0.127777  [ 5184/50000]\n",
      "loss: 0.244999  [ 5824/50000]\n",
      "loss: 0.289341  [ 6464/50000]\n",
      "loss: 0.202927  [ 7104/50000]\n",
      "loss: 0.265608  [ 7744/50000]\n",
      "loss: 0.532000  [ 8384/50000]\n",
      "loss: 0.179826  [ 9024/50000]\n",
      "loss: 0.094705  [ 9664/50000]\n",
      "loss: 0.292199  [10304/50000]\n",
      "loss: 0.420285  [10944/50000]\n",
      "loss: 0.256052  [11584/50000]\n",
      "loss: 0.383278  [12224/50000]\n",
      "loss: 0.239018  [12864/50000]\n",
      "loss: 0.122702  [13504/50000]\n",
      "loss: 0.155037  [14144/50000]\n",
      "loss: 0.119925  [14784/50000]\n",
      "loss: 0.183838  [15424/50000]\n",
      "loss: 0.287443  [16064/50000]\n",
      "loss: 0.257665  [16704/50000]\n",
      "loss: 0.254781  [17344/50000]\n",
      "loss: 0.440310  [17984/50000]\n",
      "loss: 0.347150  [18624/50000]\n",
      "loss: 0.324161  [19264/50000]\n",
      "loss: 0.220985  [19904/50000]\n",
      "loss: 0.250121  [20544/50000]\n",
      "loss: 0.220687  [21184/50000]\n",
      "loss: 0.336919  [21824/50000]\n",
      "loss: 0.188940  [22464/50000]\n",
      "loss: 0.158515  [23104/50000]\n",
      "loss: 0.278090  [23744/50000]\n",
      "loss: 0.381443  [24384/50000]\n",
      "loss: 0.306996  [25024/50000]\n",
      "loss: 0.175720  [25664/50000]\n",
      "loss: 0.343880  [26304/50000]\n",
      "loss: 0.446161  [26944/50000]\n",
      "loss: 0.453373  [27584/50000]\n",
      "loss: 0.186658  [28224/50000]\n",
      "loss: 0.458210  [28864/50000]\n",
      "loss: 0.407027  [29504/50000]\n",
      "loss: 0.221749  [30144/50000]\n",
      "loss: 0.265680  [30784/50000]\n",
      "loss: 0.266196  [31424/50000]\n",
      "loss: 0.150402  [32064/50000]\n",
      "loss: 0.282079  [32704/50000]\n",
      "loss: 0.217166  [33344/50000]\n",
      "loss: 0.407078  [33984/50000]\n",
      "loss: 0.599524  [34624/50000]\n",
      "loss: 0.261298  [35264/50000]\n",
      "loss: 0.276836  [35904/50000]\n",
      "loss: 0.272262  [36544/50000]\n",
      "loss: 0.308622  [37184/50000]\n",
      "loss: 0.249016  [37824/50000]\n",
      "loss: 0.278036  [38464/50000]\n",
      "loss: 0.362508  [39104/50000]\n",
      "loss: 0.387325  [39744/50000]\n",
      "loss: 0.197773  [40384/50000]\n",
      "loss: 0.137261  [41024/50000]\n",
      "loss: 0.236124  [41664/50000]\n",
      "loss: 0.084185  [42304/50000]\n",
      "loss: 0.367645  [42944/50000]\n",
      "loss: 0.344148  [43584/50000]\n",
      "loss: 0.290384  [44224/50000]\n",
      "loss: 0.373123  [44864/50000]\n",
      "loss: 0.365432  [45504/50000]\n",
      "loss: 0.308105  [46144/50000]\n",
      "loss: 0.205429  [46784/50000]\n",
      "loss: 0.291612  [47424/50000]\n",
      "loss: 0.216751  [48064/50000]\n",
      "loss: 0.274417  [48704/50000]\n",
      "loss: 0.252027  [49344/50000]\n",
      "loss: 0.312015  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.642413 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.269568  [   64/50000]\n",
      "loss: 0.246695  [  704/50000]\n",
      "loss: 0.185346  [ 1344/50000]\n",
      "loss: 0.118519  [ 1984/50000]\n",
      "loss: 0.201708  [ 2624/50000]\n",
      "loss: 0.265321  [ 3264/50000]\n",
      "loss: 0.182678  [ 3904/50000]\n",
      "loss: 0.115458  [ 4544/50000]\n",
      "loss: 0.168347  [ 5184/50000]\n",
      "loss: 0.163978  [ 5824/50000]\n",
      "loss: 0.516413  [ 6464/50000]\n",
      "loss: 0.214485  [ 7104/50000]\n",
      "loss: 0.089553  [ 7744/50000]\n",
      "loss: 0.305787  [ 8384/50000]\n",
      "loss: 0.232000  [ 9024/50000]\n",
      "loss: 0.280113  [ 9664/50000]\n",
      "loss: 0.222107  [10304/50000]\n",
      "loss: 0.204154  [10944/50000]\n",
      "loss: 0.235960  [11584/50000]\n",
      "loss: 0.240297  [12224/50000]\n",
      "loss: 0.185440  [12864/50000]\n",
      "loss: 0.233926  [13504/50000]\n",
      "loss: 0.188821  [14144/50000]\n",
      "loss: 0.198602  [14784/50000]\n",
      "loss: 0.272162  [15424/50000]\n",
      "loss: 0.183536  [16064/50000]\n",
      "loss: 0.110664  [16704/50000]\n",
      "loss: 0.139463  [17344/50000]\n",
      "loss: 0.217440  [17984/50000]\n",
      "loss: 0.278136  [18624/50000]\n",
      "loss: 0.162687  [19264/50000]\n",
      "loss: 0.236086  [19904/50000]\n",
      "loss: 0.290890  [20544/50000]\n",
      "loss: 0.192268  [21184/50000]\n",
      "loss: 0.214897  [21824/50000]\n",
      "loss: 0.160410  [22464/50000]\n",
      "loss: 0.177632  [23104/50000]\n",
      "loss: 0.105656  [23744/50000]\n",
      "loss: 0.217902  [24384/50000]\n",
      "loss: 0.186919  [25024/50000]\n",
      "loss: 0.163484  [25664/50000]\n",
      "loss: 0.066991  [26304/50000]\n",
      "loss: 0.154077  [26944/50000]\n",
      "loss: 0.127850  [27584/50000]\n",
      "loss: 0.198361  [28224/50000]\n",
      "loss: 0.233096  [28864/50000]\n",
      "loss: 0.237361  [29504/50000]\n",
      "loss: 0.167054  [30144/50000]\n",
      "loss: 0.199076  [30784/50000]\n",
      "loss: 0.197287  [31424/50000]\n",
      "loss: 0.089575  [32064/50000]\n",
      "loss: 0.369515  [32704/50000]\n",
      "loss: 0.298841  [33344/50000]\n",
      "loss: 0.307951  [33984/50000]\n",
      "loss: 0.239816  [34624/50000]\n",
      "loss: 0.271841  [35264/50000]\n",
      "loss: 0.217438  [35904/50000]\n",
      "loss: 0.264159  [36544/50000]\n",
      "loss: 0.133257  [37184/50000]\n",
      "loss: 0.282024  [37824/50000]\n",
      "loss: 0.328443  [38464/50000]\n",
      "loss: 0.211713  [39104/50000]\n",
      "loss: 0.226021  [39744/50000]\n",
      "loss: 0.145580  [40384/50000]\n",
      "loss: 0.340142  [41024/50000]\n",
      "loss: 0.263237  [41664/50000]\n",
      "loss: 0.206140  [42304/50000]\n",
      "loss: 0.451233  [42944/50000]\n",
      "loss: 0.086060  [43584/50000]\n",
      "loss: 0.150028  [44224/50000]\n",
      "loss: 0.158814  [44864/50000]\n",
      "loss: 0.260258  [45504/50000]\n",
      "loss: 0.337073  [46144/50000]\n",
      "loss: 0.195466  [46784/50000]\n",
      "loss: 0.234980  [47424/50000]\n",
      "loss: 0.134334  [48064/50000]\n",
      "loss: 0.205406  [48704/50000]\n",
      "loss: 0.361159  [49344/50000]\n",
      "loss: 0.381381  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.581073 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.313330  [   64/50000]\n",
      "loss: 0.187024  [  704/50000]\n",
      "loss: 0.170926  [ 1344/50000]\n",
      "loss: 0.234439  [ 1984/50000]\n",
      "loss: 0.062327  [ 2624/50000]\n",
      "loss: 0.145422  [ 3264/50000]\n",
      "loss: 0.148642  [ 3904/50000]\n",
      "loss: 0.055883  [ 4544/50000]\n",
      "loss: 0.151265  [ 5184/50000]\n",
      "loss: 0.194632  [ 5824/50000]\n",
      "loss: 0.204775  [ 6464/50000]\n",
      "loss: 0.202005  [ 7104/50000]\n",
      "loss: 0.078840  [ 7744/50000]\n",
      "loss: 0.284975  [ 8384/50000]\n",
      "loss: 0.157828  [ 9024/50000]\n",
      "loss: 0.106904  [ 9664/50000]\n",
      "loss: 0.214993  [10304/50000]\n",
      "loss: 0.228467  [10944/50000]\n",
      "loss: 0.257678  [11584/50000]\n",
      "loss: 0.271509  [12224/50000]\n",
      "loss: 0.124415  [12864/50000]\n",
      "loss: 0.173892  [13504/50000]\n",
      "loss: 0.185639  [14144/50000]\n",
      "loss: 0.179876  [14784/50000]\n",
      "loss: 0.256888  [15424/50000]\n",
      "loss: 0.243604  [16064/50000]\n",
      "loss: 0.126803  [16704/50000]\n",
      "loss: 0.151265  [17344/50000]\n",
      "loss: 0.186791  [17984/50000]\n",
      "loss: 0.190174  [18624/50000]\n",
      "loss: 0.081640  [19264/50000]\n",
      "loss: 0.168668  [19904/50000]\n",
      "loss: 0.237020  [20544/50000]\n",
      "loss: 0.112178  [21184/50000]\n",
      "loss: 0.200827  [21824/50000]\n",
      "loss: 0.233714  [22464/50000]\n",
      "loss: 0.156095  [23104/50000]\n",
      "loss: 0.170635  [23744/50000]\n",
      "loss: 0.175292  [24384/50000]\n",
      "loss: 0.306267  [25024/50000]\n",
      "loss: 0.222721  [25664/50000]\n",
      "loss: 0.174059  [26304/50000]\n",
      "loss: 0.286189  [26944/50000]\n",
      "loss: 0.109377  [27584/50000]\n",
      "loss: 0.225827  [28224/50000]\n",
      "loss: 0.089266  [28864/50000]\n",
      "loss: 0.264577  [29504/50000]\n",
      "loss: 0.261023  [30144/50000]\n",
      "loss: 0.199846  [30784/50000]\n",
      "loss: 0.105914  [31424/50000]\n",
      "loss: 0.155618  [32064/50000]\n",
      "loss: 0.264529  [32704/50000]\n",
      "loss: 0.211600  [33344/50000]\n",
      "loss: 0.160528  [33984/50000]\n",
      "loss: 0.075260  [34624/50000]\n",
      "loss: 0.123129  [35264/50000]\n",
      "loss: 0.319086  [35904/50000]\n",
      "loss: 0.139796  [36544/50000]\n",
      "loss: 0.186668  [37184/50000]\n",
      "loss: 0.174942  [37824/50000]\n",
      "loss: 0.155105  [38464/50000]\n",
      "loss: 0.277657  [39104/50000]\n",
      "loss: 0.270398  [39744/50000]\n",
      "loss: 0.195349  [40384/50000]\n",
      "loss: 0.282332  [41024/50000]\n",
      "loss: 0.138025  [41664/50000]\n",
      "loss: 0.142737  [42304/50000]\n",
      "loss: 0.152666  [42944/50000]\n",
      "loss: 0.176301  [43584/50000]\n",
      "loss: 0.100177  [44224/50000]\n",
      "loss: 0.179222  [44864/50000]\n",
      "loss: 0.100898  [45504/50000]\n",
      "loss: 0.230127  [46144/50000]\n",
      "loss: 0.127492  [46784/50000]\n",
      "loss: 0.304083  [47424/50000]\n",
      "loss: 0.173193  [48064/50000]\n",
      "loss: 0.433456  [48704/50000]\n",
      "loss: 0.268792  [49344/50000]\n",
      "loss: 0.192433  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.591081 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.203829  [   64/50000]\n",
      "loss: 0.059101  [  704/50000]\n",
      "loss: 0.103391  [ 1344/50000]\n",
      "loss: 0.086364  [ 1984/50000]\n",
      "loss: 0.198724  [ 2624/50000]\n",
      "loss: 0.102828  [ 3264/50000]\n",
      "loss: 0.130656  [ 3904/50000]\n",
      "loss: 0.113451  [ 4544/50000]\n",
      "loss: 0.131462  [ 5184/50000]\n",
      "loss: 0.095522  [ 5824/50000]\n",
      "loss: 0.314620  [ 6464/50000]\n",
      "loss: 0.090970  [ 7104/50000]\n",
      "loss: 0.165625  [ 7744/50000]\n",
      "loss: 0.066012  [ 8384/50000]\n",
      "loss: 0.122511  [ 9024/50000]\n",
      "loss: 0.158997  [ 9664/50000]\n",
      "loss: 0.197727  [10304/50000]\n",
      "loss: 0.203284  [10944/50000]\n",
      "loss: 0.158023  [11584/50000]\n",
      "loss: 0.054601  [12224/50000]\n",
      "loss: 0.178308  [12864/50000]\n",
      "loss: 0.133907  [13504/50000]\n",
      "loss: 0.232065  [14144/50000]\n",
      "loss: 0.303303  [14784/50000]\n",
      "loss: 0.069730  [15424/50000]\n",
      "loss: 0.313749  [16064/50000]\n",
      "loss: 0.214204  [16704/50000]\n",
      "loss: 0.106033  [17344/50000]\n",
      "loss: 0.046448  [17984/50000]\n",
      "loss: 0.217686  [18624/50000]\n",
      "loss: 0.089052  [19264/50000]\n",
      "loss: 0.091610  [19904/50000]\n",
      "loss: 0.229637  [20544/50000]\n",
      "loss: 0.111405  [21184/50000]\n",
      "loss: 0.074379  [21824/50000]\n",
      "loss: 0.275001  [22464/50000]\n",
      "loss: 0.055249  [23104/50000]\n",
      "loss: 0.163609  [23744/50000]\n",
      "loss: 0.098059  [24384/50000]\n",
      "loss: 0.083966  [25024/50000]\n",
      "loss: 0.098795  [25664/50000]\n",
      "loss: 0.132259  [26304/50000]\n",
      "loss: 0.163431  [26944/50000]\n",
      "loss: 0.073927  [27584/50000]\n",
      "loss: 0.196071  [28224/50000]\n",
      "loss: 0.214041  [28864/50000]\n",
      "loss: 0.170909  [29504/50000]\n",
      "loss: 0.106271  [30144/50000]\n",
      "loss: 0.096902  [30784/50000]\n",
      "loss: 0.159359  [31424/50000]\n",
      "loss: 0.182614  [32064/50000]\n",
      "loss: 0.477394  [32704/50000]\n",
      "loss: 0.250416  [33344/50000]\n",
      "loss: 0.148488  [33984/50000]\n",
      "loss: 0.183812  [34624/50000]\n",
      "loss: 0.204082  [35264/50000]\n",
      "loss: 0.133361  [35904/50000]\n",
      "loss: 0.171889  [36544/50000]\n",
      "loss: 0.252244  [37184/50000]\n",
      "loss: 0.316490  [37824/50000]\n",
      "loss: 0.140511  [38464/50000]\n",
      "loss: 0.090982  [39104/50000]\n",
      "loss: 0.188455  [39744/50000]\n",
      "loss: 0.211776  [40384/50000]\n",
      "loss: 0.164420  [41024/50000]\n",
      "loss: 0.118180  [41664/50000]\n",
      "loss: 0.114476  [42304/50000]\n",
      "loss: 0.124535  [42944/50000]\n",
      "loss: 0.257768  [43584/50000]\n",
      "loss: 0.116289  [44224/50000]\n",
      "loss: 0.264477  [44864/50000]\n",
      "loss: 0.181164  [45504/50000]\n",
      "loss: 0.065649  [46144/50000]\n",
      "loss: 0.070668  [46784/50000]\n",
      "loss: 0.216875  [47424/50000]\n",
      "loss: 0.264846  [48064/50000]\n",
      "loss: 0.120409  [48704/50000]\n",
      "loss: 0.258190  [49344/50000]\n",
      "loss: 0.140411  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.628658 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.091682  [   64/50000]\n",
      "loss: 0.125756  [  704/50000]\n",
      "loss: 0.079705  [ 1344/50000]\n",
      "loss: 0.086403  [ 1984/50000]\n",
      "loss: 0.138035  [ 2624/50000]\n",
      "loss: 0.178443  [ 3264/50000]\n",
      "loss: 0.099597  [ 3904/50000]\n",
      "loss: 0.055217  [ 4544/50000]\n",
      "loss: 0.155289  [ 5184/50000]\n",
      "loss: 0.177284  [ 5824/50000]\n",
      "loss: 0.249812  [ 6464/50000]\n",
      "loss: 0.099119  [ 7104/50000]\n",
      "loss: 0.051824  [ 7744/50000]\n",
      "loss: 0.066327  [ 8384/50000]\n",
      "loss: 0.243159  [ 9024/50000]\n",
      "loss: 0.160864  [ 9664/50000]\n",
      "loss: 0.176989  [10304/50000]\n",
      "loss: 0.203205  [10944/50000]\n",
      "loss: 0.083561  [11584/50000]\n",
      "loss: 0.082665  [12224/50000]\n",
      "loss: 0.190994  [12864/50000]\n",
      "loss: 0.256702  [13504/50000]\n",
      "loss: 0.163695  [14144/50000]\n",
      "loss: 0.205305  [14784/50000]\n",
      "loss: 0.173311  [15424/50000]\n",
      "loss: 0.083523  [16064/50000]\n",
      "loss: 0.223160  [16704/50000]\n",
      "loss: 0.293204  [17344/50000]\n",
      "loss: 0.305187  [17984/50000]\n",
      "loss: 0.132922  [18624/50000]\n",
      "loss: 0.059863  [19264/50000]\n",
      "loss: 0.135925  [19904/50000]\n",
      "loss: 0.144262  [20544/50000]\n",
      "loss: 0.057915  [21184/50000]\n",
      "loss: 0.182501  [21824/50000]\n",
      "loss: 0.209732  [22464/50000]\n",
      "loss: 0.180031  [23104/50000]\n",
      "loss: 0.240129  [23744/50000]\n",
      "loss: 0.244851  [24384/50000]\n",
      "loss: 0.182611  [25024/50000]\n",
      "loss: 0.343676  [25664/50000]\n",
      "loss: 0.164427  [26304/50000]\n",
      "loss: 0.155600  [26944/50000]\n",
      "loss: 0.197993  [27584/50000]\n",
      "loss: 0.250096  [28224/50000]\n",
      "loss: 0.136013  [28864/50000]\n",
      "loss: 0.189246  [29504/50000]\n",
      "loss: 0.394437  [30144/50000]\n",
      "loss: 0.139528  [30784/50000]\n",
      "loss: 0.106913  [31424/50000]\n",
      "loss: 0.161663  [32064/50000]\n",
      "loss: 0.069674  [32704/50000]\n",
      "loss: 0.090568  [33344/50000]\n",
      "loss: 0.245367  [33984/50000]\n",
      "loss: 0.164354  [34624/50000]\n",
      "loss: 0.138437  [35264/50000]\n",
      "loss: 0.080525  [35904/50000]\n",
      "loss: 0.190267  [36544/50000]\n",
      "loss: 0.127032  [37184/50000]\n",
      "loss: 0.136924  [37824/50000]\n",
      "loss: 0.273522  [38464/50000]\n",
      "loss: 0.130885  [39104/50000]\n",
      "loss: 0.230530  [39744/50000]\n",
      "loss: 0.134263  [40384/50000]\n",
      "loss: 0.415040  [41024/50000]\n",
      "loss: 0.147705  [41664/50000]\n",
      "loss: 0.085116  [42304/50000]\n",
      "loss: 0.204708  [42944/50000]\n",
      "loss: 0.135230  [43584/50000]\n",
      "loss: 0.273938  [44224/50000]\n",
      "loss: 0.098830  [44864/50000]\n",
      "loss: 0.175058  [45504/50000]\n",
      "loss: 0.203819  [46144/50000]\n",
      "loss: 0.131784  [46784/50000]\n",
      "loss: 0.132177  [47424/50000]\n",
      "loss: 0.237889  [48064/50000]\n",
      "loss: 0.173525  [48704/50000]\n",
      "loss: 0.155154  [49344/50000]\n",
      "loss: 0.340909  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.621459 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.060872  [   64/50000]\n",
      "loss: 0.232315  [  704/50000]\n",
      "loss: 0.229581  [ 1344/50000]\n",
      "loss: 0.217787  [ 1984/50000]\n",
      "loss: 0.077096  [ 2624/50000]\n",
      "loss: 0.159434  [ 3264/50000]\n",
      "loss: 0.162463  [ 3904/50000]\n",
      "loss: 0.130541  [ 4544/50000]\n",
      "loss: 0.036856  [ 5184/50000]\n",
      "loss: 0.081121  [ 5824/50000]\n",
      "loss: 0.199055  [ 6464/50000]\n",
      "loss: 0.098848  [ 7104/50000]\n",
      "loss: 0.177928  [ 7744/50000]\n",
      "loss: 0.105218  [ 8384/50000]\n",
      "loss: 0.191332  [ 9024/50000]\n",
      "loss: 0.336983  [ 9664/50000]\n",
      "loss: 0.022566  [10304/50000]\n",
      "loss: 0.399203  [10944/50000]\n",
      "loss: 0.147739  [11584/50000]\n",
      "loss: 0.044980  [12224/50000]\n",
      "loss: 0.110474  [12864/50000]\n",
      "loss: 0.112089  [13504/50000]\n",
      "loss: 0.082804  [14144/50000]\n",
      "loss: 0.187232  [14784/50000]\n",
      "loss: 0.075859  [15424/50000]\n",
      "loss: 0.081955  [16064/50000]\n",
      "loss: 0.255964  [16704/50000]\n",
      "loss: 0.075661  [17344/50000]\n",
      "loss: 0.163045  [17984/50000]\n",
      "loss: 0.171764  [18624/50000]\n",
      "loss: 0.202475  [19264/50000]\n",
      "loss: 0.231796  [19904/50000]\n",
      "loss: 0.151939  [20544/50000]\n",
      "loss: 0.262535  [21184/50000]\n",
      "loss: 0.104883  [21824/50000]\n",
      "loss: 0.160557  [22464/50000]\n",
      "loss: 0.265251  [23104/50000]\n",
      "loss: 0.049544  [23744/50000]\n",
      "loss: 0.065508  [24384/50000]\n",
      "loss: 0.198661  [25024/50000]\n",
      "loss: 0.278025  [25664/50000]\n",
      "loss: 0.258214  [26304/50000]\n",
      "loss: 0.143338  [26944/50000]\n",
      "loss: 0.145794  [27584/50000]\n",
      "loss: 0.174570  [28224/50000]\n",
      "loss: 0.044583  [28864/50000]\n",
      "loss: 0.102902  [29504/50000]\n",
      "loss: 0.249742  [30144/50000]\n",
      "loss: 0.075121  [30784/50000]\n",
      "loss: 0.116871  [31424/50000]\n",
      "loss: 0.082059  [32064/50000]\n",
      "loss: 0.057910  [32704/50000]\n",
      "loss: 0.138578  [33344/50000]\n",
      "loss: 0.115512  [33984/50000]\n",
      "loss: 0.122682  [34624/50000]\n",
      "loss: 0.177383  [35264/50000]\n",
      "loss: 0.254465  [35904/50000]\n",
      "loss: 0.194224  [36544/50000]\n",
      "loss: 0.062392  [37184/50000]\n",
      "loss: 0.247351  [37824/50000]\n",
      "loss: 0.089890  [38464/50000]\n",
      "loss: 0.036103  [39104/50000]\n",
      "loss: 0.321325  [39744/50000]\n",
      "loss: 0.148221  [40384/50000]\n",
      "loss: 0.149555  [41024/50000]\n",
      "loss: 0.208792  [41664/50000]\n",
      "loss: 0.147806  [42304/50000]\n",
      "loss: 0.093436  [42944/50000]\n",
      "loss: 0.189112  [43584/50000]\n",
      "loss: 0.142262  [44224/50000]\n",
      "loss: 0.244365  [44864/50000]\n",
      "loss: 0.248435  [45504/50000]\n",
      "loss: 0.192485  [46144/50000]\n",
      "loss: 0.068000  [46784/50000]\n",
      "loss: 0.140963  [47424/50000]\n",
      "loss: 0.132124  [48064/50000]\n",
      "loss: 0.132209  [48704/50000]\n",
      "loss: 0.268770  [49344/50000]\n",
      "loss: 0.192357  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.687589 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.127506  [   64/50000]\n",
      "loss: 0.268651  [  704/50000]\n",
      "loss: 0.199662  [ 1344/50000]\n",
      "loss: 0.111232  [ 1984/50000]\n",
      "loss: 0.202894  [ 2624/50000]\n",
      "loss: 0.173910  [ 3264/50000]\n",
      "loss: 0.115645  [ 3904/50000]\n",
      "loss: 0.230703  [ 4544/50000]\n",
      "loss: 0.099156  [ 5184/50000]\n",
      "loss: 0.202597  [ 5824/50000]\n",
      "loss: 0.115017  [ 6464/50000]\n",
      "loss: 0.180247  [ 7104/50000]\n",
      "loss: 0.235567  [ 7744/50000]\n",
      "loss: 0.057464  [ 8384/50000]\n",
      "loss: 0.094109  [ 9024/50000]\n",
      "loss: 0.107882  [ 9664/50000]\n",
      "loss: 0.103538  [10304/50000]\n",
      "loss: 0.142014  [10944/50000]\n",
      "loss: 0.064971  [11584/50000]\n",
      "loss: 0.163699  [12224/50000]\n",
      "loss: 0.187389  [12864/50000]\n",
      "loss: 0.134868  [13504/50000]\n",
      "loss: 0.093570  [14144/50000]\n",
      "loss: 0.200445  [14784/50000]\n",
      "loss: 0.287394  [15424/50000]\n",
      "loss: 0.060219  [16064/50000]\n",
      "loss: 0.090469  [16704/50000]\n",
      "loss: 0.076574  [17344/50000]\n",
      "loss: 0.018908  [17984/50000]\n",
      "loss: 0.122652  [18624/50000]\n",
      "loss: 0.151602  [19264/50000]\n",
      "loss: 0.047340  [19904/50000]\n",
      "loss: 0.320730  [20544/50000]\n",
      "loss: 0.091796  [21184/50000]\n",
      "loss: 0.101156  [21824/50000]\n",
      "loss: 0.036146  [22464/50000]\n",
      "loss: 0.146845  [23104/50000]\n",
      "loss: 0.209434  [23744/50000]\n",
      "loss: 0.127073  [24384/50000]\n",
      "loss: 0.119480  [25024/50000]\n",
      "loss: 0.158529  [25664/50000]\n",
      "loss: 0.202358  [26304/50000]\n",
      "loss: 0.023359  [26944/50000]\n",
      "loss: 0.184675  [27584/50000]\n",
      "loss: 0.122517  [28224/50000]\n",
      "loss: 0.236497  [28864/50000]\n",
      "loss: 0.122282  [29504/50000]\n",
      "loss: 0.128365  [30144/50000]\n",
      "loss: 0.133788  [30784/50000]\n",
      "loss: 0.170397  [31424/50000]\n",
      "loss: 0.145780  [32064/50000]\n",
      "loss: 0.110454  [32704/50000]\n",
      "loss: 0.202591  [33344/50000]\n",
      "loss: 0.122075  [33984/50000]\n",
      "loss: 0.145288  [34624/50000]\n",
      "loss: 0.262265  [35264/50000]\n",
      "loss: 0.197237  [35904/50000]\n",
      "loss: 0.068892  [36544/50000]\n",
      "loss: 0.289491  [37184/50000]\n",
      "loss: 0.132364  [37824/50000]\n",
      "loss: 0.022847  [38464/50000]\n",
      "loss: 0.247685  [39104/50000]\n",
      "loss: 0.141557  [39744/50000]\n",
      "loss: 0.098969  [40384/50000]\n",
      "loss: 0.083234  [41024/50000]\n",
      "loss: 0.118800  [41664/50000]\n",
      "loss: 0.126840  [42304/50000]\n",
      "loss: 0.083636  [42944/50000]\n",
      "loss: 0.179774  [43584/50000]\n",
      "loss: 0.053512  [44224/50000]\n",
      "loss: 0.121687  [44864/50000]\n",
      "loss: 0.097909  [45504/50000]\n",
      "loss: 0.191801  [46144/50000]\n",
      "loss: 0.170582  [46784/50000]\n",
      "loss: 0.254610  [47424/50000]\n",
      "loss: 0.188615  [48064/50000]\n",
      "loss: 0.123982  [48704/50000]\n",
      "loss: 0.208839  [49344/50000]\n",
      "loss: 0.263504  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.703297 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.148807  [   64/50000]\n",
      "loss: 0.110306  [  704/50000]\n",
      "loss: 0.191035  [ 1344/50000]\n",
      "loss: 0.054542  [ 1984/50000]\n",
      "loss: 0.074425  [ 2624/50000]\n",
      "loss: 0.160644  [ 3264/50000]\n",
      "loss: 0.116086  [ 3904/50000]\n",
      "loss: 0.186351  [ 4544/50000]\n",
      "loss: 0.050255  [ 5184/50000]\n",
      "loss: 0.051798  [ 5824/50000]\n",
      "loss: 0.052586  [ 6464/50000]\n",
      "loss: 0.040889  [ 7104/50000]\n",
      "loss: 0.110620  [ 7744/50000]\n",
      "loss: 0.064681  [ 8384/50000]\n",
      "loss: 0.063903  [ 9024/50000]\n",
      "loss: 0.087046  [ 9664/50000]\n",
      "loss: 0.078814  [10304/50000]\n",
      "loss: 0.112141  [10944/50000]\n",
      "loss: 0.020937  [11584/50000]\n",
      "loss: 0.123696  [12224/50000]\n",
      "loss: 0.037546  [12864/50000]\n",
      "loss: 0.104561  [13504/50000]\n",
      "loss: 0.106367  [14144/50000]\n",
      "loss: 0.079289  [14784/50000]\n",
      "loss: 0.065854  [15424/50000]\n",
      "loss: 0.131322  [16064/50000]\n",
      "loss: 0.069292  [16704/50000]\n",
      "loss: 0.241095  [17344/50000]\n",
      "loss: 0.091074  [17984/50000]\n",
      "loss: 0.103341  [18624/50000]\n",
      "loss: 0.054153  [19264/50000]\n",
      "loss: 0.150832  [19904/50000]\n",
      "loss: 0.258341  [20544/50000]\n",
      "loss: 0.134845  [21184/50000]\n",
      "loss: 0.137980  [21824/50000]\n",
      "loss: 0.046848  [22464/50000]\n",
      "loss: 0.095614  [23104/50000]\n",
      "loss: 0.180343  [23744/50000]\n",
      "loss: 0.148486  [24384/50000]\n",
      "loss: 0.110789  [25024/50000]\n",
      "loss: 0.145378  [25664/50000]\n",
      "loss: 0.138879  [26304/50000]\n",
      "loss: 0.132127  [26944/50000]\n",
      "loss: 0.226238  [27584/50000]\n",
      "loss: 0.154729  [28224/50000]\n",
      "loss: 0.042618  [28864/50000]\n",
      "loss: 0.104505  [29504/50000]\n",
      "loss: 0.215336  [30144/50000]\n",
      "loss: 0.095118  [30784/50000]\n",
      "loss: 0.133644  [31424/50000]\n",
      "loss: 0.107339  [32064/50000]\n",
      "loss: 0.160434  [32704/50000]\n",
      "loss: 0.062830  [33344/50000]\n",
      "loss: 0.094501  [33984/50000]\n",
      "loss: 0.134231  [34624/50000]\n",
      "loss: 0.158675  [35264/50000]\n",
      "loss: 0.150287  [35904/50000]\n",
      "loss: 0.114631  [36544/50000]\n",
      "loss: 0.072642  [37184/50000]\n",
      "loss: 0.217665  [37824/50000]\n",
      "loss: 0.118276  [38464/50000]\n",
      "loss: 0.064727  [39104/50000]\n",
      "loss: 0.204104  [39744/50000]\n",
      "loss: 0.075767  [40384/50000]\n",
      "loss: 0.071042  [41024/50000]\n",
      "loss: 0.218934  [41664/50000]\n",
      "loss: 0.083916  [42304/50000]\n",
      "loss: 0.084734  [42944/50000]\n",
      "loss: 0.061851  [43584/50000]\n",
      "loss: 0.105064  [44224/50000]\n",
      "loss: 0.379922  [44864/50000]\n",
      "loss: 0.058975  [45504/50000]\n",
      "loss: 0.250887  [46144/50000]\n",
      "loss: 0.119513  [46784/50000]\n",
      "loss: 0.040236  [47424/50000]\n",
      "loss: 0.213430  [48064/50000]\n",
      "loss: 0.151221  [48704/50000]\n",
      "loss: 0.061648  [49344/50000]\n",
      "loss: 0.117658  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.664793 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.044623  [   64/50000]\n",
      "loss: 0.051597  [  704/50000]\n",
      "loss: 0.214659  [ 1344/50000]\n",
      "loss: 0.031108  [ 1984/50000]\n",
      "loss: 0.144665  [ 2624/50000]\n",
      "loss: 0.080490  [ 3264/50000]\n",
      "loss: 0.116995  [ 3904/50000]\n",
      "loss: 0.050023  [ 4544/50000]\n",
      "loss: 0.199720  [ 5184/50000]\n",
      "loss: 0.324757  [ 5824/50000]\n",
      "loss: 0.097696  [ 6464/50000]\n",
      "loss: 0.007052  [ 7104/50000]\n",
      "loss: 0.072742  [ 7744/50000]\n",
      "loss: 0.157027  [ 8384/50000]\n",
      "loss: 0.050114  [ 9024/50000]\n",
      "loss: 0.046779  [ 9664/50000]\n",
      "loss: 0.037752  [10304/50000]\n",
      "loss: 0.086177  [10944/50000]\n",
      "loss: 0.016921  [11584/50000]\n",
      "loss: 0.315378  [12224/50000]\n",
      "loss: 0.137269  [12864/50000]\n",
      "loss: 0.105329  [13504/50000]\n",
      "loss: 0.108855  [14144/50000]\n",
      "loss: 0.130017  [14784/50000]\n",
      "loss: 0.104740  [15424/50000]\n",
      "loss: 0.088170  [16064/50000]\n",
      "loss: 0.133812  [16704/50000]\n",
      "loss: 0.066705  [17344/50000]\n",
      "loss: 0.078821  [17984/50000]\n",
      "loss: 0.065263  [18624/50000]\n",
      "loss: 0.103657  [19264/50000]\n",
      "loss: 0.253827  [19904/50000]\n",
      "loss: 0.095939  [20544/50000]\n",
      "loss: 0.125883  [21184/50000]\n",
      "loss: 0.297149  [21824/50000]\n",
      "loss: 0.207625  [22464/50000]\n",
      "loss: 0.153443  [23104/50000]\n",
      "loss: 0.107105  [23744/50000]\n",
      "loss: 0.239662  [24384/50000]\n",
      "loss: 0.102692  [25024/50000]\n",
      "loss: 0.084919  [25664/50000]\n",
      "loss: 0.102050  [26304/50000]\n",
      "loss: 0.084527  [26944/50000]\n",
      "loss: 0.044987  [27584/50000]\n",
      "loss: 0.251749  [28224/50000]\n",
      "loss: 0.137260  [28864/50000]\n",
      "loss: 0.052967  [29504/50000]\n",
      "loss: 0.069572  [30144/50000]\n",
      "loss: 0.139976  [30784/50000]\n",
      "loss: 0.129234  [31424/50000]\n",
      "loss: 0.043332  [32064/50000]\n",
      "loss: 0.115936  [32704/50000]\n",
      "loss: 0.147136  [33344/50000]\n",
      "loss: 0.077238  [33984/50000]\n",
      "loss: 0.068955  [34624/50000]\n",
      "loss: 0.096016  [35264/50000]\n",
      "loss: 0.177331  [35904/50000]\n",
      "loss: 0.171463  [36544/50000]\n",
      "loss: 0.130575  [37184/50000]\n",
      "loss: 0.124415  [37824/50000]\n",
      "loss: 0.124102  [38464/50000]\n",
      "loss: 0.071372  [39104/50000]\n",
      "loss: 0.050198  [39744/50000]\n",
      "loss: 0.098991  [40384/50000]\n",
      "loss: 0.211131  [41024/50000]\n",
      "loss: 0.149285  [41664/50000]\n",
      "loss: 0.101776  [42304/50000]\n",
      "loss: 0.070099  [42944/50000]\n",
      "loss: 0.167305  [43584/50000]\n",
      "loss: 0.078551  [44224/50000]\n",
      "loss: 0.206012  [44864/50000]\n",
      "loss: 0.036800  [45504/50000]\n",
      "loss: 0.239307  [46144/50000]\n",
      "loss: 0.251925  [46784/50000]\n",
      "loss: 0.070049  [47424/50000]\n",
      "loss: 0.056067  [48064/50000]\n",
      "loss: 0.212556  [48704/50000]\n",
      "loss: 0.075434  [49344/50000]\n",
      "loss: 0.079459  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.691194 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.133401  [   64/50000]\n",
      "loss: 0.086557  [  704/50000]\n",
      "loss: 0.041102  [ 1344/50000]\n",
      "loss: 0.075153  [ 1984/50000]\n",
      "loss: 0.021371  [ 2624/50000]\n",
      "loss: 0.046009  [ 3264/50000]\n",
      "loss: 0.093374  [ 3904/50000]\n",
      "loss: 0.123810  [ 4544/50000]\n",
      "loss: 0.054447  [ 5184/50000]\n",
      "loss: 0.111018  [ 5824/50000]\n",
      "loss: 0.108691  [ 6464/50000]\n",
      "loss: 0.038263  [ 7104/50000]\n",
      "loss: 0.018629  [ 7744/50000]\n",
      "loss: 0.032836  [ 8384/50000]\n",
      "loss: 0.112656  [ 9024/50000]\n",
      "loss: 0.116553  [ 9664/50000]\n",
      "loss: 0.026754  [10304/50000]\n",
      "loss: 0.068407  [10944/50000]\n",
      "loss: 0.115647  [11584/50000]\n",
      "loss: 0.095123  [12224/50000]\n",
      "loss: 0.090236  [12864/50000]\n",
      "loss: 0.201487  [13504/50000]\n",
      "loss: 0.095310  [14144/50000]\n",
      "loss: 0.040798  [14784/50000]\n",
      "loss: 0.180390  [15424/50000]\n",
      "loss: 0.114251  [16064/50000]\n",
      "loss: 0.127553  [16704/50000]\n",
      "loss: 0.077052  [17344/50000]\n",
      "loss: 0.042428  [17984/50000]\n",
      "loss: 0.049666  [18624/50000]\n",
      "loss: 0.031061  [19264/50000]\n",
      "loss: 0.154277  [19904/50000]\n",
      "loss: 0.054056  [20544/50000]\n",
      "loss: 0.079085  [21184/50000]\n",
      "loss: 0.059631  [21824/50000]\n",
      "loss: 0.026667  [22464/50000]\n",
      "loss: 0.035611  [23104/50000]\n",
      "loss: 0.023426  [23744/50000]\n",
      "loss: 0.067615  [24384/50000]\n",
      "loss: 0.109690  [25024/50000]\n",
      "loss: 0.042647  [25664/50000]\n",
      "loss: 0.116647  [26304/50000]\n",
      "loss: 0.074446  [26944/50000]\n",
      "loss: 0.141855  [27584/50000]\n",
      "loss: 0.035299  [28224/50000]\n",
      "loss: 0.096319  [28864/50000]\n",
      "loss: 0.152860  [29504/50000]\n",
      "loss: 0.101970  [30144/50000]\n",
      "loss: 0.160082  [30784/50000]\n",
      "loss: 0.105836  [31424/50000]\n",
      "loss: 0.212429  [32064/50000]\n",
      "loss: 0.069216  [32704/50000]\n",
      "loss: 0.118749  [33344/50000]\n",
      "loss: 0.129050  [33984/50000]\n",
      "loss: 0.146287  [34624/50000]\n",
      "loss: 0.019233  [35264/50000]\n",
      "loss: 0.183953  [35904/50000]\n",
      "loss: 0.061475  [36544/50000]\n",
      "loss: 0.108337  [37184/50000]\n",
      "loss: 0.121500  [37824/50000]\n",
      "loss: 0.095755  [38464/50000]\n",
      "loss: 0.185856  [39104/50000]\n",
      "loss: 0.098488  [39744/50000]\n",
      "loss: 0.246784  [40384/50000]\n",
      "loss: 0.133168  [41024/50000]\n",
      "loss: 0.161170  [41664/50000]\n",
      "loss: 0.152218  [42304/50000]\n",
      "loss: 0.202986  [42944/50000]\n",
      "loss: 0.108628  [43584/50000]\n",
      "loss: 0.155298  [44224/50000]\n",
      "loss: 0.019016  [44864/50000]\n",
      "loss: 0.028696  [45504/50000]\n",
      "loss: 0.052534  [46144/50000]\n",
      "loss: 0.204829  [46784/50000]\n",
      "loss: 0.086098  [47424/50000]\n",
      "loss: 0.116620  [48064/50000]\n",
      "loss: 0.068191  [48704/50000]\n",
      "loss: 0.253709  [49344/50000]\n",
      "loss: 0.110664  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.665895 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.138167  [   64/50000]\n",
      "loss: 0.014523  [  704/50000]\n",
      "loss: 0.056227  [ 1344/50000]\n",
      "loss: 0.177836  [ 1984/50000]\n",
      "loss: 0.224791  [ 2624/50000]\n",
      "loss: 0.059147  [ 3264/50000]\n",
      "loss: 0.134242  [ 3904/50000]\n",
      "loss: 0.042986  [ 4544/50000]\n",
      "loss: 0.111127  [ 5184/50000]\n",
      "loss: 0.184950  [ 5824/50000]\n",
      "loss: 0.166891  [ 6464/50000]\n",
      "loss: 0.100771  [ 7104/50000]\n",
      "loss: 0.091199  [ 7744/50000]\n",
      "loss: 0.065964  [ 8384/50000]\n",
      "loss: 0.036796  [ 9024/50000]\n",
      "loss: 0.071015  [ 9664/50000]\n",
      "loss: 0.132191  [10304/50000]\n",
      "loss: 0.133085  [10944/50000]\n",
      "loss: 0.110768  [11584/50000]\n",
      "loss: 0.089824  [12224/50000]\n",
      "loss: 0.090446  [12864/50000]\n",
      "loss: 0.040775  [13504/50000]\n",
      "loss: 0.164877  [14144/50000]\n",
      "loss: 0.118630  [14784/50000]\n",
      "loss: 0.104429  [15424/50000]\n",
      "loss: 0.120969  [16064/50000]\n",
      "loss: 0.048862  [16704/50000]\n",
      "loss: 0.184388  [17344/50000]\n",
      "loss: 0.078721  [17984/50000]\n",
      "loss: 0.056160  [18624/50000]\n",
      "loss: 0.069785  [19264/50000]\n",
      "loss: 0.062165  [19904/50000]\n",
      "loss: 0.068656  [20544/50000]\n",
      "loss: 0.103544  [21184/50000]\n",
      "loss: 0.097236  [21824/50000]\n",
      "loss: 0.115838  [22464/50000]\n",
      "loss: 0.093057  [23104/50000]\n",
      "loss: 0.149628  [23744/50000]\n",
      "loss: 0.015490  [24384/50000]\n",
      "loss: 0.058488  [25024/50000]\n",
      "loss: 0.088270  [25664/50000]\n",
      "loss: 0.105583  [26304/50000]\n",
      "loss: 0.181246  [26944/50000]\n",
      "loss: 0.096738  [27584/50000]\n",
      "loss: 0.092950  [28224/50000]\n",
      "loss: 0.067043  [28864/50000]\n",
      "loss: 0.176415  [29504/50000]\n",
      "loss: 0.052089  [30144/50000]\n",
      "loss: 0.193326  [30784/50000]\n",
      "loss: 0.081527  [31424/50000]\n",
      "loss: 0.039182  [32064/50000]\n",
      "loss: 0.103571  [32704/50000]\n",
      "loss: 0.212144  [33344/50000]\n",
      "loss: 0.044609  [33984/50000]\n",
      "loss: 0.143527  [34624/50000]\n",
      "loss: 0.226287  [35264/50000]\n",
      "loss: 0.040491  [35904/50000]\n",
      "loss: 0.088181  [36544/50000]\n",
      "loss: 0.063149  [37184/50000]\n",
      "loss: 0.211700  [37824/50000]\n",
      "loss: 0.051027  [38464/50000]\n",
      "loss: 0.079251  [39104/50000]\n",
      "loss: 0.076392  [39744/50000]\n",
      "loss: 0.193425  [40384/50000]\n",
      "loss: 0.177009  [41024/50000]\n",
      "loss: 0.062742  [41664/50000]\n",
      "loss: 0.185883  [42304/50000]\n",
      "loss: 0.069443  [42944/50000]\n",
      "loss: 0.057463  [43584/50000]\n",
      "loss: 0.032320  [44224/50000]\n",
      "loss: 0.061082  [44864/50000]\n",
      "loss: 0.042661  [45504/50000]\n",
      "loss: 0.052505  [46144/50000]\n",
      "loss: 0.040058  [46784/50000]\n",
      "loss: 0.122212  [47424/50000]\n",
      "loss: 0.096537  [48064/50000]\n",
      "loss: 0.249279  [48704/50000]\n",
      "loss: 0.049071  [49344/50000]\n",
      "loss: 0.009266  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.698185 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.076284  [   64/50000]\n",
      "loss: 0.374572  [  704/50000]\n",
      "loss: 0.059611  [ 1344/50000]\n",
      "loss: 0.172533  [ 1984/50000]\n",
      "loss: 0.034476  [ 2624/50000]\n",
      "loss: 0.092056  [ 3264/50000]\n",
      "loss: 0.034581  [ 3904/50000]\n",
      "loss: 0.033016  [ 4544/50000]\n",
      "loss: 0.038977  [ 5184/50000]\n",
      "loss: 0.019735  [ 5824/50000]\n",
      "loss: 0.156013  [ 6464/50000]\n",
      "loss: 0.175006  [ 7104/50000]\n",
      "loss: 0.124881  [ 7744/50000]\n",
      "loss: 0.081581  [ 8384/50000]\n",
      "loss: 0.022708  [ 9024/50000]\n",
      "loss: 0.065015  [ 9664/50000]\n",
      "loss: 0.029190  [10304/50000]\n",
      "loss: 0.107994  [10944/50000]\n",
      "loss: 0.019848  [11584/50000]\n",
      "loss: 0.117882  [12224/50000]\n",
      "loss: 0.031720  [12864/50000]\n",
      "loss: 0.124710  [13504/50000]\n",
      "loss: 0.038894  [14144/50000]\n",
      "loss: 0.028683  [14784/50000]\n",
      "loss: 0.089002  [15424/50000]\n",
      "loss: 0.070295  [16064/50000]\n",
      "loss: 0.100135  [16704/50000]\n",
      "loss: 0.158998  [17344/50000]\n",
      "loss: 0.091605  [17984/50000]\n",
      "loss: 0.173909  [18624/50000]\n",
      "loss: 0.084991  [19264/50000]\n",
      "loss: 0.095420  [19904/50000]\n",
      "loss: 0.096917  [20544/50000]\n",
      "loss: 0.088437  [21184/50000]\n",
      "loss: 0.024699  [21824/50000]\n",
      "loss: 0.076467  [22464/50000]\n",
      "loss: 0.161296  [23104/50000]\n",
      "loss: 0.159775  [23744/50000]\n",
      "loss: 0.173535  [24384/50000]\n",
      "loss: 0.125602  [25024/50000]\n",
      "loss: 0.098363  [25664/50000]\n",
      "loss: 0.024185  [26304/50000]\n",
      "loss: 0.062887  [26944/50000]\n",
      "loss: 0.090927  [27584/50000]\n",
      "loss: 0.075870  [28224/50000]\n",
      "loss: 0.064600  [28864/50000]\n",
      "loss: 0.099021  [29504/50000]\n",
      "loss: 0.056459  [30144/50000]\n",
      "loss: 0.065935  [30784/50000]\n",
      "loss: 0.081489  [31424/50000]\n",
      "loss: 0.097081  [32064/50000]\n",
      "loss: 0.041849  [32704/50000]\n",
      "loss: 0.073233  [33344/50000]\n",
      "loss: 0.062030  [33984/50000]\n",
      "loss: 0.405603  [34624/50000]\n",
      "loss: 0.118038  [35264/50000]\n",
      "loss: 0.203900  [35904/50000]\n",
      "loss: 0.112956  [36544/50000]\n",
      "loss: 0.266867  [37184/50000]\n",
      "loss: 0.234196  [37824/50000]\n",
      "loss: 0.022075  [38464/50000]\n",
      "loss: 0.067009  [39104/50000]\n",
      "loss: 0.090758  [39744/50000]\n",
      "loss: 0.033489  [40384/50000]\n",
      "loss: 0.013422  [41024/50000]\n",
      "loss: 0.164362  [41664/50000]\n",
      "loss: 0.065767  [42304/50000]\n",
      "loss: 0.074997  [42944/50000]\n",
      "loss: 0.082092  [43584/50000]\n",
      "loss: 0.068378  [44224/50000]\n",
      "loss: 0.143512  [44864/50000]\n",
      "loss: 0.075485  [45504/50000]\n",
      "loss: 0.145400  [46144/50000]\n",
      "loss: 0.067076  [46784/50000]\n",
      "loss: 0.160422  [47424/50000]\n",
      "loss: 0.105134  [48064/50000]\n",
      "loss: 0.038856  [48704/50000]\n",
      "loss: 0.151254  [49344/50000]\n",
      "loss: 0.061983  [49984/50000]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.690737 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▅▆▇▇▇▇█▇███████████</td></tr><tr><td>test_loss</td><td>█▄▃▂▂▁▁▁▂▁▁▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8396</td></tr><tr><td>test_loss</td><td>0.69074</td></tr><tr><td>train_loss</td><td>0.09537</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mobnet1</strong> at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/7cls1xza' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2/runs/7cls1xza</a><br> View project at: <a href='https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2' target=\"_blank\">https://wandb.ai/shadaevf-rtu-mirea/ML2_4_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250502_182151-7cls1xza/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "trainset, testset = get_data()\n",
    "\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "net = mobnet_model\n",
    "net.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"ML2_4_2\",\n",
    "    # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "    name=\"mobnet1\",\n",
    ")\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, net, loss_fn, optimizer, device)\n",
    "    test_loop(testloader, net, loss_fn, device)\n",
    "\n",
    "torch.save(net.state_dict(), \"model_weights.pth\")\n",
    "torch.save(optimizer.state_dict(), \"optimizer_settings.pth\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPjF5et91NB7coJIOmg+4zZ",
   "collapsed_sections": [
    "r549vmfG2QpQ"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
